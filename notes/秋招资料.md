[TOC]



## 基础知识

### 数据结构与算法

#### Q：红黑树

![image-20220307191129362](C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\image-20220307191129362.png)

红黑树本质上是一种二叉查找树，但它在二叉查找树的基础上额外添加了一个标记（颜色），同时具有一定的规则。这些规则使红黑树保证了一种平衡，插入、删除、查找的最坏时间复杂度都为 O(logn)。它的性能统计上要好于平衡二叉树（AVL树）。

黑色高度：从根节点到叶节点的路径上黑色节点的个数，叫做树的黑色高度。

红黑树的 5 个特性：

1. 每个节点要么是红色，要么是黑色；
2. 根节点永远是黑色的；
3. 所有的叶节点都是是黑色的（注意这里说叶子节点其实是上图中的 NIL 节点）；
4. 每个红色节点的两个子节点一定都是黑色；
5. **从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点；**



#### Q：B树

<img src="C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\image-20220307195520385.png" alt="image-20220307195520385" style="zoom:67%;" />

B树是一种多路平衡查找树，每个节点有多个分支。

一棵m阶B树(balanced tree of order m) 是一棵平衡的m路搜索树，B树常用于磁盘寻址。

它具有以下性质：

1. 每个节点最多有m-1个关键字（可以存有键值对）
2. 根节点最少可以只有1个关键字
3. 非根节点至少有m/2个关键字
4. 每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。
5. 所有的叶子节点都位于同一层
6. 每个节点都存有索引和数据，也就是对应的key和value。

B树的插入：判断当前结点key的个数是否小于等于m-1，如果满足，直接插入即可，如果不满足，将节点的中间的key将这个节点分为左右两部分，中间的节点放到父节点中即可。

参考文章：[B树和B+树](https://juejin.cn/post/6844903944292925447)





#### Q：B+树

![img](C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\997909-20190728114240297-169990922.png)

B+树是应文件系统所需而产生的B树的变形树

特点：

1. 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。
2. 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
3. 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。

B+树的好处主要体现在查询性能上：

1. 在单行查询时，B+树会自顶向下逐层查找结点，最终找到匹配的叶子节点；

   中间节点没有不存储数据，所以同样大小的磁盘页可以容纳更多的节点元素，故B+树IO次数更少更加矮胖，其次查找性能更加稳定。

2. 范围查询时，B+树叶子节点之间组成一个链表，方便于遍历查询。而B树范围查询只能依靠繁琐的中序遍历。

   



#### Q：跳表

<img src="C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\image-20220307200211521.png" alt="image-20220307200211521" style="zoom: 67%;" />

跳表是用于有序元素序列快速搜索查找的一个数据结构，通过以空间换时间的思想，在原有的链表上面增加了多级索引，可以通过索引实现近似二分查找的效率。

查找过程：

1. 首先从head出发，如果当前结点的key与查找的key相等，那么直接返回；

2. 如果key不相等，且右侧为null，那么证明只能向下；

3. 如果key不相等，且右侧不为null，且右侧节点key小于等于待查的key，那么说明同级还可以向右；

4. 如果key不相等，且右侧不为null，且右侧节点key大于待查的key，那么说明有结果的就在这个索引和右侧索引之间。

   



### 计算机网络

#### Q：TCP/IP 各层的作用

**应用层：**通过应用进程间的交互来完成特定功能的网络应用。对于不同的网络应用需要不同的应用层协议。

**表示层：**提供各种用于应用层数据的编码和转换功能

**会话层**：负责建立、管理和终止表示层实体之间的通信会话

**运输层**：传输层建立了主机端到端的链接，提供可靠传输和端口复用。

**网络层**：在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。

**数据链路层**：两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。 在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。

**物理层**：实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异， 使其上面的数据链路层不必考虑网络的具体传输介质是什么

参考文章：[TCP/IP 各层的结构与功能](TCP/IP 各层的结构与功能)



#### Q：TCP和UDP的比较

- 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，可靠的流协议，且提供顺序控制、流量控制、拥塞控制、全双工端到端通信等功能。

- 用户数据报协议 UDP（User Datagram Protocol）是面向无连接的数据报协议，使用尽最大可能交付，无拥塞控制、首部开销小。

显然，TCP主要用于在传输层有必要实现可靠传输的情况，而UDP适用于那些对高速传输和实时性有较高要求的通信或者广播通信。



#### Q：TCP三次握手过程

<img src="http://www.yswang.tech/upload/2022/01/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B-0db876c4fad441898b4579cad32c816e.png" alt="TCP三次握手.png" style="zoom:50%;" />

**第一次握手**

客户端向服务端发送连接请求报文段。该报文段中包含自身的数据通讯初始序号。请求发送后，客户端便进入 SYN-SENT 状态。

**第二次握手**

服务端收到连接请求报文段后，如果同意连接，则会发送一个应答，该应答中也会包含自身的数据通讯初始序号，发送完成后便进入 SYN-RECEIVED 状态（半连接状态）。

**第三次握手**

当客户端收到连接同意的应答后，还要向服务端发送一个确认报文。客户端发完这个报文段后便进入 ESTABLISHED 状态，服务端收到这个应答后也进入 ESTABLISHED 状态，此时连接建立成功。



#### Q：TCP四次挥手过程

![TCP四次挥手.jpg](C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\TCP四次挥手-ffdcc72f714844e18c832cfd77f79210.jpg)

**第一次挥手**

若客户端 A 认为数据发送完成，则它需要向服务端 B 发送**连接释放**请求。

**第二次挥手**

B 收到连接释放请求后，会告诉应用层要释放 TCP 链接。然后会发送 ACK 包，并进入 CLOSE_WAIT 状态，此时表明 A 到 B 的连接已经释放，不再接收 A 发的数据了。但是因为 **TCP 连接是双向的，所以 B 仍旧可以发送数据给 A**。

**第三次挥手**

B 如果此时还有没发完的数据会继续发送，完毕后会向 A 发送连接释放请求，然后 B 便进入 LAST-ACK 状态。

> PS：通过延迟确认的技术（通常有时间限制，否则对方会误认为需要重传），可以将第二次和第三次握手合并，延迟 ACK 包的发送。

**第四次挥手**

A 收到释放请求后，向 B 发送确认应答，此时 A 进入 TIME-WAIT 状态。该状态会持续 2MSL（最长报文段寿命，指报文段在网络中生存的时间，超时会被抛弃） 时间，若该时间段内没有 B 的重发请求的话，就进入 CLOSED 状态。当 B 收到确认应答后，也便进入 CLOSED 状态。

> 1. 保证TCP协议的全双工连接能够可靠关闭。
> 2. 保证本次连接的重复数据段从网络中消失。这里可能不太好理解，反推解释下。假设time_wait在1MSL后回收资源。如果对端正常收到第四次握手的确认包，那没什么问题。但如果对端没有收到，超时后会重传第三次握手的包，极端情况下这个包相对于本地要在2MSL后才能彻底从网络中消失，当到达本地时端口很有可能被新连接使用了，会影响新连接。



#### Q：ARQ协议

答：ARQ协议，即自动重传请求（Automatic Repeat-reQuest），是OSI模型中的错误纠正协议之一。

==它通过使用确认和重传这两个机制，在不可靠服务的基础上实现可靠的信息传输==；

如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送；

重传的请求是自动进行的，接收方不需要请求发送方重传某个出错的分组；

ARQ包括停止等待ARQ协议和 连续ARQ协议。

（1）停止等待ARQ协议

基本思想就是每发完一个分组就停止发送，等待对方的确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到ACK确认，说明没有发送成功，需要重新发送，直到收到确认后再发送下一个分组。

在停止等待协议中，若接收方收到重复分组，那就丢弃该分组，但同时还要发送确认。

（2）连续ARQ协议

为了提高信道利用率，连续ARQ协议的发送方维持一个发送窗口，凡是位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

为了解决这种流水线的差错恢复，TCP提供了两种滑动窗口：**回退N(Go-Back- N，GBN)** 和**选择重传(Selective Repeat，SR)** 。

**回退N帧**：发送窗口大于1，接收窗口等于1。发送方可连续发送多个数据帧 而不需等待对方确认。接收方只允许按顺序接收帧。当一个分组确认时间超时，发送方就需要重传所有待确认的分组。

**选择重传**：发送窗口大于1，接收窗口大于1。只重传真正出错或者丢失的分组。具体就是发送方维持着一个窗口，包含可发送或已发送但未被确认的序号。接收方维持着一个窗口，==包含可接收的序号，每个序号还保留一个缓存区，用来指明是否被填充==。每个接收方接到分组后会判断是否在窗口内，在的话就先缓存并返回确认。而发送到这边每个发送缓存都设置一个计时器，超时没有确认就重发。



ARQ到底运行在那一层？

ARQ是一种可以在不可靠的数据通道上可靠地传输数据的方案，所以其实链路层和传输层都用了ARQ，并不专属某一层。

并不是一条连接只要有一层用了ARQ，它的上层的通信就是可靠的。因为ARQ只保证使用它的点到点是可靠的，比如数据链路层只保证你和你的路由器通信可靠，你的路由器到小区的路由器通信也可靠， 但是路由器本身会故障，会拥塞丢包，也就是点本身会产生问题。

所以需要在传输层或者应用层再加一层ARQ保障整条数据通道的可靠性。比如你自己写程序要在应用层通信，但传输层不用tcp想用udp，也可以在你程序里用ARQ协来实现可靠性。

参考文章：[TCP可靠传输：ARQ协议（停止等待、超时重传、滑动窗口、回退N帧、选择重传）](https://juejin.cn/post/7059671699926548511)



#### Q：TCP 如何保证可靠性传输

TCP协议保证数据传输可靠性的方式主要有：

1. **连接管理：**使用三次握手和四次挥手来保证可靠的连接。
2. **校验和：** TCP 将保存它首部和数据的检验和，目的是检测数据在传输过程中是否发生变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
3. **序列号：**TCP 给发送的每一个字节进行编号，接收方对数据包进行排序，并且去掉重复序列号的数据，把有序数据传送给应用层。
4. **自动重传请求**（**ARQ 协议）：** 为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认，在收到确认后再发送下一个分组。
5. **超时重传：** 当 TCP 发出一个包后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。
6. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据，当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
7. **拥塞控制：** 根据网络的情况，调节发送速率，当网络拥塞时，减少数据的发送。TCP 的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。





#### Q：Cookie和Session的区别

Cookie是某些网站为了辨别用户身份而储存在用户本地终端上的数据；

Session则是通过在服务端开辟一块内存空间记录用户的状态和行为的手段。（是否登录）

使用Cookie-Session方案做身份验证：

1. POST /user/login
2. 返回带SessionId的Cookie 给客户端
3. 客户端下次请求时带上SessionId

多服务器下Session-Cookie方案：

1. 一致性哈希
2. 每个服务器全量保存
3. 第三方公共的集群保存（如Redis）

没有Cookie时能否用Session：

1. 一般禁用Cookie，那么Session就无法正常工作
2. 手段：将SessionId写在url中；安全性较低





#### Q：URL到页面的过程

总体来说分为一下几个过程：

<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220305140336435.png" alt="image-20220305140336435" style="zoom: 67%;" />

1. DNS 解析
2. TCP 连接
3. 发送 HTTP 请求
4. 服务器处理请求并返回 HTTP 报文
5. 浏览器解析渲染页面
6. 连接结束





#### Q：HTTP状态码

- 1XX：信息性状态码；接收的请求正在处理

- 2XX：成功状态码；请求正常处理完毕

  > - `200 OK`：客户端请求成功。
  > - `204 No Content`：无内容。服务器成功处理，但未返回内容。一般用在只是客户端向服务器发送信息，而服务器不用向客户端返回什么信息的情况。不会刷新页面。
  > - `206 Partial Content`：服务器已经完成了部分 GET 请求（客户端进行了范围请求）。响应报文中包含 Content-Range 指定范围的实体内容。

- 3XX：重定向状态码；需要进行附加操作已完成请求

  > - 301：被请求的资源已永久移动到新位置。服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。
  > - 302、303都是临时重定向
  > - 304：自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。

- 4XX：客户端错误状态码；服务器无法处理请求

  > - 400：客户端请求有语法错误，服务器无法理解。
  > - 401：请求未经授权，这个状态代码必须和 WWW-Authenticate 报头域一起使用
  > - 403：服务器已经理解请求，但是拒绝执行它
  > - 404：请求资源不存在。比如，输入了错误的 URL。

- 5XX：服务器错误状态码；服务器处理请求出错

  > - 500：服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。
  > - 502：Web服务器用作网关或代理服务器时收到了无效响应
  > - 503：由于临时的服务器维护或者过载，服务器当前无法处理请求。通常，这个是暂时状态，一段时间会恢复





#### Q：HTTP 1.0 、HTTP 1.1 和 HTTP 2.0 的主要区别

**HTTP 1.1 与 HTTP1.0比较**：

1. **长连接** : 在 HTTP/1.0 中，默认使用的是短连接；HTTP/1.1则默认采用长连接，并且支持流水线方式请求。
2. **错误状态响应码**：在 HTTP1.1 中新增了 24 个错误状态响应码
3. **缓存处理** ：引入了更多的缓存控制策略
4. **带宽优化及网络连接的使用**：HTTP1.1 则在请求头引入了 range 字段，它允许只请求资源的某个部分

**HTTP2.0优化**：

1. **二进制分帧**：HTTP 2.0 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式，二进制协议解析起来更高效。每个数据流都以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装。
2. **多路复用**：所有请求都是通过一个 TCP连接并发完成，同域名下所有通信都在单个连接上完成，该连接可以承载任意数量的双向数据流。
3. **服务器推送**：服务端可以在发送页面HTML时主动推送其它资源，而不用等到浏览器解析到相应位置，发起请求再响应。例如服务端可以主动把JS和CSS文件推送给客户端，而不需要客户端解析HTML时再发送这些请求。
4. **头部压缩**：HTTP 1.1请求的大小变得越来越大，HTTP 2对消息头采用HPACK（专为HTTP 2头部设计的压缩格式）进行压缩传输，能够节省消息头占用的网络的流量。而HTTP 1.x每次请求，都会携带大量冗余头信息，浪费了很多带宽资源。



#### Q：HTTP和HTTPS的区别

HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP协议安全。

HTTPS和HTTP的区别主要如下：

1、HTTPS协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。

2、HTTP是超文本传输协议，信息是明文传输，HTTPS则是具有安全性的ssl加密传输协议。

3、HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

4、HTTP的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比HTTP协议安全。

HTTP 有以下安全性问题：

- 使用明文进行通信，内容可能会被窃听；
- 不验证通信方的身份，通信方的身份有可能遭遇伪装；
- 无法证明报文的完整性，报文有可能遭篡改。

HTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。

通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。

[HTTPs 详细内容介绍](./HTTP基础知识.md)



#### Q：GET/POST 以及幂等性

（1）作用：GET 用于获取资源，而 POST 用于传输实体主体。

（2）参数：GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。

（3）安全：安全的HTTP方法不会改变服务器状态，也就是说只是可读的。

基于此安全的方法有GET、HEAD、OPTION；而不安全的方法有POST、PUT、DELETE。

（4）幂等性：幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。

所有的安全方法也都是幂等的。

在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。

（5）可缓存：GET一般可以缓存，而POST多数情况下不可缓存。





#### Q：常见的密钥算法

对称加密算法：指在加密和解密时使用的是同一个秘钥，常用算法：AES、DES（Data Encryption Standard）

DES算法把64位的明文输入块变为64位的密文输出块，它所使用的密钥也是64位。

非对称加密算法：非对称加密算法需要公钥和私钥。 公钥和私钥是一对,如果用公钥对数据进行加密,只有用对应的私钥才能解密。常用算法：RSA，DSA（Digital Signature Algorithm，数字签名算法）

RSA 算法可以生成公钥和私钥的。公钥用于加密信息，私钥用来解密。算法特点是由公钥和信息作为参数进行运算，得到密文，这个过程要很容易。而逆向运算，由密文和公钥想要获得信息，是很难做到的。当然，这个算法还必须有另外一个特点。就是逆向操作虽然默认很难做到的，但是如果拥有了特定的提示信息，也就是私钥，操作就变得非常容易了。

具体实现涉及取模运算和整数分解，实际生成公钥和私钥的过程是，我们选出 p1 和 p2 两个大素数，让 N = p1 * p2 。随机选择一个指数 e ，这样公钥就有了。而在知道 p1 和 p2 的前提下，从公钥算出私钥，也就是算出 d ，是非常容易的。而外人，因为不知道 p1 和 p2 ，而只知道 N ，所以不可能从 e 算出 d ，也就是不可能用公钥算出私钥。

参考文章：[RSA 算法--基本原理篇](https://blog.csdn.net/yexudengzhidao/article/details/102759795)



#### Q：泛洪攻击

答：泛洪攻击是一种针对TCP三次握手进行攻击的手段：

攻击者在第一次握手阶段向服务器发送大量的SYN包，在服务器回应第二次握手成功后，不向服务器端发送ACK包导致服务器在第二次握手后存在大量的半开连接，消耗服务器资源，最后使得服务器无法再响应TCP连接，达到攻击目的。

使用SYN cookie可以有效抵御泛洪攻击：

服务器在第二次握手时不会为第一次握手的SYN创建半开连接，而是生成一个cookie一起发送给客户端，只有客户端在第三次握手发送ACK报文并且验证cookie成功服务器才会创建TCP连接，分配资源。













### 操作系统与Linux

#### Q：进程、线程和协程的区别

进程：进程一般由程序、数据集合和PCB组成，是一个程序在一个数据集上的一次动态执行过程，==进程是程序在执行过程中分配和管理资源的基本单位，每一个进程都有一个自己的地址空间==。

线程：==线程是CPU调度和分派的基本单位==，它可与同属一个进程的其他的线程共享进程所拥有的全部资源。

联系：线程是进程的一部分，一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。

为什么引入线程概念：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，需要较大的时空开销，限制了并发程度的进一步提高。为减少进程切换的开销，把进程作为资源分配单位和调度单位这两个属性分开处理，即进程还是作为资源分配的基本单位，但是不作为调度的基本单位（很少调度或切换），把调度执行与切换的责任交给线程，即线程成为独立调度的基本单位，它比进程更容易（更快）创建，也更容易撤销。

协程：==协程是一种用户态的轻量级线程，协程的调度完全由用户控制==。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

![image-20220321111240705](C:/Users/Lenovo/Desktop/笔记/CS-Learning-Notes/notes/pics/image-20220321111240705.png)

进程切换：

1. 保存处理机上下文，包括程序计数器和其他寄存器。
2. 更新PCB信息。
3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。
4. 选择另一个进程执行，并更新其PCB。
5. 更新内存管理的数据结构。
6. 恢复处理机上下文。

进程状态：

1. 创建状态(new) ：进程正在被创建，尚未到就绪状态。
2. 就绪状态(ready) ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
3. 运行状态(running) ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
4. 阻塞状态(waiting) ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
5. 结束状态(terminated) ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。



#### Q：进程调度算法

- 先到先服务(FCFS)调度算法 : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- 短作业优先(SJF)的调度算法 : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- 时间片轮转调度算法 : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- 高响应比优先的调度算法：这种算法是在短作业优先调度算法的基础上，加上一个随着时间累计而叠加的权重机制。响应比=(等待时间 + 要求服务时间) / 要求服务时间，这种算法既可以优先完成短作业，又能确保长作业不至于长期饥饿，是一个折中的算法。
- 多级反馈队列调度算法 ：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。
- 优先级调度 ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。



#### Q：进程间通信方式

进程通信方式主要有管道、消息队列、共享内存、信号量、信号、socket。 

（1）管道

管道分成匿名管道和命名管道匿名管道在linux非常常见，就是那个竖线 |，就是把前一个命令的输出作为后一个命令的输入。数据传输是单向的且没有名字。

管道还有一种类型就是命名管道，也叫FIFO，采用的是先进先出的传输方式。使用 mkfifo命令来创建，并且命令管道名字。这本质上也就是一种文件，使用前需要内存中创建一个文件，通过文件写入读取来通信。

```shell
echo "hello" > myPipe // 将数据写进管道 
cat < myPipe // 读取管道里的数据 
hello 
int pipe(int fd[2])
```

管道的原理：所谓管道，就是内核里面的一串缓存。创建匿名管道的时候，会返回两个描述符，一个管道读取端描述符，一个是管道写入端描述符。在通信时，父进程fork创建子进程，创建的子进程会复制父进程的文件描述符，两个进程就可以通过各自的fd写入和读取同一个管道文件实现跨进程通信了。在执行 A | B命令时，A进程和B进程都是shell创建出来的子进程，A和B不存在父子关系，但两个的父进程都是shell。也就说shell通过 | 匿名管道将多个命令连接在一起，实际上就是创建出了多个子进程。

综上，对于匿名管道，它的通信范围是存在父子关系的进程。对于命名关东，由于提前创建了一个管道类型的设备文件，不相关的进程也能相互通信。

（2）消息队列

消息队列是保存在内核中的消息链表，这中方式下的两个进程之间的通信就像收发邮件一样。先是定义好消息体的数据类型，然后进程把消息写到内核的消息队列，如何进程读取了消息体，内核就会把这个消息体删除。

这种邮件式的通信存在两个不足的地方：一个是通信不及时，二是不适合大数据传输。同时通信过程中涉及用户态和内核态的频繁切换和数据拷贝。

（3）共享内存

因为消息队列存在用户态和内核态之间的消息拷贝过程，共享内存的方式就出来了。由于现代操作系统的内存管理采用的虚拟内存技术，也就是每个进程都有一个自己独立的虚拟存储空间，不同进程的虚拟内存映射到不同的物理内存中。所以即使A、B两个进程的虚拟地址是一样的，其实访问的是不同的物理地址，对于数据的增删查改互不影响。

共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样子一个进程写入的东西，另一个线程立马就能看到，不需要拷贝来拷贝去，极大提高了进程通信的速度。

（4）信号量

有了共享内存通信方式，带来了一个新的问题，那就是如何避免多线程竞争共享资源，而造成数据错乱的问题，所以需要提供保护机制，让共享资源在任意时刻只能被一个进程访问。信号量就实现了这个保护机制，信号量本质上是一个整型的计数器，主要用来实现进程间的同步与互斥，而不是用来缓存进程间的通信数据。

信号量表示资源的数量，控制信号量有两种原子操作，P操作和V操作，一个是对信号量 -1，一个是+1操作。当信号量P操作以后小于0，则需要被阻塞，等待资源释放被唤醒。

（5）信号

上面的通信方式是常规状态下的工作模式。对于异常情况下的工作模式，就需要用信号的方式来通知进程。

在LInux中提供了几十种信号，可以用 kill -1 来查看。比如常见的Ctrl + C、Z、kill 命令产生的信号等。信号是进程间通信机制种唯一的异步通信机制，因为可以在任何时候发送信号给某一个进程，一旦有信号产生，用户进程得做出一定响应操作。

（6）Socket

前面都是单机上得进程间通信，对于网络上不同主机间进程的通信，就需要Socket通信了。根据创建 socket 类型的不同，通信的方式也就不同。

- 针对TCP协议通信的Socket编程模型为例，
- 先是服务器端和客户端初始化socket得到文件描述符。
- 接着服务器端调用bind，将IP 地址和端口绑定在socket上；
- 服务器端会调用listen，进行监听，再调用accept 等待客户端连接；
- 客户端调用 connect 开始三次握手请求连接服务器；
- 服务器 accept 返回用于传输的socket 的文件描述符；
- 两者使用 read 和 write 相互读写交互；
- 结束时，调用close断开连接



#### Q：线程通信方式

同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步。

操作系统一般有下面三种线程同步的方式：

1. 互斥量(Mutex)：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2. 信号量(Semphares**)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
3. 事件(Event) :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。





#### Q：何为死锁，产生条件，预防措施

答：死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象。

系统中以下四个条件同时成立，那么就能引起死锁：互斥、不可剥夺、占有且等待和循环等待。

死锁的预防方法：构成死锁的四个条件只要破坏其中一个就构不成死锁，死锁一旦形成就无法消除，因此最好的方法就是避免产生死锁。

1. 破坏互斥条件，让资源能够共享，但缺点是不通过，因为有些资源不能共享，如打印机。
2. 破坏请求并保持条件，采用预先分配的方法，在进行运行前一次性申请好它所需要的所有资源，但缺点是浪费资源。
3. 破坏不可剥夺的条件，对已经占用资源的线程发送取消请求，但是实现比较复杂，而且还有破坏业务逻辑。
4. 破坏循环等待条件，为每个资源进行编号，采用顺序的的资源分配方法，规定每个线程必须按照递增的顺序请求资源，缺点是编号必须相对稳定，增加新资源时会比较麻烦，而且有些特殊的业务逻辑不能按完全按照指定的顺序分配资源。

避免产生死锁的算法：银行家算法

核心思想：分配资源之前，判断系统是否安全，如果安全才会进行资源分配。即每当进程提出资源请求且系统的资源能够满足该请求时，系统将判断满足此次资源请求后系统状态是否安全，如果判断结果为安全，则给该进程分配资源，否则不分配资源，申请资源的进程将阻塞。





#### Q：操作系统的内存管理机制

答：简单分为连续分配管理方式和非连续分配管理方式这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 块式管理 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如页式管理 和 段式管理。

（1）连续分配管理方式

单一连续分配：内存中只能有一道用户程序，用户程序独占整个用户区空间；

固定分区分配：将整个用户空间划分为若干个固定大小的分区，在每个分区中只装入一道作业；

动态分区分配：使用特殊的数据结构记录内存的使用情况，根据进程的大小动态地建立分区。

存在的问题：由于其要求把作业（进程）放在内存的一片连续区域中，很容易出现大段的连续内存空间因为不足够容纳作业或进程而不可用。

（2）非连续分配管理方式

基本分页管理：将内存空间分为一个个大小相等的分区，每个分区就称为一个 “页框（page frame）”。每个页框有一个编号，即“页框号”（也成为物理页框号、内存块号），页框号从 0 开 始 。

进程的页面与内存的页框有一一对应的关系。 各个页面不必连续存放，可以放到不相邻（离散）的各个页框中。

一个进程对应一张页表，进程的每个页面对应一个页表项，每个页表项由页号和块号（页框号）组成，记录着进程页面和实际存放的内存块之间的映射关系。

在任何分页式系统中，都不可避免地要考虑下面这两个问题：

问题 1：如何保证虚拟地址到物理地址的转换足够快 — 使用快表解决

问题 2：如何解决虚拟地址空间大，页表也会很大的问题（页表项多了，页表自然也就大了）— 使用多级页表解决

基本分段管理：段式系统是按照用户作业（进程）中的自然段来划分逻辑空间的。段与段之间可以不连续存储，但是段的内部仍然是连续的。和基本分页管理一样，基本分段管理也需要一个数据结构来记录虚拟地址和物理地址之间的映射，这个数据结构就是段表。

基本段页管理：对虚拟地址空间先进行段的划分，然后在每一段内再进行页的划分。



#### Q：分页机制和分段机制的区别

共同点：

- 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。
- 页内和段内的内存是连续的，页与页和段与段之间是离散的。

区别：

- 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
- 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。



#### Q：快表

==为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换==。本质上就是一种高速缓冲存储器，其中保存了虚拟页号与物理页号的映射。

由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

地址转换流程：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。



#### Q：虚拟内存

虚拟内存是计算机系统==内存管理==的一种技术。通过 虚拟内存 ==可以让程序可以拥有超过系统物理内存大小的可用内存空间==。另外，虚拟内存为每个进程提供了一个一致的、==私有的地址空间==，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）。这样会更加有效地管理内存并减少出错。

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

1. 时间局部性 ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. 空间局部性 ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。



#### Q：虚拟内存技术的实现

虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。 虚拟内存的实现有以下三种方式：

1. 请求分页存储管理 ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. 请求分段存储管理 ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. 请求段页式存储管理



#### Q：页面置换算法

- **OPT 页面置换算法（最佳页面置换算法）**：所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页。



#### Q：零拷贝



#### Q：Linux网络 I/O模型

（1）阻塞I/O模型：最常见的I/O模型就是阻塞I/O模型，当用户进程发起系统调用开始到它返回结果的整个过程，用户进程都是被阻塞的。并且内核在数据准备阶段也是会一直等待。

（2）非阻塞I/O模型：用户进程发起系统调用，内核数据没有准备好时，就会直接返回一个error，用户进程不会被阻塞，而是进行不断询问内核数据好了没有。一旦内核数据好了，又接到用户进程的系统调用，就马上返回数据。

（3）I/O复用模型：就是我们说的select、poll、epoll，它们内核提供给用户态的多路复用系统调用，线程可以通过一个系统调用函数从内核中获取多个事件。在获取事件时，先把我们要关心的连接传给内核，再由内核检测：

- 如果没有事件发生，线程只需阻塞在这个系统调用，而无需像前面的线程池方案那样轮询调用 read 操作来判断是否有数据。
- 如果有事件发生，内核会返回产生了事件的连接，线程就会从阻塞状态唤醒，处理这些连接对应的业务即可。

（4）信号驱动I/O模型：用户进程发起系统调用，内核立即返回，当内核操作完，就为该进程生成一个信号，通过信号回调通知进程来取数据。

（5）异步I/O模型：用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。



epoll 事件触发模式有默认的 level-trigger 模式和通过 EPOLLET 启用的 edge-trigger 模式两种。

LT模式状态时，主线程正在epoll_wait等待事件时，请求到了，epoll_wait返回后没有去处理请求(recv)，那么下次epoll_wait时此请求还是会返回（立刻返回了）；而ET模式状态下，这次没处理，下次epoll_wait时将不返回（所以我们应该每次一定要处理），可见很大程度降低了epoll的触发次数。

> IO多路复用其实就是指一个线程可以监视多个网络IO连接，它的基本原理就是系统轮询所服务的所有socket，当某个socket有数据到达了，就通知用户进程。具体实现有select、poll、epoll。
>
> 就是select，poll，epoll这些系统调用会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。
>
> （1）select(…)工作原理？
>
> 当操作系统的select函数被调用以后，首先会按照fd集合，去检查内存中的socket套接字状态，这个复杂度是O(N)的。然后检查完一遍之后，发现有就绪状态的socket那么直接返回，不会阻塞当前调用线程，否则就说明当前指定fd集合对应的socket没有就绪状态的。
>
> 那么就需要阻塞当前调用线程了，直到有某个socket有数据之后，才会唤醒线程。
>
> （2）监听socket数量有没有限制？
>
> 它默认最大可以监听1024个socket。因为fd_set这个结构它是一个bitmap位图结构，默认长度是1024bit。之所以是1024bit，是考虑系统调用涉及到参数的数据拷贝， 如果bitmap数据太庞大，也不利于系统调用速度。
>
> （3）poll(…) 和select(…)主要区别是什么？
>
> select缺点：
>
> 1. 1024 bitmap
> 2. fd_set不可重用
> 3. 用户态<->内核态 开销
> 4. O(n)再次遍历
>
> poll和select最大的区别是两者的传参不同，poll使用的是链表结构，解决了socket监听数量的问题。
>
> （4）epoll产生的背景是什么呢
>
> 1. select和poll这两系统函数每次都是需要我们提供它所有需要监听的socket文件描述符集合，而且咱们的程序主线程都是死循环调用 select/poll函数的，这里涉及到用户空间数据到内核克空间拷贝的过程，这个相对来讲，还是比较消耗新性能的。
> 2. select和poll函数它的返回值是个int整形值，只能代表有几个socket就绪或者是有错误了，它没办法表示具体是哪个socket就绪了。这就导致程序唤醒以后，还需要新的一轮系统调用去检查哪个socket是就绪状态的，然后再进行socket数据处理逻辑，在这已经走了不少弯路了。
>
> （5）epoll函数的工作原理是什么？
>
> 面试者：解决上面说的问题，就需要epoll函数再内核空间内，创建一个对应的数据结构去存储一些数据，这个数据结构其实就是epoll_event对象，它是通过系统函数epoll_create()去创建，就会得到epfd文件号，相当于我们再内核开辟了一小块空间，并且我们也知道这块空间的位置。
>
> 先说一下 epoll_event的结构，它主要是两块重要的区域，其中一块是存放需要监听的socket_fd描述符列表，另一块就是就绪列表，存放就绪状态的socket信息。
>
> 还另外两个重要的函数epoll_ctl()和epoll_wait()。
> epoll_ctl它可以根据epfd号去增删改内核空间上的eventpoll对象列表；epoll_wait()它主要的参数就是epfd，表示此次系统调用需要监测的socket_fd集合，是eventpoll中已经指定好的那些socket信息。epoll_wait函数默认情况下会阻塞调用线程，直到某个socket就绪以后epoll_wait才会返回。
> （6）eventpoll对象的就绪列表数据是如何维护的呢？
>
> 前面已经说了socket对象，它有三块区域嘛，读缓冲区、写缓冲区和等待队列。epoll跟select调用流程非常相似，当我们调用epoll_ctl添加一个需要关注的socket，其实内核程序就会把当前eventpoll对象追加到这个socket#等待队列里，当socket对应的客户端发送完数据，写入内存之后触发中断程序，最后检查这个socket的等待队列，发现这个socket#不是进程，是一个eventpoll对象引用，它会根据这个引用讲当前socket引用追加到eventpoll的就绪链表的末尾。
>
> 还有一个是eventpoll 有一块空间是eventpoll#等待队列，这个等待队列它保存的就是调用了epoll_wait的进程了。
> （7）epollevent对象中存放需要检查的socket信息是采用的什么数据结构？为什么？
>
> 调用epoll_wait函数的时候会传入一个epoll_event事件数组指针，epoll_wait函数正常返回之前，会把就绪的socket事件信息拷贝到这个数组里，返回到上层程序，这样就可以通过这个数组拿到就绪列表了。
>
> epoll_wait默认是阻塞的，也可以设置成非阻塞。
>
> 存放的集合信息是采用 红黑树数据结构。
>
>
> 参考文章：[Linux IO模式及 select、poll、epoll详解](https://juejin.cn/post/6844903488170786824) 、[看这一篇IO多路复用面试专题就够了！最全面最详细的解答！](https://blog.csdn.net/Oooo_mumuxi/article/details/108164013)
>
> 
>
> 问：epoll的优势
>
> 1、支持一个进程的打开socket描述符不受限制
>
> 2、I/O效率不会随着FD数目的增加而线性下降
>
> 3、使用mmap加速内核与用户空间的消息传递
>
> 4、epoll的API更加简单





#### Q：Linux 内存管理

Linux 操作系统是采用段页式内存管理方式：

页式存储管理能有效地提高内存利用率（解决内存碎片），而分段存储管理能反映程序的逻辑结构并有利于段的共享。将这两种存储管理方法结合起来，就形成了段页式存储管理方式。

段页式存储管理方式即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。在段页式系统中，为了实现从逻辑地址到物理地址的转换，系统中需要同时配置段表和页表，利用段表和页表进行从用户地址空间到物理内存空间的映射。

系统为每一个进程建立一张段表，每个分段有一张页表。段表表项中至少包括段号、页表长度和页表始址，页表表项中至少包括页号和块号。在进行地址转换时，首先通过段表查到页表始址，然后通过页表找到页帧号，最终形成物理地址。

![img](C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\6C90A85D39900A44AAFAA50520B82CAE.png)





#### Q：Linux 常用命令

| 命令 | 说明                                                      |
| ---- | --------------------------------------------------------- |
| cd   | 切换当前目录                                              |
| ls   | 查看当前文件与目录                                        |
| grep | 通常与管道命令一起使用，用于对一些命令的输出进行筛选加工  |
| cp   | 复制文件或文件夹                                          |
| mv   | 移动文件或文件夹                                          |
| rm   | 删除文件或文件夹                                          |
| ps   | 查看进程情况                                              |
| kill | 向进程发送信号                                            |
| tar  | 对文件进行打包                                            |
| cat  | 查看文件内容                                              |
| top  | 查看操作系统的信息，如进程、CPU占用率、内存信息等（实时） |
| free | 查看内存使用情况                                          |
| pwd  | 显示当前工作目录                                          |



### 数据库

#### Q：索引

索引的目的是为了提高数据查询的效率，类似书的目录一样。

常见的索引模型有三种，分别是哈希表、有序数组和搜索树。

- 哈希表是一种以键-值（key-value）存储数据的结构，它把值放在一个数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。当然，多个key值经过哈希函数的换算，会出现同一个值的情况。处理这样情况的常见方法是拉出一个链表。哈希表这种结构因为不是有序的，所以哈希索引做区间查询的速度是很慢的，适用于只有等值查询的场景。
- 有序数组在等值查询和范围查询场景中的性能就都非常优秀，但是数据的删除和插入的成本却非常高。所以只适用于静态存储引擎，比如保存某个地区的人口信息，这类信息不会再修改的数据。
- 



**按功能划分，索引主要有四种：**

普通索引：就是最基础的索引，没有任何的约束作用，目的就是提高查询效率。

唯一性索引：在普通索引的基础上增加了数据唯一性的约束，一张表中可以同时存在多个唯一性索引。

主键索引：在唯一性索引的基础上又增加了不为空的约束。一张表中最多只有一个主键索引，当然主键索引可以包含多个字段。

全文索引：对字段类型有要求，只有数据类型为CHAR、TEXT等才可以建立全文索引。

**按物理实现划分，索引分为两大类：**

聚集索引：

- 表中数据行按索引的排序方式进行存储，B+树的叶子节点就是完整的数据行，查找的时候，找到了主键也就找到了完整的数据行。
- 优点是查询快，如果要查询完整数据行，使用非聚集索引往往需要回表，而使用聚集索引则能一步到位。
- 缺点是聚集索引在插入时，如果是非自增主键，插入效率就会比较低。

非聚集索引：

- 对于非聚集索引，数据库会有单独的存储空间来存放。非聚集索引在查找时第一次搜索B+树拿到主键值后再去搜索聚集索引的B+树，也就是有个回表的过程。
- 使用聚集索引的时候，数据的查询效率高，但如果对数据进行插入，删除，更新等操作，效率会比非聚集索引低。



**覆盖索引：**

1. 一个查询语句的执行结果只用从索引中就可以获得，不必再去数据表中读取
2. 减少回表查询次数

**回表查询：**因为非聚簇索引的叶子节点保存的主键值，当查到索引对应的主键后，可能还需要再到表中查询记录值

**联合索引：**

多个普通字段组合在一起创建的索引就叫做联合索引。

==联合索引的最左匹配原则是指联合索引的最左前缀原则，只要查询的是联合索引的最左 N 个字段，就可以利用该联合索引来加速查询==。不按照最左匹配来为什么失效，其原因就在于联合索引的 B+ 树中的键值是排好序的。

在创建联合索引的时候，如何安排索引内的字段顺序：

第一，优先选择使用频率高的字段放在索引的更左列。

第二，考虑空间开销











#### Q：SQL语句及索引的优化

（1）读取适当的记录limit M, N，而不要读取多余的记录

```sql
select id,name from t limit 866613, 20
```

当做分页时，随着表数据量的增强，直接使用`limit m, n`分页查询会越来越慢，这是因为MySQL 并非是跳过偏移量直接去取后面的数据，而是先把偏移量+要取的条数，然后再把前面偏移量这一段的数据抛弃掉再返回的。

优化方法：可以取前一页的最大行数的id，根据这个id来限制下一页的起点。或者是直接根据索引字段定位后，才取出相应内容，效率自然大大提升。

```sql
//方案一 ：返回上次查询的最大记录(偏移量)
select id,name from product where id > 866613 limit 20
//方案二：order by + 索引
select id,name from product order by id  limit 10000，10
//方案三：在业务允许的情况下限制页数
```

（2）只返回必要的列，用具体的字段列表替代`select * `语句

`select * ` 会增加回表的可能性，带来不必要的IO和内存等消耗，并且当有order by操作的时候，有可能会影响排序的效率。

（3）优化Join语句

MySQL在执行Join的时候，会选择一个表把他要返回以及需要和其他表进行比较的数据放入`join_buffer` ，然后让这些数据依次去和被驱动表做匹配，所以实践中，需要尽可能减少循环次数的优化方式是，用小结果集驱动大结果集，尽量减少join语句中的Nested Loop的循环总次数。另一个是在被驱动表的join字段上建立索引，无法建立索引则设置足够的Join Buffer Size。





#### Q：数据库三范式

一范式：属性（对应于表中的字段）不能再被分割。

二范式：消除了非主属性对于码的部分函数依赖。

三范式：消除了非主属性对于码的传递函数依赖。

一些重要的概念：

- 函数依赖（functional dependency） ：若在一张表中，在属性（或属性组）X 的值确定的情况下，必定能确定属性 Y 的值，那么就可以说 Y 函数依赖于 X，写作 X → Y。
- 部分函数依赖（partial functional dependency） ：如果 X→Y，并且存在 X 的一个真子集 X0，使得 X0→Y，则称 Y 对 X 部分函数依赖。比如学生基本信息表 R 中（学号，身份证号，姓名）当然学号属性取值是唯一的，在 R 关系中，（学号，身份证号）->（姓名），（学号）->（姓名），（身份证号）->（姓名）；所以姓名部分函数依赖与（学号，身份证号）；
- 完全函数依赖(Full functional dependency) ：在一个关系中，若某个非主属性数据项依赖于全部关键字称之为完全函数依赖。比如学生基本信息表 R（学号，班级，姓名）假设不同的班级学号有相同的，班级内学号不能相同，在 R 关系中，（学号，班级）->（姓名），但是（学号）->(姓名)不成立，（班级）->(姓名)不成立，所以姓名完全函数依赖与（学号，班级）；
- 传递函数依赖 ： 在关系模式 R(U)中，设 X，Y，Z 是 U 的不同的属性子集，如果 X 确定 Y、Y 确定 Z，且有 X 不包含 Y，Y 不确定 X，（X∪Y）∩Z=空集合，则称 Z 传递函数依赖(transitive functional dependency) 于 X。传递函数依赖会导致数据冗余和异常。传递函数依赖的 Y 和 Z 子集往往同属于某一个事物，因此可将其合并放到一个表中。比如在关系 R(学号 ,姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖。



#### Q：存储引擎

InnoDB 和MyISAM，默认搜索引擎是InnoDB

1. InnoDB支持事务，而MyISAM不支持事务
2. InnoDB最小的锁粒度是行锁，而MyISAM最小的锁粒度是表锁。
3. InnoDB采用聚簇索引，而MyISAM是非聚簇索引。也就是说InnoDB的B+树主键索引的叶子节点就是数据文件，辅助索引的叶子节点是主键的值；而MyISAM的B+树主键索引和辅助索引的叶子节点都是数据文件的地址指针。
4. InnoDB支持外键，而MyISAM不支持外键

为什么选择B+树作为索引数据结构？

因为Hash索引底层是哈希表，==哈希表是一种以key-value存储数据的结构==，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。所以，哈希索引只适用于等值查询的场景。其次哈希索引不支持多列联合索引的最左匹配规则和模糊查询，并且存在哈希碰撞的问题，影响效率。

二叉查找树，比如红黑树，红黑树是二叉树搜索树的变种，一个Node节点只能存储一个key和一个Value。

而B树是一种多路平衡查找树，它的每一个节点最多包含m个孩子，m被称为B树的阶。m的大小取决于磁盘页的大小。B树的定义如下：

- 每个节点最多有m-1个关键字（可以存有的键值对）。
- 根节点最少可以只有1个关键字。 非根节点至少有m/2个关键字。
- 每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有
- 关键字都小于它，而右子树中的所有关键字都大于它。
- 所有叶子节点都位于同一层，或者说根节点到每个叶子节点的长度都相同。

MySQL的数据是存储在硬盘的，在查询时一般是不能「一次性」把全部数据加载到内存中。



B和B+树是多路搜索树，相较于与红黑树而言。一个Node节点可以存储的信息会更多，「多路搜索树」的高度会比「二叉搜索树」更低。

B+树相对于B树而言，它又有两种特性。

- B+树非叶子节点不存储数据，在相同的数据量下，B+树更加矮壮。（这个应该不用多解释了，数据都存储在叶子节点上，非叶子节点的存储能存储更多的索引，所以整棵树就更加矮壮）

- B+树叶子节点之间组成一个链表，方便于遍历查询（遍历操作在MySQL中比较常见）

> B+树是多路搜索树，树的层级更低；只有叶子节点存储数据会更矮；叶子节点具有双向链表，便于遍历数据。

参考文章：[面试官问我MySQL索引](https://juejin.cn/post/7003527396427038733)







#### Q：MySQL组成部分和查询语句执行过程

把 MySQL 分成三层，跟客户端对接的连接层，真正执行操作的服务层，和跟硬件打交道的存储引擎层。

- 连接层：我们的客户端要连接到 MySQL 服务器 3306 端口，必须要跟服务端建立连接，那么管理所有的连接，验证客户端的身份和权限，这些功能就在连接层完成。

- 服务层：连接层会把 SQL 语句交给服务层，这里面又包含一系列的流程：

  比如查询缓存的判断、根据 SQL 调用相应的接口，对我们的 SQL 语句进行词法和语法的解析（比如关键字怎么识别，别名怎么识别，语法有没有错误等等）。

  然后就是优化器，MySQL 底层会根据一定的规则对我们的 SQL 语句进行优化，最后再交给执行器去执行。

- 存储引擎：存储引擎就是我们的数据真正存放的地方，在 MySQL 里面支持不同的存储引擎。再往下就是内存或者磁盘。

SQL的执行流程：

通过连接器查询当前执行者的角色是否有权限，进行查询。如果有的话，就继续往下走，如果没有的话，就会被拒绝掉，同时报出 `Access denied for user` 的错误信息；

接下来就是去查询缓存，首先看缓存里面有没有，如果有呢，那就没有必要向下走，直接返回给客户端结果就可以了；如果缓存中没有的话，那就去执行语法解析器和预处理模块。（ MySQL 8.0 版本直接将查询缓存的整块功能都给删掉了）

语法解析器和预处理主要是分析sql语句的词法和语法是否正确，没啥问题就会进行下一步，来到查询优化器；

查询优化器就会对sql语句进行一些优化，看哪种方式是最节省开销，就会执行哪种sql语句

优化器决定选择哪个方案之后，执行引擎就去执行了。然后返回给客户端结果。





#### Q：优化

**失效场景：**

1. 不满足联合索引的最左前缀原则
2. 索引字段做运算，比如substring(字段)
3. 以%开头的like左模糊查询
4. 用or分割开的条件，一边有索引一边没索引，那么都会走全表
5. 关联表的两个字段类型不一致会发生隐式转换
6. 避免使用select *，减少表结构改变带来的影响；无法使用覆盖索引

**慢SQL排查：**

（1）MySQL慢查询日志

```sql
-- 查看慢查询日志是否开启
show variables like '%slow_query_log%';
-- 开启慢查询日志，只对当前数据库生效，并且重启数据库后失效
set global slow_query_log = 1;
-- 设置阈值,默认10s
set long_query_time = 3;
```

（2）日志分析工具mysqldumpslow

mysqldumpslow能将相同的慢SQL归类，并统计出相同的SQL执行的次数，每次执行耗时多久、总耗时，每次返回的行数、总行数，以及客户端连接信息等

（3）expain

- type：表示表的连接类型，一般至少要达到range级别，最好达到ref （非唯一性索引扫描）。
- key：表示查询时，实际使用的索引
- ref：显示索引的哪一列被使用了，如果可能的话，是一个常数
- rows：扫描行数
- extra：执行情况的说明和描述
  - using filesort：在索引之外，需要额外进行外部的排序动作；一般是order&nbsp;by有关
  - using index：查询使用了覆盖索引，无需回表
  - using index condition：使用了索引下推
  - using where：没用索引，需要全表扫描，再按where过滤



**小表驱动大表：**

通过对比 in 和 exists 关键字，在多表联合查询时，如果用 in 关键字查询的话，先先部门再医生表，一般来说部门表的数据是要小于医生表的数据的，所以这就是小表驱动大表，效率比较高。

在 MySQL 中，这种多表联合查询的原理是：以驱动表的数据为基础，通过类似于我们 Java 代码中写的`嵌套循环` 的方式去跟被驱动表记录进行匹配。**搜索被驱动的表的时候，一般都是有索引的，而索引的搜索就要快很多，搜索次数也少。**



**分库分表：**

- 水平分库：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。
- 水平分表：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。
- 垂直分库：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。
- 垂直分表：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。



**索引下推：**

**ICP（Index Condition Pushdown）**，不支持ICP之前，当进行索引查询时，首先根据索引来查找数据，然后再根据where条件来过滤，扫描了大量不必要的数据，增加了数据库IO操作。

在支持ICP后，MySQL在取出索引数据的同时，判断是否可以进行where条件过滤，将where的部分过滤操作放在存储引擎层提前过滤掉不必要的数据，减少了不必要数据被扫描带来的IO开销。

在某些查询下，可以减少Server层对存储引擎层数据的读取，从而提供数据库的整体性能。



#### Q：日志

（1）binlog

binlog是一种逻辑日志，用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。

MySQL的主从复制主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。

- binlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。
- I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。
- SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。

（2）redolog

一种物理日志，记录数据页（16KB）的物理修改，用于崩溃重启后，恢复到最后一次事务提交的位置。

redolog分两部分，一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。

当数据变化时，先写入redo log buffer，当到了持久化时机就会刷盘到redolog file，保证持久化。

（3）undolog

用于记录数据的逻辑变化，用于发生错误时回滚。保证事务的原子性，也是先写缓存在写磁盘。

> 补充点：
>
> Buffer Pool：缓存索引和表数据，以避免每一次操作都要进行磁盘IO，提高访问速度
>
> change buffer：当修改数据库数据时，把更改记录先写道内存中，等到将来数据被读取时，再将内存中的数据合并到buffer pool，满足条件后刷新回磁盘。
>
> WAL （Write-Ahead Logging）：在操作buffer pool和change buffer前，先把记录写到redo log日志，然后再去更新buffer pool 或 change buffer。
>
> redo log 是顺序IO，而写数据涉及到随机IO，写数据需要寻址定位，然后在处理，而写redo log则是在一个固定的位置循环写入，是顺序IO，所以速度要高于写数据



#### Q：事务

**（1）事务的定义**

事务可以使逻辑上的一组操作，要么都执行，要么都不执行，保证数据最终的一致性。

**（2）四大特性**

1. 原子性：事务的最小工作单元，要么同时成功，要么同时失败
2. 隔离性：在事务并发执行时，他们内部的操作互不干扰
3. 持久性：一旦提交了事务，数据是永久记录的
4. 一致性：事务的目的，执行事务前后，数据保持一致

**（3）并发事务带来的问题**

1. 脏读：指一个事务读取到了另一个事务未提交的数据
2. 丢失修改：指两个事务同时读取一个数据然后做了修改，其中一个事务的修改结果丢失了。
3. 不可重复读：在一个事务开启过程中，一个事务受到另一个事务已提交事务修改的影响，导致两次读取的数据不一样。
4. 幻读：在事务开启过程中，一个事务受到另一个已提交事务修改的影响，导致两次读取的数据条目不一样。

**（4）隔离级别**

读未提交：如果一个事务读到了另一个事务修改但未提交的数据，即是读未提交。存在脏读、不可重复读、幻读的问题。

读已提交：如果一个事务只能读取到另一个已提交事务的修改过的数据，并且每次都是最新值，即是读已提交。存在不可重复读、幻读的问题。

可重复读：一个事务在开启期间，对于同一字段数据每次读取结果是一致的，且期间其他事务修改了该记录的值也不受影响，即是可重复读。存在幻读的情况。

可串行化：最高级别，对于同一行记录，“写”会加“写锁”，“读”会加“读锁”，当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。



#### Q：MVCC

MVCC(Mutil-Version Concurrency Control)，就是多版本并发控制。MVCC 是一种并发控制的方法。

它指在使用`读已提交（READ COMMITTD）、可重复读（REPEATABLE READ）`这两种隔离级别的事务在执行普通的SELECT操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。

**版本链**

对于使用InnoDB存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列（`row_id`并不是必要的，我们创建的表中有主键或者非NULL唯一键时都不会包含`row_id`列）：

- `trx_id` ：事务ID，记录创建这条记录/最后一次修改该记录的事务ID；

- `roll_pointer` ：回滚指针，指向这条记录的上一个版本。

每次对记录进行改动，都会记录一条`undo日志`，每条`undo日志`也都有一个`roll_pointer`属性（`INSERT`操作对应的`undo日志`没有该属性，因为该记录并没有更早的版本），可以将这些`undo日志`都连起来，串成一个链表。

对该记录每次更新后，都会将旧值放到一条`undo日志`中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被`roll_pointer`属性连接成一个链表，我们把这个链表称之为`版本链`，版本链的头节点就是当前记录最新的值。

<img src="C:/Users/Lenovo/Desktop/笔记/CS-Learning-Notes/notes/pics/a7fad862d80f184f1f117d93cd9090ba.png" alt="img" style="zoom:50%;" />

**Read View（读视图）**

`Read View`是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，**记录并维护系统当前活跃事务的ID**(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大)

对于使用`READ UNCOMMITTED`隔离级别的事务来说，直接读取记录的最新版本就好了，对于使用`SERIALIZABLE`隔离级别的事务来说，使用加锁的方式来访问记录。对于使用`READ COMMITTED`和`REPEATABLE READ`隔离级别的事务来说，就需要用到我们上边所说的`版本链`了，核心问题就是：需要判断一下版本链中的哪个版本是当前事务可见的。所以设计`InnoDB`的大叔提出了一个`ReadView`的概念，这个`ReadView`中主要包含当前系统中还有哪些活跃的读写事务，把它们的事务id放到一个列表中，我们把这个列表命名为为`m_ids`。这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见：

- 如果被访问版本的`trx_id`属性值小于`m_ids`列表中最小的事务id，表明生成该版本的事务在生成`ReadView`前已经提交，所以该版本可以被当前事务访问。
- 如果被访问版本的`trx_id`属性值大于`m_ids`列表中最大的事务id，表明生成该版本的事务在生成`ReadView`后才生成，所以该版本不可以被当前事务访问。
- 如果被访问版本的`trx_id`属性值在`m_ids`列表中最大的事务id和最小事务id之间，那就需要判断一下`trx_id`属性值是不是在`m_ids`列表中，如果在，说明创建`ReadView`时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建`ReadView`时生成该版本的事务已经被提交，该版本可以被访问。

如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本，如果最后一个版本也不可见的话，那么就意味着该条记录对该事务不可见，查询结果就不包含该记录。

在`MySQL`中，`READ COMMITTED`和`REPEATABLE READ`隔离级别的的一个非常大的区别就是它们生成`ReadView`的时机不同。

- `READ COMMITTED` --- 每次读取数据前都生成一个ReadView
- `REPEATABLE READ` --- 只在第一次读取数据时生成一个ReadView



#### Q：MySQL锁机制

（1）**Record Lock**

Record Lock，也叫记录锁，是加在索引记录上的锁。即使表没有定义索引，InnoDB也会创建一个隐藏的聚集索引，并使用这个索引来锁定记录。

（2）**Gap Lock**

Gap Lock，也叫间隙锁，在索引记录之间的间隙上的锁，或者在第一个索引记录之前或最后一个索引记录之后的间隙上的锁。

**Gap指的是InnoDB的索引数据结构中可以插入新值的位置。**间隙锁只有在Repeatable Reads这种隔离级别中才会起作用。

在Repeatable Read这种隔离下，对于锁定的读操作（select … for update 、 lock in share mode)、update操作、delete操作时，会进行如下的加锁：

- 对于具有唯一搜索条件的唯一索引，InnoDB只锁定找到的索引记录，而不会锁定间隙。
- 对于其他搜索条件，InnoDB锁定扫描的索引范围，使用gap lock或next-key lock来阻塞其他事务插入范围覆盖的间隙。

**也就是说，对于SELECT FOR UPDATE、LOCK IN SHARE MODE、UPDATE和DELETE等语句处理时，除了对唯一索引的唯一搜索外都会获取gap锁或next-key锁，即锁住其扫描的范围。**

（3）Next-key Lock

Next-Key锁是索引记录上的记录锁和索引记录之前间隙上的间隙锁的组合。Next-Key 的锁的范围都是左开右闭的。Next-Key Lock和Gap Lock一样，只有在InnoDB的RR隔离级别中才会生效。



**InnoDB中的Repeatable Reads是通过next-key lock解决了RR的幻读问题的**。

因为有了next-key lock，所以在需要加行锁的时候，会同时在索引的间隙中加锁，这就使得其他事务无法在这些间隙中插入记录，这就解决了幻读的问题。



MySQL加锁的原则：

原则 1：加锁的基本单位是 next-key lock。是一个前开后闭区间。

原则 2：查找过程中访问到的对象才会加锁。

优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。

优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。

一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

参考文章：[数据库的锁](https://mp.weixin.qq.com/s?__biz=MzI3NzE0NjcwMg==&mid=2650167577&idx=1&sn=50145801b11de3dae37e5eabbc1205e2&chksm=f3684438c41fcd2e9a248aa464ee589689469a22009af0f69e57063a8db796be46b6aecf008e&scene=21#wechat_redirect)





#### Q：当前读和快照读

（1）快照读：就是单纯的 SELECT 语句，执行方式是生成 ReadView，直接利用 MVCC 机制来进行读取，并不会对记录进行加锁。

（2）当前读：读取的是最新版本，并且需要先获取对应记录的锁，如以下这些 SQL 类型：

select ... lock in share mode 、

select ... for update、

update 、delete 、insert

要 update 一条记录，在事务执行过程中，如果不加锁，那么另一个事务可以 delete 这条数据并且能成功 commit，就会产生冲突了。所以 update 的时候肯定要是当前读，得到最新的信息并且锁定相应的记录。

当前读是通过 next-key 锁(行记录锁+间隙锁)来是实现的。

Innodb支持三种行锁定方式

**行锁**：锁的是索引，如果SQL没有走索引，那么会全表扫描，从而升级为表锁

**Gap锁（间隙锁）**：当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时（增删改查操作，Mysql会默认加锁），InnoDB会给符合条件的已有数据记录的索引项加行锁。对于键值在条件范围内但并不存在的记录加上间隙锁。Innodb 为了解决幻读问题时引入的锁机制，所以只有在 Read Repeatable 、Serializable 隔离级别才有。要取消间隙锁的话，切换隔离级别为读已提交即可。

**Next-Key Lock**：行锁与间隙锁组合起来用就叫做Next-Key Lock。



#### Q：MySQL数据cpu飙升故障排查

排查过程：

（1）使用top 命令观察，确定是mysqld导致还是其他原因

（2）如果是mysqld导致的，show processlist，查看session情况，确定是不是有消耗资源的sql在运行

（3）找出消耗高的sql，看看执行计划是否准确，索引是否缺失，数据量是否太大。

处理过程：

（1）kill 掉这些线程观察cpu使用率是否下降

（2）进行相应的调整，如加索引、改sql、改内存参数等

（3）重新跑这些sql。



#### Q：主从同步延迟解决方案

主从同步延迟的原因：

一个服务器开放N个链接给客户端来连接的，这样会有大并发的更新操作，但是从服务器读取binlog的线程仅有一个，当某个SQL在从服务器上执行的时间稍长 或者由于某个SQL要进行锁表就会导致，主服务器的SQL大量积压，未被同步到从服务器里。这就导致了主从不一致，也就是主从延迟。

解决方法：

1. 主服务器要负责更新操作，对安全性的要求比从服务器要高，所以有些设置参数可以修改，比如sync_binlog=1，innodb_flush_log_at_trx_commit = 1 之类的设置等。
2. 选择更好的硬件设备作为slave。
3. 把一台从服务器当度作为备份使用， 而不提供查询， 那边他的负载下来了， 执行relay log 里面的SQL效率自然就高了。
4. 增加从服务器喽，这个目的还是分散读的压力，从而降低服务器负载。



#### Q：MySQL数据量过大的优化方案

**单表优化**：MySQL中几百万甚至小几千万的表优先考虑单表优化

（1）表分区

MySQL在5.1后出现的，可以看作是水平拆分，分区表需要在建表的时候加上分区参数。分区表底层由多个物理子表组成，但是对于代码来说，分区表是透明的；分区类型有Range、hash、list、key分区。

```sql
// 可以使用ALTER TABLE来进行更改表为分区表
// 会创建一个分区表，然后自动进行数据copy然后删除原表
ALTER TABLE tbl_rtdata PARTITION BY RANGE (Month(fld_date))
(   
PARTITION p_Apr VALUES LESS THAN (TO_DAYS('2012-05-01')),
PARTITION p_May VALUES LESS THAN (TO_DAYS('2012-06-01')), 
PARTITION p_Dec VALUES LESS THAN MAXVALUE );
```

（2）增加缓存

主要思想是减少对数据库的访问，常用的是Redis。

（3）字段设计

单表不要有太多的字段，VarChar长度尽可能分配真正需要的空间，尽量使用TIMESTAMP而非DATETIME；

（4）索引优化

尽量使用索引，也要保证不要因为错误的写法导致索引失效。

索引不是越多越好，针对性地建立索引，索引会加速查询，但是对新增、修改、删除会造成一定的影响；

值域很少的字段不适合建索引；

尽量不用UNIQUE，不要设置外键，由程序保证；

（5）NoSQL



**表拆分**：数据量进一步增大的时候，就不得不考虑表拆分的问题了

（1）垂直拆分

将字段较多的表拆分成多个字段较少的表，一般单表字段最好不要超过二三十个。

（2）水平拆分

也就是常说的分库分表了；分表，解决了单表数据过大的问题，但是毕竟还在同一台数据库服务器上，所以IO、CPU、网络方面的压力，并不会得到彻底的缓解，这个可以通过分库来解决。

水平拆分优点很明显，可以利用多台数据库服务器的资源，提高了系统的负载能力；缺点是逻辑会变得复杂，跨节点的数据关联性能差，维护难度大（特别是扩容的时候）。





#### Q：SQL注入

SQL注入是指未经检查或者未经充分检查的用户输入数据，意外变成了代码被执行。

避免方法的核心思想就是不相信用户的输入。

1. 代码层防止sql注入攻击的最佳方案就是sql预编译（sql模板化或者说参数化）

   ```sql
   select*from tablename where username=? and password=?
   ```

   参数化能防注入的原因在于，语句是语句，参数是参数，参数的值并不是语句的一部分，数据库只按语句的语义跑

2. 数据类型检查、关键字过滤





## Java知识

### Java基础

#### Q：面向对象大三特征

封装可以隐藏实现细节，使得代码模块化；继承可以扩展已存在的代码模块（类）；它们的目的都是为了——代码重用。而多态则是为了实现另一个目的——接口重用



#### Q：内部静态类



#### Q：== 和equals() 的区别

`==` 对于基本类型和引用类型的作用效果是不同的：

- 对于基本数据类型来说，`==` 比较的是值。
- 对于引用数据类型来说，`==` 比较的是对象的内存地址。

`equals()` 不能用于判断基本数据类型的变量，只能用来判断两个对象是否相等。



#### Q：为何重写equals() 时必须重写 Hashcode()

首先两个对象的`hashcode`值相等并且`equal()` 方法返回true，我们才认为两个对象相等，如果只是`hashcode`值相等，那有可能是哈希碰撞的原因。

如果重写 `equals()` 时没有重写 `hashCode()` 方法的话就可能会导致 `equals` 方法判断是相等的两个对象，`hashCode` 值却不相等。



#### Q：String、StringBuffer、StringBuider的区别

String 被final 修饰且没有提供修改字符串的方法

StringBuider 适用于单线程，线程不安全

StringBuffer 对方法加了同步锁，在并发情况下也是线程安全的



#### Q：泛型

泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。

Java 的泛型是伪泛型，这是因为 Java 在运行期间，所有的泛型信息都会被擦掉，这也就是通常所说类型擦除 。

泛型一般有三种使用方式: 泛型类、泛型接口、泛型方法。

**泛型擦除**是指Java在运行时，不会保留泛型。Java泛型只存在存在于源码里，编译时会检查一下泛型类型是否正确，而到了运行时就不检查了。



#### Q：反射

反射拥有以下四大功能：

- 在运行时（动态编译）获知任意一个对象所属的类。
- 在运行时构造任意一个类的对象。
- 在运行时获知任意一个类所具有的成员变量和方法。
- 在运行时调用任意一个对象的方法和属性。

这种动态获取信息、动态调用对象的方法的功能就称为 Java 语言的反射机制。



然后反射的具体原理：

在通常情况下，一定是先有类然后再 new 一个对象出来的对吧，类的正常加载过程是这样的：

首先 JVM 会将我们的代码编译成一个 `.class` 字节码文件，然后被类加载器（ClassLoader）加载进 JVM 的内存中，同时会创建这个类的 `Class` 对象存到堆中（注意这个不是 new 出来的对象，而是类的类型对象）。JVM 在创建这个类对象前，会先检查其类是否加载，寻找类对应的 `Class` 对象，若加载好，则为其分配内存，然后再进行初始化 `new` 操作。

OK，那么在加载完一个类后，堆内存的方法区就产生了一个 `Class` 对象，并且包含了这个类的完整结构信息，我们可以通过这个 `Class` 对象看到类的结构，就好比一面镜子。所以我们形象的称之为：反射。

说的再详细点，在通常情况下，一定是先有类再有对象，我们把这个通常情况称为 “正”。那么反射中的这个 “反” 我们就可以理解为根据对象找到对象所属的类（对象的出处）

通过反射，也就是调用了 `getClass()` 方法后，我们就获得了这个类类对应的 `Class` 对象，看到了这个类的结构，输出了类对象所属的类的完整名称，即找到了对象的出处。当然，获取 `Class` 对象的方式除了调用 `getClass()` 外还有另外三种方法

反射的优点就是比较灵活，能够在运行时动态获取类的实例。

不过反射也存在很明显的缺点：

1）性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的 Java 代码要慢很多。

2）安全问题：反射机制破坏了封装性，因为通过反射可以获取并调用类的私有方法和字段。

反射在我们实际编程中其实并不会直接大量的使用，但是实际上有很多设计都与反射机制有关，比如：

- 动态代理机制
- 使用 JDBC 连接数据库
- Spring / Hibernate 框架（实际上是因为使用了动态代理，所以才和反射机制有关，这个地方可以酌情扩展）

参考文章：https://mp.weixin.qq.com/s/rubfY4Ku3_p-PDpoWvAO8Q



作用：Java的反射是指程序在运行期可以拿到一个对象的所有信息，解决在运行期，对某个实例一无所知的情况下，如何调用其方法。

原理：JVM为每个加载的`class`及`interface`创建了对应的`Class`实例来保存`class`及`interface`的所有信息；获取一个`class`对应的`Class`实例后，就可以获取该`class`的所有信息；获取`class` 的`Class` 实例的方法主要有：

1. 直接通过一个`class`的静态变量`class`获取
2. 如果我们有一个实例变量，可以通过该实例变量提供的`getClass()`方法获取
3. 如果知道一个`class`的完整类名，可以通过静态方法`Class.forName()`获取

优缺点：反射的优点就是比较灵活，能够在运行时动态获取类的实例。不过反射也存在很明显的缺点：

1. 性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的 Java 代码要慢很多。
2. 安全问题：反射机制破坏了封装性，因为通过反射可以获取并调用类的私有方法和字段。

适用场景有动态代理机制等。



#### Q：异常

主要分成：

1.编译错误（语法错误）；

2.运行时错误（运行时发现不能执行的错误）；

3.逻辑错误（没有按照预期的逻辑顺序执行）

Throwable

1. Error（虚拟机错误）
2. Exception
   - RuntimeException（运行时异常）eg.空指针、类型转换不兼容
   - IOException（I/O错误）需要try..catch捕获异常，eg.找不到文件等



#### Q：处理异常的原则

1. 如果你不能处理异常，不要捕获该异常
2. 如果要捕获，应在离异常源近的地方捕获它
3. 不要吞没你捕获的异常
4. 除非你要重新抛出异常，否则把它log起来
5. 用自定义的异常类，不要每次需要抛出异常的时候都抛出java.lang.Exception。方法的调用者可以通过throws知道有哪些异常需要处理--所以它是自我描述的





#### Q：注解

（1）类型

- 由编译器使用的注解，比如 @Override、@SupperssWarnings；这类注解不会被编译进入.class文件，在编译后会被扔掉
- 由工具处理.class文件使用的注解，在加载class时对其动态修改，不存在于内存，底层库使用
- 程序运行期能够读到的注解，存在于JVM中

（2）配置参数

所有的基本类型；String;枚举类型；前面的数组

（3）元注解

- @Target：定义注解被应用于源码的哪些位置
- @Retention：定义了注解的生命周期
  - 仅源文件 source
  - 仅编译期 class
  - 运行期 runtime

- @Repeatable：定义注解是否可重复
- @Inherited：定义子类是否可以继承父类定义的注解

（4）处理注解

- 通过反射判断某个注解是否存在：Class.isAnnotationPresent(注解Class)

- 通过反射API读取注解：Class.getAnnotation(注解Class) 返回注解实例



#### Q：sleep(）方法与wait()方法的区别

两者都是可以让线程停止执行的方法，不同点在于：

1. 原理：sleep是Thread类的静态方法，由线程来控制自身流程的，时间到了会自动唤醒；wait() 是Object类的方法，用于线程之间的通信，需要notify() 或者指定一个时间醒来。
2. 对锁处理机制不同：sleep 不涉及线程通信，调用期间不会释放锁，可能导致死锁；而wait() 方法会释放锁。
3. sleep 必须捕获异常，而wait 不用。



#### Q：抽象类和接口的区别

1. 抽象类要被子类继承，接口要被类实现
2. 接口只能做方法声明，抽象类即可做方法声明，也可做方法实现
3. 接口里定义的只能是公共的静态的常量，抽象类中的变量可以是普通变量
4. 接口是设计的结果，抽象功能，抽象类是重构的结果，抽象类别



#### Q：Serializable接口为何需要定义serialVersionUID常量

serialVersionUID是序列化版本，为一个类定义序列化版本，是出于**兼容性**的考虑。如果某个类随着项目进行了升级，那么对于升级之前序列化的数据，在升级之后反序列化时就很可能出现不兼容的情况。如果事先定义了序列化的版本，则在反序列化的时候，只要版本不变就可以将其认定为同一个class文件。

如果类的修改会导致反序列化失败，则应该为此类分配新的serialVersionUID，那么对类的哪些内容进行修改会导致反序列化失败呢？

1.  如果修改类时只是修改了方法，则反序列化不受影响。
2.  如果修改类时只是修改了静态变量，则反序列化不受影响。
3.  如果修改类时改变了实例变量，则可能导致反序列化失败。



#### Q：创建线程的方式

创建线程有三种方式，分别是继承Thread类、实现Runnable接口、实现Callable接口。

1. 通过继承Thread类来创建线程的步骤如下：

   - 定义Thread类的子类，并重写该类的run()方法，该方法将作为线程执行体。
   - 创建Thread子类的实例，即创建了线程对象。
   - 调用线程对象的start()方法来启动该线程。

2. 通过实现Runnable接口来创建线程的步骤如下：

   - 定义Runnable接口的实现类，并实现该接口的run()方法，该方法将作为线程执行体。

   - 创建Runnable实现类的实例，并将其作为参数来创建Thread对象，Thread对象为线程对象。

   - 调用线程对象的start()方法来启动该线程。

3. 通过实现Callable接口来创建线程的步骤如下：

   - 定义Callable接口的实现类，并实现call()方法，该方法将作为线程执行体。

   - 创建Callable实现类的实例，并以该实例作为参数，创建FutureTask对象。

   - 使用FutureTask对象作为参数，创建Thread对象，然后启动线程。

   - 调用FutureTask对象的get()方法，获得子线程执行结束后的返回值。

     

#### Q：Java中的IO流

流是Java对不同输入源输出源的抽象，代表了从起源到接收的有序数据，有了它程序就可以采用统一的方式来访问不同的输入源和输出源了。

按照数据的流向，可以将流分为输入流和输出流。其中，输入流只能读取数据、不能写入数据，而输出流只能写入数据、不能读取数据。

按照数据的类型，可以将流分为字节流和字符流。其中，字节流操作的数据单元是byte（8位的字节），而字符流操作的数据单元是char（16位的字符）。

 按照使用的场景，可以将流分为节点流和处理流。其中，节点流可以直接从/向一个特定的IO设备读/写数据，也称为低级流。而处理流则是对节点流的连接或封装，用于简化数据读/写功能或提高效率，也成为高级流。

 **Java中的IO流主要有4个基类：InputStream、OutputStream、Reader、Writer。其中，InputStream代表字节输入流，OutputStream代表字节输出流，Reader代表字符输入流，Writer代表字符输出流。**其他的IO流都是从这4个基类派生而来的，并且子类的名字往往以基类的名字结尾，所以通过类名我们很容易识别某个流的作用。

  Java为我们提供了大量的IO流实现，我们没办法逐个介绍，下面举一些较为常用的例子：

1. 用于访问文件的FileInputStream、FileOutputStream、FileReader、FileWriter。
2. 带有缓冲功能的BufferedInputStream、BufferedOutputStream、BufferedReader、BufferedWriter。
3. 具有转换功能的InputStreamReader、OutputStreamWriter。
4. 支持打印功能的PrintStream、PrintWriter。





### Java集合

#### Q：Collection 的划分、List、Set、Map的区别

首先介绍 `Collection` 接口下的容器：

（1）List

- `ArrayList`：`Object[]` 数组
- `Vector`：`Object[]` 数组
- `LinkedList`：双向链表

（2）Set

- `HashSet`（无序，唯一）：基于`HashMap` 实现的，底层采用 `HashMap` 来保存元素
- `LinkedHashSet`：`LinkedHashSet` 是 `HashSet` 的子类，并且其内部是通过 `LinkedHashMap` 来实现的。
- `TreeSet`(有序，唯一)：红黑树

（3）Queue

- `PriorityQueue`：`Object[]` 数组来实现二叉堆
- `ArrayQueue`：`Object[]` 数组 + 双指针

接下是 `Map` 接口下的容器：

- `HashMap`： JDK1.8 之前 `HashMap` 由数组+链表组成的，数组是 `HashMap` 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间
- `LinkedHashMap`： `LinkedHashMap` 继承自 `HashMap`，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，`LinkedHashMap` 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。
- `Hashtable`： 数组+链表组成的，数组是 `Hashtable` 的主体，链表则是主要为了解决哈希冲突而存在的
- `TreeMap`： 红黑树（自平衡的排序二叉树）



#### Q：ArrayList

**ArrayList 和 LinkedList的区别：**

首先来讲讲 `ArrayList` 和 `Vector` 两者都是 `List` 的实现类，且底层使用 `Object[]` 存储，区别在于 `ArrayList` 查找高效却线程不安全，而 `Vector` 支持线程的同步故是线程安全，当然效率相对较低。

接着比较一下 `ArrayList` 和 `LinkedList` ，主要从以下方面来看：

1. 是否保证线程安全：两者都是线程不同步的，也即是不保证线程安全；
2. 底层数据结构：`ArrayList` 底层适用 `Object[]` 数组，而 `LinkedList` 则是双向链表；
3. 查找、插入和删除是否受元素位置的影响：`ArrayList` 支持随机元素访问，但是`LinkedList` 的首尾插入和删除高效。
4. 内存空间占用：`ArrayList` 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素需要保存索消耗空间。

可见两者的区别主要是取绝于底层数据结构的特性

**ArrayList的扩容：**

有参构造时，直接创建对应大小的数组空间

无参时，初始化是空数组，添加第一个元素时，扩容为10

当前容量小于所需容量时，复制的方式扩容至当前容量的1.5倍；





#### Q：HashMap

HashMap 就是以 Key-Value 的方式进行数据存储的一种数据结构嘛，在我们平常开发中非常常用，它在 JDK 1.7 和 JDK 1.8 中底层数据结构是有些不一样的。总体来说，JDK 1.7 中 HashMap 的底层数据结构是数组 + 链表，使用 `Entry` 类存储 Key 和 Value；JDK 1.8 中 HashMap 的底层数据结构是数组 + 链表/红黑树，使用 `Node` 类存储 Key 和 Value。

每一个节点都会保存自身的 hash、key 和 value、以及下个节点。

因为 HashMap 本身所有的位置都为 null 嘛，所以在插入元素的时候即 `put` 操作时，会根据 key 的 hash 去计算出一个 index 值，也就是这个元素将要插入的位置。

在有限的数组上使用哈希，那么哈希冲突是不可避免的，HashMap采用**拉链法**。也就是把 hash 后值相同的元素放在同一条链表上。

当然这里还有一个问题，那就是当 Hash 冲突严重时，在数组上形成的链表会变的越来越长，由于链表不支持索引，要想在链表中找一个元素就需要遍历一遍链表，那显然效率是比较低的。为此，JDK 1.8 引入了红黑树，**当链表的长度大于 8 的时候就会转换为红黑树，不过，在转换之前，会先去查看 table 数组的长度是否大于 64，如果数组的长度小于 64，那么 HashMap 会优先选择对数组进行扩容 `resize`，而不是把链表转换成红黑树**。

参考文章：https://mp.weixin.qq.com/s/JuwcUAfvxVQmJdhEBAekUw



**底层数据结构：**

在JDK1.8之前，HashMap的底层是数组+链表结合在一起使用也就是链表散列。

在JDK1.8之后，变成了数组+链表+红黑树。由于数组+链表的形式会产生链表过长的现象，链表过长使得通过key值依次查找的效率变得很低，所以当链表长度大于8并且 HashMap 数组长度超过 64 的时候，链表就会转换为红黑树，加快查询。

**构造函数**

HashMap的构造方法有4种，主要涉及到的参数有，指定初始容量，指定填充比和用来初始化的Map

```java
public class HashMap<k,v> extends AbstractMap<k,v> implements Map<k,v>, Cloneable, Serializable {
    private static final long serialVersionUID = 362498820763181265L;
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16
    static final int MAXIMUM_CAPACITY = 1 << 30;//最大容量
    static final float DEFAULT_LOAD_FACTOR = 0.75f;//填充比
    //当add一个元素到某个位桶，其链表长度达到8时将链表转换为红黑树
    static final int TREEIFY_THRESHOLD = 8;
    static final int UNTREEIFY_THRESHOLD = 6;
    static final int MIN_TREEIFY_CAPACITY = 64;
    transient Node<k,v>[] table;//存储元素的数组
    transient Set<map.entry<k,v>> entrySet;
    transient int size;//存放元素的个数
    transient int modCount;//被修改的次数fast-fail机制
    int threshold;//临界值 当实际大小(容量*填充比)超过临界值时，会进行扩容 
    final float loadFactor;//填充比（......后面略）
}

public HashMap(int initialCapacity, float loadFactor) {
    //指定的初始容量非负
    if (initialCapacity < 0)
        throw new IllegalArgumentException(Illegal initial capacity:  +
                                           initialCapacity);
    //如果指定的初始容量大于最大容量,置为最大容量
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    //填充比为正
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException(Illegal load factor:  +
                                           loadFactor);
    this.loadFactor = loadFactor;
    this.threshold = tableSizeFor(initialCapacity);//新的扩容临界值
}
```

**HashMap get函数**

get(key)方法时，先获取key的hash值，计算hash&(n-1)得到在链表数组中的位置first=tab[hash&(n-1)],先判断first的key是否与参数key相等，不等就遍历后面的链表找到相同的key值返回对应的Value值即可。

```java
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
/**
     * Implements Map.get and related methods
     *
     * @param hash hash for key
     * @param key the key
     * @return the node, or null if none
     */
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab;//Entry对象数组
    Node<K,V> first,e; //在tab数组中经过散列的第一个位置
    int n;
    K k;
    /*找到插入的第一个Node，方法是hash值和n-1相与，tab[(n - 1) & hash]*/
    //也就是说在一条链上的hash值相同的
    if ((tab = table) != null && (n = tab.length) > 0 &&(first = tab[(n - 1) & hash]) != null) {
        /*检查第一个Node是不是要找的Node*/
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))//判断条件是hash值要相同，key值要相同
            return first;
        /*检查first后面的node*/
        if ((e = first.next) != null) {
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            /*遍历后面的链表，找到key值和hash值都相同的Node*/
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
```

**HashMap的put函数**

1、判断键值对数组tab[]是否为空或为null，否则以默认大小resize()；
2，根据键值key计算hash值得到插入的数组索引i，如果tab[i]==null，直接新建节点添加，否则转入3
3，判断当前数组中处理hash冲突的方式为链表还是红黑树(check第一个节点类型即可),分别处理

```java
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}
/**
     * Implements Map.put and related methods
     *
     * @param hash hash for key
     * @param key the key
     * @param value the value to put
     * @param onlyIfAbsent if true, don't change existing value
     * @param evict if false, the table is in creation mode.
     * @return previous value, or null if none
     */
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; 
    Node<K,V> p; 
    int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    /*如果table的在（n-1）&hash的值是空，就新建一个节点插入在该位置*/
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    /*表示有冲突,开始处理冲突*/
    else {
        Node<K,V> e; 
        K k;
        /*检查第一个Node，p是不是要找的值*/
        if (p.hash == hash &&((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
            for (int binCount = 0; ; ++binCount) {
                /*指针为空就挂在后面*/
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    //如果冲突的节点数已经达到8个，看是否需要改变冲突节点的存储结构，　　　　　　　　　　　　　
                    //treeifyBin首先判断当前hashMap的长度，如果不足64，只进行
                    //resize，扩容table，如果达到64，那么将冲突的存储结构为红黑树
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                /*如果有相同的key值就结束遍历*/
                if (e.hash == hash &&((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        /*就是链表上有相同的key值*/
        if (e != null) { // existing mapping for key，就是key的Value存在
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;//返回存在的Value值
        }
    }
    ++modCount;
    /*如果当前大小大于门限，门限原本是初始容量*0.75*/
    if (++size > threshold)
        resize();//扩容两倍
    afterNodeInsertion(evict);
    return null;
}
```

**扩容方式：**

1、HashMap 没有指定初始长度的话，默认会为null，这时候往里面添加元素他就会进行扩容，初始数组大小为16.

2、当元素添加到链表上，链表的长度大于8的时候，数组长度小于64时，则扩容。

3、当HashMap中的元素个数超过数组大小 * 负载因子时，比如16的容量，你加到12时，就会进行扩容。resize扩容分两步：

- ==扩容==：创建一个新的Entry空数组，长度是原数组的2倍。
- ==ReHash==：遍历原Entry数组，把所有的Entry重新Hash到新数组。



> 之所以不能直接复制是因为长度扩大以后，Hash的规则也随之改变。
>
> 负载因子是0.75是对空间和时间效率的一个平衡选择。
>
> 默认初始化大小是16，之所以选择16，是==为了服务将Key映射到index的算法==。当容量是 $2^{n}$时，$2^{n}-1$ 与 hash值进行按位与运算，相当于取hash值中的低n位的值作为对应的数组下标。只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。这样子会比取模运算快上很多。



**HashMap并发不安全的原因：**

1.7：并发扩容时由于头插法存在环形链导致插入查询死循环和数据丢失

1.8：并发执行put存在数据覆盖的情况

**并发场景下的安全方案：**

可以用Collections.synchronizedMap() 包装 HashMap，本质就是加全局锁实现同步

但建议使用比如ConcurrentHashmap、Hashtable等线程安全等集合类



#### Q：Hashtable

1. Hashtable底层数据结构是数组+链表，链表主要是为了解决hash冲突。
2. 创建时如果不指定容量初始值，`Hashtable` 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。
3. `Hashtable` 内部的方法基本都经过`synchronized` 修饰
4. Hashtable 不允许有 null 键和 null 值，否则会抛出 `NullPointerException`

**为什么 key 和 value 不允许为 null** ：

在并发编程中，==null 值容易引来歧义==， 假如先调用 `get(key)` 返回的结果是 null，那么我们无法确认是因为当时这个 key 对应的 value 本身放的就是 null，还是说这个 key 值根本不存在，这会引起歧义，==如果在非并发编程中，可以进一步通过调用 containsKey 方法来进行判断，但是并发编程中无法保证两个方法之间没有其他线程来修改 key 值，所以就直接禁止了 null 值的存在==。



#### Q：ConcurrentHashMap

**JDK1.8之前**

ConcurrentHashMap由Segment(分段锁)数组结构和HashEntry数组组成，Segment是一种可重入锁，一个Segment中包含一个HashEntry数组，每个HashEntry又是一个链表结构，有点类似HashMap。

因此在ConcurrentHashMap查询一个元素的过程需要进行两次Hash操作，如下所示：

- 第一次Hash定位到Segment，
- 第二次Hash定位到元素所在的链表的头部

而同样它的插入操作则是先计算put 的 key 的位置，获取指定位置的 Segment，如果指定位置的 Segment 为空，则初始化这个 Segment，Segment.put 插入 key,value 值。

ConcurrentHashMap 的扩容是仅仅和每个Segment元素中HashEntry数组的长度有关，并且只扩容当前Segment中HashEntry数组。扩容只会扩容到原来的两倍。老数组里的数据移动到新的数组时，位置要么不变，要么变为 index+ oldSize，参数里的 node 会在扩容之后使用链表**头插法**插入到指定位置。

正是通过Segment分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。

**JDK1.8**

ConcurrentHashMap 它取消了 Segment 分段锁，数据结构是数组+链表/红黑二叉树。当冲突链表达到一定长度时，链表会转换成红黑树。采用 CAS 和 synchronized 来保证并发安全。

而在JDK1.8中只需要一次定位，并且采用CAS+synchronized的机制。如果对应下标处没有结点，说明没有发生哈希冲突，此时直接通过CAS进行插入，若成功，直接返回。若失败，则使用synchronized进行加锁写入。

**构造函数：**

```java
public ConcurrentHashMap(int initialCapacity) {
    this(initialCapacity, LOAD_FACTOR, 1);
}
```



链接：https://zhuanlan.zhihu.com/p/237295675



#### Q：Deque

**ListedList和ArrayDeque：**

1. ArrayDeque基于可变长的数组和双指针实现；LinkedList则是通过双向链表实现
2. ArrayDeque不支持存储Null数据；LinkedList支持

3. LinkedList每次插入数据需要申请新空间，ArrayDeque扩容步骤少，性能上要好些



#### Q：PriorityQueue

利用二叉堆的数据结构，底层是可变长的数组

增删元素时间复杂度为O(logn)



#### Q：CopyOnWriteArrayList

1. 线程安全的 List
2. 当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了
3. 读取操作没有任何同步控制和锁操作，理由就是内部数组 array 不会发生修改，只会被另外一个 array 替换，因此可以保证数据安全
4. 写入操作 add()方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会 copy 出多个副本出来



#### Q：ConcurrentLinkedQueue

高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列



### Java并发

#### Q：volatile关键字实现原理

volatile关键字的作用主要是防止JVM指令重排，以及保证变量的可见性。

指令重排的原因：

由于**CPU 处理速度和内存不匹配**，CPU为了提高运算效率，处理器可能会对输入的代码进行乱序执行，也就是所谓的「指令重排序」。CPU指令重排在多线程下会导致代码在非预期下执行，最终会导致结果存在错误的情况。

volatile的底层是采用内存屏障来实现的，就是在编译器生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。内存屏障就是一段与平台相关的代码，Java中的内存屏障代码都在Unsafe类中定义，共包含三个方法：LoadFence()、storeFence()、fullFence()。

不可见性的原因：

Java内存模型希望 **屏蔽各种硬件和操作系统的访问差异，保证了Java程序在各种平台下对内存的访问都能得到一致效果**。所以规定了线程之间的「共享变量」存储在「主内存」中，每个线程都有自己私有的「本地内存」，「本地内存」存储了该线程以读/写共享变量的副本。线程对变量的所有操作都必须在「本地内存」进行，「不能直接读写主内存」的变量。

这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成**数据的不一致**。要解决这个问题，就需要把变量声明为 `volatile` ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。

volatile用于保证内存的可见性，可以将其看做是轻量级的锁，它具有如下的内存语义：

- 写内存语义：当写一个volatile变量时，JMM会把该线程本地内存中的共享变量的值刷新到主内存中。

- 读内存语义：当读一个volatile变量时，JMM会把该线程本地内存置为无效，使其从主内存中读取共享变量。



> （1）背景
>
> -  ==可见性==：现有计算机往往是多核的，每个核心下会有高速缓存。高速缓存的诞生是由于「CPU与内存(主存)的速度存在差异」，L1和L2缓存一般是「每个核心独占」一份的。
>
> -  ==有序性==：为了让CPU提高运算效率，处理器可能会对输入的代码进行「乱序执行」，也就是所谓的「指令重排序」
>
> -  ==原子性==一次对数值的修改操作往往是非原子性的（比如i++实际上在计算机执行时就会分成多个指令）
>
> （2）多线程并发的线程安全问题
>
> - 缓存数据不一致
> - CPU指令重排序在多线程下会导致代码在非预期下执行，最终会导致结果存在错误的情况
>
> （3）缓存不一致问题的解决方案
>
> - 使用==总线锁==：某个核心在修改数据的过程中，其他核心均无法修改内存中的数据。（类似于独占内存的概念，只要有CPU在修改，那别的CPU就得等待当前CPU释放）
>
> - ==缓存一致性协议==：常见的有MESI协议。MESI拆开英文是（Modified （修改状态）、Exclusive （独占状态）、Share（共享状态）、Invalid（无效状态））
>
>   也可以理解成==缓存锁==，它针对的是「缓存行」(Cache line) 进行”加锁”，所谓「缓存行」其实就是 高速缓存 存储的最小单位。
>
> MESI协议大致原理是当每个CPU读取共享变量之前，会判断**对象状态**，根据**对象状态**做不同的策略。
>
> 1. 如果是独占，说明当前CPU将要得到的变量数据是最新的，没有被其他CPU所同时读取
> 2. 如果是共享，说明当前CPU将要得到的变量数据还是最新的，有其他的CPU在同时读取，但还没被修改
> 3. 如果是修改，说明当前CPU正在修改该变量的值，同时会向其他CPU发送该数据状态为invalid(无效)的通知，得到其他CPU响应后（其他CPU将数据状态从共享(share)变成invalid(无效)），会当前CPU将高速缓存的数据写到主存，并把自己的状态从modify(修改)变成exclusive(独占)
> 4. 如果是无效，说明当前数据是被改过了，需要从主存重新读取最新的数据。
>
> 
>
> 关键就在于某个CPU在对数据进行修改时，需要「同步」通知其他CPU，表示这个数据被我修改了，你们不能用了。
>
> 由于CPU对「缓存一致性协议」进行的异步优化「store buffer」「invalid queue」，很可能导致后面的指令很可能查不到前面指令的执行结果（各个指令的执行顺序非代码执行顺序），这种现象很多时候被称作「CPU乱序执行」
>
> 为了解决乱序问题（也可以理解为可见性问题，修改完没有及时同步到其他的CPU），又引出了「内存屏障」的概念。
>
> （4）内存屏障
>
> 「内存屏障」其实就是为了解决「异步优化」导致「CPU乱序执行」/「缓存不及时可见」的问题。
>
> 内存屏障可以分为三种类型：写屏障，读屏障以及全能屏障（包含了读写屏障），屏障可以简单理解为：==在操作数据的时候，往数据插入一条”特殊的指令”。只要遇到这条指令，那前面的操作都得「完成」==。
>
> 那写屏障就可以这样理解：CPU当发现写屏障的指令时，会把该指令「之前」存在于「store Buffer」所有写指令刷入高速缓存。通过这种方式就可以让CPU修改的数据可以马上暴露给其他CPU，达到「写操作」可见性的效果。
>
> 那读屏障也是类似的：CPU当发现读屏障的指令时，会把该指令「之前」存在于「invalid queue」所有的指令都处理掉。通过这种方式就可以确保当前CPU的缓存状态是准确的，达到「读操作」一定是读取最新的效果。
>
> （5）Java 内存模型
>
> ==Java内存模型希望 屏蔽各种硬件和操作系统的访问差异，保证了Java程序在各种平台下对内存的访问都能得到一致效果==。目的是解决多线程存在的原子性、可见性（缓存一致性）以及有序性问题。
>
> ==Java内存模型的抽象结构==：线程之间的「共享变量」存储在「主内存」中，每个线程都有自己私有的「本地内存」，「本地内存」存储了该线程以读/写共享变量的副本。线程对变量的所有操作都必须在「本地内存」进行，「不能直接读写主内存」的变量。
>
> happen-before规则：Java内存模型规定在某些场景下（一共8条），前面一个操作的结果对后续操作必须是可见的。这8条规则成为happen-before规则。
>
> 对volatile内存语义的探讨
>
> 可见性和有序性(禁止重排序)：Java内存模型为了实现volatile有序性和可见性，定义了4种内存屏障的「规范」，分别是LoadLoad/LoadStore/StoreLoad/StoreStore。
>
> 说白了，就是在**volatile「前后」加上「内存屏障」，使得编译器和CPU无法进行重排序，致使有序，并且写volatile变量对其他线程可见。**
>
> ==volatile是Java的关键字，修饰的变量是可见性且有序的（不会被重排序）。可见性由happen-before规则完成，有序性由Java内存模型定义的「内存屏障」完成==

参考文章：[为什么需要Java内存模型](http://javainterview.gitee.io/luffy/2021/08/19/02-Java%E5%B9%B6%E5%8F%91/08.%20%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/)



#### Q：CAS

CAS 是**乐观锁**的一种实现方式，他采用的是**自旋锁**(一直尝试,直到成功)的思想，是一种轻量级的锁机制

CAS操作(CompareAndSwap)，CAS操作简单的说就是比较并交换。

CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。

如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。

CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”

 Java并发包(java.util.concurrent)中大量使用了CAS操作,涉及到并发的地方都调用了sun.misc.Unsafe类方法进行CAS操作。

缺点：

- ABA问题，解决方案：通过一个顺序递增的version字段，或时间戳
- 并发程度高时，自旋耗费CPU资源





#### Q：synchronized关键字及原理

synchronized是Java的一个关键字，是一种互斥锁，实现一次只允许一个线程进入被锁住的方法或者代码块。

一般用于以下几个场景：

修饰实例方法，对当前实例对象加锁；修饰静态方法，对当前类的Class对象加锁；修饰代码块，指定一个加锁的对象，给对象加锁。

原理是当修饰方法时，**编译器会生成ACC_SYNCHRONIZED 关键字用来标识**，该标识指明这个方法是一个同步方法。如果是实例方法，JVM会尝试获取实例对象的锁。如果是静态方法，JVM会尝试获取当前类Class对象的锁。

当修饰代码块时，**依赖的是monitorenter 和monitorexit指令，两个指令会嵌入代码块两端**。其次每个对象都会有一个与之对应的monitor对象，monitor对象中存储着当前持有锁的线程以及等待锁的线程队列。使用类似信号量的PV操作来竞争锁，拿到对象的锁，则计数器+1，释放锁则计数器-1。获取失败就要阻塞等待唤醒。

synchronized 锁优化：

synchronized的底层是采用Java对象头来存储锁信息的，synchronized的锁信息包括锁的标志和锁的状态，这些信息都存放在对象头的Mark Word这一部分，并且还支持锁升级。

在内存中，对象一般由三部分组成，分别是对象头、对象实际数据和对齐填充。在对象头的Mark Word 部分会记录对象关于锁的信息。

Mark Word 对锁的状态记录一共有4种：无锁，偏向锁、轻量锁和重量级锁。

![图片](C:/Users/Lenovo/Desktop/笔记/CS-Learning-Notes/notes/pics/synchronized锁升级.png)

（1）无锁，一开始，没有任何线程访问同步块，此时同步块处于无锁状态

（2）偏向锁指的是JVM会认为只有某个线程才会执行同步代码（没有竞争的环境）所以在Mark Word会直接记录线程ID，只要线程来执行代码了，会比对线程ID是否相等，相等则当前线程能直接获取得到锁，执行同步代码。

如果不相等，则用CAS来尝试修改当前的线程ID，如果CAS修改成功，那还是能获取得到锁，执行同步代码。

如果CAS失败了，说明有竞争环境，此时会对偏向锁撤销，升级为轻量级锁。

（3）在轻量级锁状态下，当前线程会在栈帧下创建Lock Record，LockRecord 会把Mark Word的信息拷贝进去，线程执行到同步代码时，则用CAS试图将Mark Word的指向到线程栈帧的Lock Record，假设CAS修改成功，则获取得到轻量级锁。

假设修改失败，则自旋（重试），自旋一定次数后，则升级为重量级锁。

（4）重量级锁，当有一个线程获取锁之后，其余所有等待获取该锁的线程都会处于阻塞状态

依赖monitor和操作系统的mutex指令，需要用户态和内核态切换，性能损耗明显。

![img](C:/Users/Lenovo/Desktop/笔记/CS-Learning-Notes/notes/pics/008i3skNgy1gtt125cqodj61p00c8wh502.jpg)



#### Q：AQS原理

AQS也就是抽象队列同步器，是可以给我们实现锁的一个 **框架**，内部实现的关键是维护了一个先进先出的等待队列CLH和state状态变量。

先进先出队列存储的元素叫做Node节点，该节点标识着当前的状态值、是独占还是共享模式以及它的前驱和后继节点等信息。

总体流程：如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那就将暂时获取不到锁的线程以Node 节点的形式加入到队列中

简单理解说：AQS定义了模板，具体实现由各个子类完成。

AQS支持两种模式：

- 独占（锁只会被一个线程独占），可分成公平锁指按照线程在队列中的排队顺序，先到者先拿到锁；非公平锁，当线程要获取锁时，先通过两次CAS操作去抢锁，如果没抢到，当前线程再加入到队列中等待唤醒。

- 共享（多个线程可以同时执行），多个线程可同时执行





#### Q：ReentrantLock

ReentrantLock是一个可重入锁，主要实现依赖于CAS+AQS队列实现，一个是支持公平锁和非公平锁。

（1）公平锁原理

1. 选择公平锁时，会实例化FairSync类，FairSync继承Sync，而Sync继承AQS；
2. ReentrantLock调用lock方法，最终会调用sync的tryAcquire函数获取资源；
3. 而FairSync的tryAcquire函数是当前线程只有在队列为空或者时队首节点的时候，才能获取资源，否则会被加入到阻塞队列中

（2）非公平锁原理

1. NoFairSync同样继承Sync，ReentrantLock调用lock方法，NoFairSync的tryAcquire函数，会调用父类Sync的方法nofairTryAcquire函数；
2. 该函数是如果资源释放时，新的线程会尝试CAS操作获取资源，而不管阻塞队列中时候有先于其申请的线程





#### Q：Semaphore

Semaphore 信号量，用来控制同一时间，资源可被访问的线程数量，一般可用于流量的控制。

不同于 `synchronized` 和 `ReentrantLock` 都是一次只允许一个线程访问某个资源。

Semaphore 维持了一个可获得许可证的数量。当一个线程执行 `acquire()` 方法会阻塞，直到有一个许可证可以获得然后拿走一个许可证；而 `release()` 时则会归还许可证。这属于共享锁的一种实现。

此外Semaphore 有两种模式，公平模式和非公平模式。

- 公平模式： 调用 `acquire()` 方法的顺序就是获取许可证的顺序，遵循 FIFO；
- 非公平模式： 抢占式的。



#### Q：CountDownLatch 和 CyclicBarrier

首先 CountDownLatch 和CyclicBarrier 都是线程同步工具类。

CountDownLatch 允许 count 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。常用于让某个一线程在开始运行前等待n个线程执行完毕的场景。

而CyclicBarrier 则是一组线程会互相等待，直到所有线程都到达一个同步点。应用场景类似。

**两者的区别**：

（1）首先是等待主体不同，CountDownLatch调用`await()` 通常是主线程，而CyclicBarrier调用的await()是在任务线程调用，主线程是不受影响的。

（2）CountDownLatch 是计数器，只能使用一次，而 CyclicBarrier 的计数器提供 reset 功能，可以多次使用。

（3）CountDownLatch 的计数是减 1 直到 0，CyclicBarrier 是加 1，直到指定值。

（4）**CountDownLatch 的实现是基于 AQS 的，而 CyclicBarrier 是基于 ReentrantLock(ReentrantLock 也属于 AQS 同步器)和 Condition 的。**



**CountDownLatch原理**：

当我们构建CountDownLatch 对象时，传入的值其实就是赋值给AQS 的关键变量state；

执行countDown方法时，其实就是利用CAS将state减一；

执行await方法时，就是判断state是否为0，不为0则加入到队列中，将该线程阻塞掉，头节点除外；

因为头节点会一直自旋等待state为0，当state为0的时候，头节点把剩余的在队列中阻塞的线程也一并唤醒。

**CyclicBarrier原理**：

CyclicBarrier没有像CountDownLatch一样使用AQS的state变量，则是==直接借助ReentrantLock 和 Condition等待唤醒的功能==实现。

在构建CyclicBarrier时，传入的值会赋值给CyclicBarrier内部维护的count变量，也会赋值给parties变量（复用的关键）；

每次调用await时，会将count - 1，操作count值是直接使用ReentrantLock来保证线程安全性；

如果count不为0，则添加到condition队列中；

如果count等于0，则把节点从condition队列添加到AQS的队列中进行全部唤醒，并且将count的值重新赋值为parties，实现复用。



#### Q：ThreadLocal

目的：用做数据隔离，为每个线程提供一个局部变量，不会和其他线程的局部变量发送冲突。

做法：

1. 每个线程都有一个ThreadLocalMap类型的实例变量threadlocals，其中key是对ThreadLocal对象的一个弱引用，value则是我们要放入的值；
2. set时，将值插入当前线程的ThreadLocalMap中；
3. get时，则以ThreadLocal对象为key，从当前线程的ThreadLocalMap中取出。

内存泄漏问题：

原因：当threadlocal变量不用后会被置为null，而堆中的threadlocal对象没有强引用则会被GC回收，此时线程不结束，Entry中key为null的value对象并不会被回收；

措施：当前用完threadlocal后，调用ThreadLocal的remove方法清除。

**Java的四种引用类型：**

- **强引用**：我们常常 new 出来的对象就是强引用类型，只要强引用存在，垃圾回收器将永远不会回收被引用的对象，哪怕内存不足的时候
- **软引用**：使用 SoftReference 修饰的对象被称为软引用，软引用指向的对象在内存要溢出的时候被回收
- **弱引用**：使用 WeakReference 修饰的对象被称为弱引用，只要发生垃圾回收，若这个对象只被弱引用指向，那么就会被回收
- **虚引用**：虚引用是最弱的引用，在 Java 中使用 PhantomReference 进行定义。虚引用中唯一的作用就是用队列接收对象即将死亡的通知



#### Q：线程池基本知识

==线程是一个重资源==，JVM 中的线程与操作系统的线程是一对一的关系，所以在 JVM 中每创建一个线程就需要调用操作系统提供的 API 创建线程，赋予资源，并且销毁线程同样也需要系统调用。

而系统调用就意味着上下文切换等开销，并且线程也是需要占用内存的，而内存也是珍贵的资源。

使用线程池可以降低资源消耗、提高响应速度以及提高线程的可管理性。

==线程池其实是一个典型的生产者-消费者模式==

线程池中的ctl，一个涵盖了两个概念的原子整数类，它将工作线程数和线程池状态结合在一起维护，低29位存放workerCount，高3位存放runstate。

![图片](C:/Users/Lenovo/Desktop/笔记/CS-Learning-Notes/notes/pics/ctl源码.png)

如何修改原生线程池，使得可以先拉满线程数再入任务队列排队？

> 在 offer 方法内部判断此时线程数还小于最大线程数的时候返回 false，即可走下面 `else if` 中 `addWorker` (新增线程)的逻辑，如果数量已经达到最大线程数，直接入队即可。

![图片](C:/Users/Lenovo/Desktop/笔记/CS-Learning-Notes/notes/pics/addworker.png)

线程池如何动态修改核心线程数和最大线程数？

> 线程数的设定是一个迭代的过程，需要压测适时调整。想要动态修改那就得==实时监控线程池状态==。线程池提供了相关方法修改配置。

如何自己设计一个线程池？

> 线程池讲白了就是存储线程的一个容器，池内保存之前建立过的线程来重复执行任务，减少创建和销毁线程的开销，提高任务的响应速度，并便于线程的管理。
>
> 我个人觉得如果要设计一个线程池的话得考虑池内工作线程的管理、任务编排执行、线程池超负荷处理方案、监控。
>
> 初始化线程数、核心线程数、最大线程池都暴露出来可配置，包括超过核心线程数的线程空闲消亡配置。
>
> 任务的存储结构可配置，可以是无界队列也可以是有界队列，也可以根据配置分多个队列来分配不同优先级的任务，也可以采用 stealing 的机制来提高线程的利用率。
>
> 再提供配置来表明此线程池是 IO 密集还是 CPU 密集型来改变任务的执行策略。
>
> 超负荷的方案可以有多种，包括丢弃任务、拒绝任务并抛出异常、丢弃最旧的任务或自定义等等。
>
> 线程池埋好点暴露出用于监控的接口，如已处理任务数、待处理任务数、正在运行的线程数、拒绝的任务数等等信息。

参考文章：[线程池](https://mp.weixin.qq.com/s?__biz=MzAwNDA2OTM1Ng==&mid=2453152340&idx=2&sn=ab8af46dbbb7e40b8a174ff6547bac23&scene=21#wechat_redirect)



#### Q：Executor框架的使用

Executor框架结构由三大部分组成：

- 任务（Runnable / Callable）：执行任务需要实现的 Runnable 接口 或 Callable接口。Runnable 接口或 Callable 接口 实现类都可以被 ThreadPoolExecutor 或 ScheduledThreadPoolExecutor 执行;
- 任务的执行（Executor）：使用最多的是 ThreadPoolExecutor;
- 异步计算的结果（Future）：Future 接口以及 Future 接口的实现类 FutureTask 类都可以代表异步计算的结果。

![Executor框架的使用示意图](C:/Users/Lenovo/Desktop/笔记/CS-Learning-Notes/notes/pics/Executor框架的使用示意图.png)

Executor框架的使用：

1. 主线程首先创建一个实现了Runnable 或者 Callable 接口的任务对象；
2. 把任务对象直接交给 ExecutorService 执行
3. 如果执行 `ExecutorService.submit(..)`，ExecutorService 将返回一个实现了Future 接口的对象；
4. 最后，主线程可以执行 `FutureTask.get()` 方法来等待执行完成。



#### Q：介绍ThreadPoolExecutor函数参数

ThreadPoolExecutor 3 个最重要的参数：

- corePoolSize : 核心线程数线程数定义了最小可以同时运行的线程数量。
- maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

ThreadPoolExecutor其他常见参数:

- keepAliveTime：当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁；
- unit：keepAliveTime 参数的时间单位。
- threadFactory：executor 创建新线程的时候会用到。
- handler：如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，采用的策略。



#### Q：ThreadPoolExecutor 饱和策略

- ThreadPoolExecutor.AbortPolicy ：抛出 RejectedExecutionException来拒绝新任务的处理。
- ThreadPoolExecutor.CallerRunsPolicy ：调用执行自己的线程运行任务，如果执行程序已关闭，则会丢弃该任务。
- ThreadPoolExecutor.DiscardPolicy ：不处理新任务，直接丢弃掉。
- ThreadPoolExecutor.DiscardOldestPolicy ： 此策略将丢弃最早的未处理的任务请求。



#### Q：ThreadPoolExecutor实现流程

1. 提交一个任务，线程池里存活的核心线程数小于线程数corePoolSize时，线程池会创建一个核心线程去处理提交的任务。
2. 如果线程池核心线程数已满，即线程数已经等于corePoolSize，一个新提交的任务，会被放进任务队列workQueue排队等待执行。
3. 当线程池里面存活的线程数已经等于corePoolSize了，并且任务队列workQueue也满，判断线程数是否达到maximumPoolSize，即最大线程数是否已满，如果没到达，创建一个非核心线程执行提交的任务。
4. 如果当前的线程数达到了maximumPoolSize，还有新的任务过来的话，直接采用拒绝策略处理。



#### Q：介绍线程池的工作队列

（1）ArrayBlockingQueue（有界队列）

一个用数组实现的有界阻塞队列，按FIFO排序。

ArrayBlockingQueue只有一个锁对象，一个锁对象会造成要么是生产者获得锁，要么是消费者获得锁，两者竞争锁，无法并行。

（2）LinkedBlockingQueue（可设置容量队列）

基于链表结构的阻塞队列，按FIFO排序任务，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE；

newFixedThreadPool线程池使用了这个队列。

LinkedBlockingQueue有两个锁对象，可以并行处理。

（3）DelayQueue（延迟队列）：

一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序，否则根据插入到队列的先后排序。newScheduledThreadPool线程池使用了这个队列。

队列元素必须实现Delayed接口，支持延迟获取，元素按照时间排序，只有元素到期后，消费者才能从队列中取出。

（4）PriorityBlockingQueue（优先级队列）

一个具有优先级的无界阻塞队列。

底层是基于数组存储元素的，元素按照优选级顺序存储，优先级是通过Comparable的compareTo方法来实现的（自然排序），和其他堵塞队列不同的是，其只会堵塞消费者，不会堵塞生产者，数组会不断扩容。

（5）SynchronousQueue（同步队列）：

一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene。newCachedThreadPool线程池使用了这个队列。



#### Q：介绍几种常见的线程池

（1）newFixedThreadPool：固定数目线程的线程池

特点：核心线程数和最大线程数大小一样，没有所谓的非空闲时间，工作队列为LinkedBlockingQueue。

工作机制：提交任务后，如果线程数少于核心线程，创建核心线程执行任务；如果线程数等于核心线程，把任务添加到LinkedBlockingQueue阻塞队列；如果线程执行完任务，去阻塞队列取任务，继续执行。

使用场景：FixedThreadPool适用于处理CPU密集型的任务，确保CPU在长期被工作线程使用的情况下，尽可能地少分配线程，即适用执行长期地任务

（2）newCachedThreadPool：可缓存线程的线程池

特点：核心线程数为0，最大线程数为Integer.MAX_VALUE，工作队列是SynchronousQueue。

工作机制：提交任务后，因为没有核心线程，所以任务直接加到SynchronousQueue队列，判断是否有空闲线程。如果有，就去取出任务执行；如果没有空闲线程，就新建一个线程执行。执行完任务的线程，还可以存活60秒，如果在这期间，接到任务，可以继续活下去；否则，被销毁。

使用场景：用于并发执行大量短期的小任务。

（3）newSingleThreadExecutor：单线程的线程池

特点：核心线程数和最大线程数都为1，工作队列为LinkedBlockingQueue

工作机制：提交任务，判断线程是否存在，如果没有则创建一个新线程，如果由则加入阻塞队列。唯一线程依次执行。

使用场景：适用于串行执行任务的场景，一个任务一个任务地执行。

（4）newScheduledThreadPool：定时及周期执行的线程池

 主要用来在给定的延迟后运行任务，或者定期执行任务。任务队列使用的是DelayQueue。每次线程从 DelayQueue 中获取 time 大于等于当前时间的任务。

使用场景：周期性执行任务的场景，需要限制线程数量的场景。



#### Q：线程池状态有哪些

![线程池状态.png](C:/Users/Lenovo/Desktop/笔记/CS-Learning-Notes/notes/pics/线程池状态-4872074e2f9640688171e9d577315a04.png)

RUNNING

- 该状态的线程池会接收新任务，并处理阻塞队列中的任务;
- 调用线程池的shutdown()方法，可以切换到SHUTDOWN状态;
- 调用线程池的shutdownNow()方法，可以切换到STOP状态;

SHUTDOWN

- 该状态的线程池不会接收新任务，但会处理阻塞队列中的任务；
- 队列为空，并且线程池中执行的任务也为空,进入TIDYING状态;

STOP

- 该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务；
- 线程池中执行的任务为空,进入TIDYING状态;

TIDYING

- 该状态表明所有的任务已经运行终止，记录的任务数量为0。
- terminated()执行完毕，进入TERMINATED状态

TERMINATED

- 该状态表示线程池彻底终止



#### Q：原子类

类型：包括基本类型有AtomicInteger 整形原子类，AtomicLong，AtomicBoolean

AtomicInteger 类的原理：

- 利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销
- CAS 的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值
- value 是一个 volatile 变量，保证JVM任何线程拿到最新值
- UnSafe 类的 objectFieldOffset() 方法是一个本地方法，获取原来值的内存地址，返回valueOffset



#### Q：Java 中的锁

（1）乐观锁和悲观锁

悲观锁：线程每次操作该数据时都会假设其他线程也会操作该数据，所以每次操作前都会上锁，这样其他线程想操作这个数据拿不到锁就只能阻塞了。典型的悲观锁有synchronized 和ReentrantLock。

乐观锁：操作数据时不会上锁，在更新的时候会判断一下在此期间是否有其他线程去更新这个数据。乐观锁可以使用版本号机制和CAS算法实现。在 Java 语言中 `java.util.concurrent.atomic`包下的原子类就是使用CAS 乐观锁实现的。

（2）独占锁和共享锁

独占锁是指锁一次只能被一个线程所持有。如果一个线程对数据加上排他锁后，那么其他线程不能再对该数据加任何类型的锁。获得独占锁的线程即能读数据又能修改数据。JDK中的`synchronized`和`java.util.concurrent(JUC)`包中Lock的实现类就是独占锁。

共享锁是指锁可被多个线程所持有。如果一个线程对数据加上共享锁后，那么其他线程只能对数据再加共享锁，不能加独占锁。获得共享锁的线程只能读数据，不能修改数据。在 JDK 中 `ReentrantReadWriteLock` 就是一种共享锁。

（3）互斥锁和读写锁

**互斥锁是独占锁的一种常规实现**，是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。互斥锁一次只能一个线程拥有互斥锁，其他线程只有等待。

**读写锁是共享锁的一种具体实现**。读写锁管理一组锁，一个是只读的锁，一个是写锁。

读锁可以在没有写锁的时候被多个线程同时持有，而写锁是独占的。写锁的优先级要高于读锁，一个获得了读锁的线程必须能看到前一个释放的写锁所更新的内容。

读写锁相比于互斥锁并发程度更高，每次只有一个写线程，但是同时可以有多个线程并发读。

（4）公平锁和非公平锁

公平锁是指多个线程按照申请锁的顺序来获取锁。

非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发环境下，有可能造成优先级翻转，或者饥饿的状态（某个线程一直得不到锁）。

（5）可重入锁

可重入锁又称之为递归锁，是指同一个线程在外层方法获取了锁，在进入内层方法会自动获取锁。

可重入锁的一个好处是可一定程度避免死锁。

（6）自旋锁

自旋锁是指线程在没有获得锁时不是被直接挂起，而是执行一个忙循环，这个忙循环就是所谓的自旋。

自旋锁的目的是为了减少线程被挂起的几率，因为线程的挂起和唤醒也都是耗资源的操作。

如果锁被另一个线程占用的时间比较长，即使自旋了之后当前线程还是会被挂起，忙循环就会变成浪费系统资源的操作，反而降低了整体性能。因此自旋锁是不适应锁占用时间长的并发情况的。

（7）锁升级（无锁|偏向锁|轻量级锁|重量级锁）

为了提升性能减少获得锁和释放锁所带来的消耗，引入了4种锁的状态：`无锁`、`偏向锁`、`轻量级锁`和`重量级锁`，它会随着多线程的竞争情况逐渐升级，但不能降级。

**无锁**

无锁状态其实就是上面讲的乐观锁，这里不再赘述。

**偏向锁**

Java偏向锁(Biased Locking)是指它会偏向于第一个访问锁的线程，如果在运行过程中，只有一个线程访问加锁的资源，不存在多线程竞争的情况，那么线程是不需要重复获取锁的，这种情况下，就会给线程加一个偏向锁。

偏向锁的实现是通过控制对象`Mark Word`的标志位来实现的，如果当前是`可偏向状态`，需要进一步判断对象头存储的线程 ID 是否与当前线程 ID 一致，如果一致直接进入。

**轻量级锁**

当线程竞争变得比较激烈时，偏向锁就会升级为`轻量级锁`，轻量级锁认为虽然竞争是存在的，但是理想情况下竞争的程度很低，通过`自旋方式`等待上一个线程释放锁。

**重量级锁**

如果线程并发进一步加剧，线程的自旋超过了一定次数，或者一个线程持有锁，一个线程在自旋，又来了第三个线程访问时（反正就是竞争继续加大了），轻量级锁就会膨胀为`重量级锁`，重量级锁会使除了此时拥有锁的线程以外的线程都阻塞。

升级到重量级锁其实就是互斥锁了，一个线程拿到锁，其余线程都会处于阻塞等待状态。



#### Q：线程安全的含义

==线程安全其实指的是内存安全==。在堆内存中数据由于可以被任何线程访问到，在没有限制的情况下存在被意外修改的风险。

保证线程安全的方法：

隔离法：

1. 位置隔离，线程空间，也就是栈内存
2. 数据隔离，ThreadLocal

标记法：

1. 只读标记，数据定义成final，只能读取
2. 加锁标记，给数据加互斥锁

大胆法：CAS加乐观锁，假设数据不会被意外修改，被修改了就放弃。



### JVM

#### Q：JVM内存区域

JVM由三部分组成：类加载子系统、执行引擎、运行时数据区。

其中运行时数据区域，可以简单分成5大块：方法区、堆、程序计数器、虚拟机栈、本地方法栈。其中线程共享的区域是方法区和堆，线程私有的区域是虚拟机栈、本地方法栈和程序计数器。

先来说线程私有的三个区域：

1. 程序计数器：是一块较小的内存空间，用于记录正在执行的虚拟机字节码指令的地址。为了线程切换后能恢复到正确的执行位置，每个线程需要一个独立的程序计数器。
2. 虚拟机栈：它是线程私有的，生命周期与线程相同。虚拟机描述的是Java方法执行的线程内存模型。每次方法调用都会创建一个==栈帧==。每个「栈帧」会包含几块内容：==局部变量表（基本数据类型，对象引用类型）、操作数栈、动态连接和返回地址。它的作用就是保存计算变量和方便函数的返回==。
3. 本地方法栈：跟虚拟机栈的功能类似，虚拟机栈用于管理 Java 函数的调用，而本地方法栈则用于管理本地方法的调用。这里的「本地方法」指的是「非Java方法」，一般本地方法是使用C语言实现的。

再来说线程共享的两个区域：

1. 方法区：是JVM规范的一部分，JDK8以前是实现是永久代，之后是元空间。它主要是用来存放已经被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。
2. 堆：是所有的JVM 线程间共享的区域，几乎类的实例和数组分配的内存都来自于它。堆在jvm启动时创建，堆中对象不用显式释放，gc会帮我们释放并回收内存。

> **局部变量表主要存放了编译期可知的各种数据类型**（boolean、byte、char、short、int、float、long、double）、**对象引用**（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。
>
> **Java 虚拟机栈会出现两种错误：`StackOverFlowError` 和 `OutOfMemoryError`。**
>
> - **`StackOverFlowError`：** 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。
> - **`OutOfMemoryError`：** Java 虚拟机栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出`OutOfMemoryError`异常。

> 在 JDK 8 之前，堆和方法区其实是连在一起的，或者说方法区其实就是堆的一部分，HotSpot 虚拟机给出的具体实现是永久代，永久代是一个连续的内存空间，由于永久代的垃圾回收和老年代的垃圾回收是绑定的，一旦其中一个区域被占满，这两个区都要进行垃圾回收，增大了 OOM 发生的概率，另外，有少数的方法例如 String 的 intern() 方法会因永久代的原因而导致不同虚拟机下有不同的表现，不利于代码迁移。这两个原因呢，促使 HotSpots 在 JDK 8 之后将方法区的实现更换成了元空间。
>
> 元空间与永久代之间最大的区别在于：元空间不再与堆连续，并且是存在于本地内存（Native memory）中的，这意味着只要本地内存足够，它就不会发生 OOM。

> 栈区存储方法的参数和局部变量，还有基本数据类型和引用类型的引用。堆是线程共享的内存区域，栈是线程独享的内存区域。堆中主要存放对象实例，栈中主要存放各种基本数据类型、对象的引用。



#### Q：如何判断对象是否死亡

答：GC 主要发生在堆，判断一个对象是否死亡的方式有两种：

（1）引用计数法

给对象添加一个引用计数器，每当有一个地方引用它，计数器加1；当引用失效，计数器就减1；当计数器为0时，说明对象不再被引用，可以被可回收。

缺点：如果对象存在循环依赖，那就无法定位该对象是否应该被回收（A依赖B，B依赖A）

（2）可达性分析算法

这个算法就是通过一系列的称为「GC Roots」的对象作为起点，从这些节点开始向下搜索，当对象到「GC Roots」都没有任何引用相连时，说明对象是不可用的，可以被回收。

可以作为 GC Root 的对象有以下几类：

- 虚拟机栈（栈帧中的本地变量表）中引用的对象（int a = new Test();）
- 方法区中类静态属性引用的对象 
- 方法区中常量引用的对象
- 本地方法栈中 JNI（即一般说的 Native 方法）引用的对象

参考文章：[看完这篇垃圾回收，和面试官扯皮没问题了](https://mp.weixin.qq.com/s/_AKQs-xXDHlk84HbwKUzOw)



#### Q：GC 的几种主要的收集方法及其优缺点

答：（1）标记-清除算法

该算法分为标记和清除阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。

这种垃圾收集算法会带来两个明显的问题：

一是执行效率不稳定；二是内存空间的碎片化问题。

（2）标记-复制算法

为了解决效率问题，标记-复制收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。

标记-复制收集算法简单高效但问题也很明显，可用空间直接少了一半，另外每次回收也要把存活对象移动到另一半，效率低下。

（3）标记-整理算法

前面两步和标记清除法一样，不同的是它在标记-清除算法的基础上添加了一个整理的过程，即把所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。

这算法缺点也很明显：每进一次垃圾清除都要频繁地移动存活的对象，效率十分低下

（4）分代收集算法

==分代算法是根据对象存活周期的不同将内存分为几块==。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。

比如在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。

> 是否移动对象都存在弊端，移动则内存回收时会更复杂，不移动则内存分配时会更复杂。从垃圾收集的停顿时间来看，不移动对象停顿时间会更短，甚至可以不需要停顿，但是从整个程序吞吐量来看，移动对象更加划算。因为内存分配和访问比起垃圾收集频率要高得多。



#### Q：Minor GC 和 Full GC触发条件

Full GC的触发条件：

1. 担保失败：当准备要触发一次 young GC时，如果发现统计数据说之前 young GC的平均晋升大小比目前的老年代剩余的空间大，则不会触发young GC而是转为触发 full GC
2. 老年代满了或者堆外内存满了
3. System.gc()，heap dump带GC,其默认都是触发 full GC

Minor GC的触发条件：

1. 当新生代的Eden区满的时候触发 Minor GC



#### Q：JVM如何避免Minor GC扫描全堆

**Minor GC存在一个问题就是，老年代的对象可能引用新生代的对象**，在标记存活对象的时候，就需要扫描老年代的对象，如果该对象拥有对新生代对象的引用，那么这个引用也会被作为 GC Roots。这相当于就做了**全堆扫描**。

HotSpot 给出的解决方案是 一项叫做 **卡表** 的技术。如下图所示:

<img src="C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\卡表.png" alt="卡表" style="zoom: 33%;" />

卡表的具体策略是**将老年代的空间分成大小为 512B的若干张卡，并且维护一个卡表，卡表本省是字节数组，数组中的每个元素对应着一张卡，其实就是一个标识位，这个标识位代表对应的卡是否可能存有指向新生代对象的引用**，如果可能存在，那么我们认为这张卡是脏的，即**脏卡**。如上图所示，卡表3被标记为脏。

在进行Minor GC的时候，我们便可以不用扫描整个老年代，而是在卡表中寻找脏卡，并将脏卡中的老年代指向新生代的引用加入到 Minor GC的GC Roots里，当完成所有脏卡的扫描之后，Java 虚拟机便会将所有脏卡的标识位清零。这样虚拟机以空间换时间，避免了全表扫描

参考文章：https://juejin.cn/post/6844903669251440653



#### Q：内存分配与回收策略

新生代：老年代 = 1 : 2；

minor GC：从年轻代（Eden+Survivor）空间回收内存被称为Minor GC；

Major是清理永久代。Full Gc是清理整个堆空间-包括年轻代和永久代；

年轻代：使用标记-复制算法进行清理；

老年代：标记-整理算法：标记处仍然存活的对象，将所有存活的对象向一端移动，以保内存的连续。

1. 对象在新生代的分配与回收

   - Eden: S0: S1 = 8:1:1；
   - 大部分对象在很短的时间内都会被回收，对象一般分配在 Eden 区
   - 当 Eden 区将满时，触发 Minor GC
   - 在 Eden 区的垃圾回收我们采用的是**标记 - 复制算法**

2. 对象何时晋升老年代

   - 长期存活的对象将进入老年代，当对象的年龄达到了我们设定的阈值，则会从S0（或S1）晋升到老年代。
   - 大对象直接进入老年代减少复制开销也放在老年代
   - 相同年龄的对象大于S0空间的一半，更老的对象则去老年代

3. 空间分配担保

   在发生Minor GC之前，虚拟机必须先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么这次Minor GC可以确保是安全的。否则就需要进行分配担保。

   空间分配担保就是担保**老年代的内存足够多，把新生代中Survivor无法容纳的的对象直接送入老年代。**

   - 在发生Minor GC 之前，虚拟机必须先检查

     ==老年代最大可用得连续空间是否大于新生代所有对象总空间或者历次晋升的平均大小==

     JDK 6 Update 24之后不再使用-XX：HandlePromotionFailure参数（是否允许担保失败）

     - 如果条件成立，那么这一次Minor GC就是安全的。

     - 如果不成立，则虚拟机会先查看 -XX:HandlePromotionFailure参数的设置值是否允许担保失败；

       - 如果允许，那会继续检查

         老年代最大可用的连续空间是否大于历次晋升到老年代的平均大小

         - 如果大于，将尝试进行Minor GC，尽管这次Minor GC有风险
         - 如果小于，那么就需要进行Full GC

       - 如果不允许，则进行Full GC

   谁进行空间担保：老年代需要能存放年轻代中的对象，所以是**老年代进行空间分配担保**

   ==目的：避免FullGC过于频繁==

4. Stop The World

   如果老年代满了，会触发 Full GC, Full GC 会同时回收新生代和老年代（即对整个堆进行GC），它会导致 Stop The World（简称 STW）,造成挺大的性能开销。

   什么是 STW ？所谓的 STW, 即在 GC（minor GC 或 Full GC）期间，只有垃圾回收器线程在工作，其他工作线程则被挂起。

   合理设置新生代与老年代的空间大小比例就是尽可能地避免对象过早地进入老年代，尽可能晚地触发 Full GC。

   由于 Full GC（或Minor GC） 会影响性能，所以我们要在一个合适的时间点发起 GC，这个时间点被称为 Safe Point，这个时间点的选定既不能太少以让 GC 时间太长导致程序过长时间卡顿，也不能过于频繁以至于过分增大运行时的负荷。一般当线程在这个时间点上状态是可以确定的，如确定 GC Root 的信息等，可以使 JVM 开始安全地 GC。Safe Point 主要指的是以下特定位置：

   - 循环的末尾
   - 方法返回前
   - 调用方法的 call 之后
   - 抛出异常的位置 另外需要注意的是由于新生代的特点（大部分对象经过 Minor GC后会消亡）， Minor GC 用的是复制算法，而在老生代由于对象比较多，占用的空间较大，使用复制算法会有较大开销（复制算法在对象存活率较高时要进行多次复制操作，同时浪费一半空间）所以根据老生代特点，在老年代进行的 GC 一般采用的是标记整理法来进行回收。



#### Q：垃圾收集器原理和种类

- Serial 收集器，单线程完成垃圾收集工作，并且进行垃圾收集时，必须暂停其他所有工作线程，直到它收集结束。标记-复制算法。
- ParNew 收集器，ParNew 收集器其实就是 Serial 收集器的多线程版本。
- Parallel Scavenge 收集器，Parallel Scavenge 收集器类似 ParNew 收集器，Parallel 收集器更关注系统的吞吐量。吞吐量指用于运行用户代码的时间与处理器总消耗时间的比值。标记-复制算法。
- Serial Old 收集器，单线程收集器，使用标记-整理算法。
- Parallel Old 收集器，Parallel Old 是 Parallel Scavenge 收集器的老年代版本，使用多线程和“标记－整理”算法
- CMS 收集器，CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。
- G1 收集器，G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征



> 根节点枚举

所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的，必须在一个能保障一致性的快照中才能得以进行，否则分析结果准确性也就无法保证。

> 并发的可达性分析

理论证明了当且仅当以下两个条件同时满足时，会产生“对象消失”问题：

- 赋值器插入了一条或多条从黑色对象到白色对象的新引用
- 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用

CMS 是基于增量更新来做并发标记的，破坏第一个条件，黑色对象一旦插入了指向白色对象的引用之后，它就被记录下来，等并发扫描结束之后，再以这些黑色对象为根重新扫描一次。

G1 则是用原始快照来实现，破坏第二个条件，当灰色要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，再并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。就是无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索。

> 跨代引用问题的解决

垃圾收集器在老年代中建立了名为记忆集（Remembered set）的数据结构，用以避免把整个老年代加进GC Roots 扫描范围。

记忆集是一种具体实现是卡表，在垃圾收集发生时，只要筛选卡表中变脏的元素，就能轻易得出哪些卡页内存块中包含跨代指针，把他们加入GC Roots 中一并扫描。

> 卡表元素的维护

卡表元素在有其他分代区域中对象引用了本区域对象时，对应卡表元素就应该变脏，变脏时间点原则上应该发生在引用类型字段赋值的那一刻。虚拟机通过写屏障技术维护卡表状态，在虚拟机层面对引用字段赋值操作进行一个AOP的增强。



**CMS（Concurrent Mark Sweep）**

CMS收集器是以实现最短 STW 时间为目标的收集器。 CMS 工作于老年代，但采用的是==标记清除法==。

主要有以下四个步骤：

1. 初始标记**：** 暂停所有的其他线程，并记录下与GCRoots 直接关联的对象，速度很快 ；
2. 并发标记： 从GC Roots的直接关联对象开始遍历整个对象图，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集器一起并发运行。
3. 重新标记**：** 为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
4. 并发清除：清理删除掉标记阶段判断的已经死亡的对象，由于不需要存活对象，所以这个阶段也是可以与用户线程同时并发的。

CMS在耗时最长的并发标记和并发清除阶段中，垃圾收集器都可以与用户线程一起工作。主要优点是 **并发收集、低停顿**。但是它有下面三个明显的缺点：

- 对 CPU 资源敏感，并发标记会占用资源导致用户程序变慢，降低总吞吐量；
- 无法处理浮动垃圾，每次并发标记和清理阶段都与用户线程并发，总会留下新的垃圾对象给下次处理；
- 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生，当空间碎片过多时，将会给大对象分配带来麻烦，进而可能触发Full GC



**G1（Garbage First） 收集器**

G1是一款能够建立“停顿时间模型”的收集器，它开创基于Region的堆内存布局，将连续的Java堆划分为多个大小相等的独立区域Region，它可以面向堆内存的任何部分来组成回收集合，每次收集到的内存空间大小都是Region大小的整数倍。G1收集器会去跟踪各个Region里面垃圾的价值大小，价值即回收所获得的空间大小以及回收所需时间的经验值，然后在后台维护一个优先级列表，每次根据用户设定的允许收集停顿时间，优先处理回收价值收益最大的那些Region。

1. 初始标记：仅仅标记一下 GC Roots 能直接关联的对象，并修改 TAMS 指针的值，让下一阶段用户线程并发运行时，能正确地在可用的Region中分配对象。该阶段需停顿线程，但耗时很短，而且是借进行 Minor GC 时同步完成的，实际上并没有额外的停顿。

2. 并发标记：从 GC Roots 开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收对象。该阶段耗时较长，但可与用户程序并发执行。当扫描完成后，还要重新处理 SATB 记录下在并发时有引用变动的对象。

3. 最终标记：对用户线程做短暂暂停，处理并发阶段结束后遗留下来的最后那少量的SATB记录。

4. 筛选回收：==更新 Region 的统计数据，对各个 Region 的回收价值和成本进行排序，根据用户所期望的停顿时间制定回收计划。然后把要回收的那一部分 Region 构成回收集，将其中的存活对象复制到空的 Region 中，再清理掉整个旧 Region 的全部空间。这里涉及到存活对象的移动，必须暂停用户线程==



> Region中的跨Region引用对象如何解决？

采用双向卡表，卡表是记录“我指向谁”，这种结构还记录“谁指向我”。

> 并发标记阶段如何保证收集线程与用户线程互不干扰地运行？

首先要解决地是用户线程改变对象引用关系时，必须保证其不能打破原本的对象结构，导致标记结果出现错误。

CMS 采用增量更新，G1采用原始快照（SATB）算法实现。其次对于回收过程中新创建对象的内存分配上，G1为每个Region设计了两个名为TAMS（Top at Mark Start）的指针，把Region一部分的空间划分出来用于并发回收过程中新对象的分配，并发回收时新分配的对象地址必须要在这两个指针位置以上。G1默认这个地址以上是标记过的也就是默认存活，不纳入回收范围。

> G1如何建立可靠的停顿预测模型？

G1收集器的停顿模型是以衰减均值为理论基础实现的，GC过程中，G1会记录每个Region的回收耗时、脏卡数量等各个可测量的步骤花费的成本，并分析得出平均值。

> G1的不足之处

首先是内存占用，G1和CMS都用卡表来处理跨代指针，但G1的卡表实现更为复杂，堆中的Region都必须有一份卡表，导致G1的记忆集可能会占整个堆容量的20%乃至更多的内存空间；相比起来CMS的卡表就相对比较简单，只有一份，而且只需要处理老年代到新生代的引用，反过来则不需要。

其次是执行负载上，CMS用写后屏障来更新卡表；而G1除了写后屏障外，为了实现原始快照搜索（SATB）算法，还需要使用写前屏障来跟踪并发时指针的变化情况。

> 衡量垃圾收集器的指标

内存占用、吞吐量和延迟。由于硬件性能增长，最关注的是延迟。



缺点：对机器要求高，耗CPU资源

G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征。它具备以下特点：

- 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。

- 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。

- 空间整合：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。

- 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。

G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。

参考文章：[分代收集算法](https://javaguide.cn/java/jvm/jvm-garbage-collection/#_3-4-%E5%88%86%E4%BB%A3%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95) 



#### Q：双亲委派机制

Java中的类加载器：

- Bootstrap ClassLoader 启动类加载器，默认加载的是jdk\lib目录下jar中诸多类；
- Extention ClassLoader 扩展类加载器，默认加载jdk\lib\ext\目录下jar中诸多类；
- Application ClassLoader 应用类加载器，负责加载开发人员所编写的诸多类。
- User ClassLoader 用户自定义类加载器

所谓的双亲委派机制，指的就是：**当一个类加载器收到了类加载的请求的时候，他不会直接去加载指定的类，而是把这个请求委托给自己的父加载器去加载。只有父加载器无法加载这个类的时候，子加载器才会尝试去加载这个类。**

为什么需要双亲委派机制：因为类加载器之间有严格的层次关系，那么也就使得Java类也随之具备了层次关系。这种机制好处体现在：

首先，**通过委派的方式，可以避免类的重复加载**，当父加载器已经加载过某一个类时，子加载器就不会再重新加载这个类。

另外，**通过双亲委派的方式，还保证了安全性**。因为Bootstrap ClassLoader在加载的时候，只会加载JAVA_HOME中的jar包里面的类，如java.lang.Integer，那么这个类是不会被随意替换的，除非有人跑到你的机器上， 破坏你的JDK。

双亲委派是怎么实现的：**实现双亲委派的代码都集中在java.lang.ClassLoader的loadClass()方法之中**：

1. 先检查类是否已经被加载过
2. 若没有加载则调用父加载器的loadClass()方法进行加载 
3. 若父加载器为空则默认使用启动类加载器作为父加载器。 
4. 如果父类加载失败，抛出ClassNotFoundException异常后，再调用自己的findClass()方法进行加载。

如何主动破坏双亲委派机制：

1. 当我们想要自定义一个类加载器的时候，并且像破坏双亲委派原则时，继承ClassLoader类，我们会重写loadClass方法。（因为双亲委派的逻辑就写在了loadClass()方法中)）
2. 如果我们想定义一个类加载器，但是不想破坏双亲委派模型的时候，可以继承ClassLoader，并且重写findClass方法实现加载逻辑。

使用场景：因为双亲委派机制不能支持SPI(Service Provider Interface), 所以才会引入线程上下文类加载器，有了它，就可以打通双亲委派模型的层次结构来反向使用类加载器来完成类加载。



#### Q：类加载过程

答：Class 文件需要加载到虚拟机中之后才能运行和使用，虚拟机加载 Class 类型的文件主要三步：加载->连接->初始化。连接过程又可分为三步：验证->准备->解析。

![img](C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\类加载过程-完善.png)

1. 加载：通过一个完整的类或接口名称来获得其二进制流的形式并将其按照Java虚拟机规范将数据存储到运行时数据区。

   - 通过全类名获取定义此类的==二进制字节流==
   - 将字节流所代表的==静态存储结构转换为方法区的运行时数据结构==
   - 在内存中生成一个代表该类的 `Class` 对象，作为方法区这些数据的访问入口

2. 连接：获取类或接口类型的二进制形式并将其结合到Java虚拟机的运行时状态以便执行的过程

   1. 验证：类加载进来了肯定是需要对格式做一个校验，要不然什么东西都直接放到内存里面，Java的安全性就完全无法得到保障。文件格式验证（版本号），元数据验证（字段合法），字节码验证（逻辑）
   2. 准备：准备工作是正式开始分配内存地址的一个阶段，**主要为类或接口创建静态字段(类变量和常量)，并将这些字段初始化为默认值。**
   3. 解析：虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。

3. 初始化：执行初始化方法 `<init> ()`方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。

4. 卸载：卸载类即该类的 Class 对象被 GC。

   **卸载类需要满足 3 个要求**:

   1. 该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。
   2. 该类没有在其他任何地方被引用
   3. 该类的类加载器的实例已被 GC

   所以，在 JVM 生命周期内，由 jvm 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。



#### Q：new一个对象在堆中的历程

对象的创建过程分五步，如下图：

<img src="C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\v2-fc5cfaa4197d14310aaa5baab36c05d5_r.jpg" alt="preview" style="zoom:50%;" />

new 一个对象在堆中的过程主要分为五个步骤：

1）类加载检查：具体来说，当 Java 虚拟机遇到一条字节码 new 指令时，它会首先检查根据 **类文件常量池**（Constant Pool Table）能否找到这个类对应的符号引用，然后去==方法区中的运行时常量池==中查找该符号引用所指向的类是否已被 JVM 加载、解析和初始化过

- 如果没有，那就先执行相应的类加载过程
- 如果有，那么进入下一步，为新生对象分配内存

2）分配内存：就是在堆中给划分一块内存空间分配给这个新生对象用。具体的分配方式根据堆内存是否规整有两种方式：

- 堆内存规整的话采用的分配方式就是指针碰撞：所有被使用过的内存都被放在一边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，分配内存就是把这个指针向空闲空间方向挪动一段与对象大小相等的距离
- 堆内存不规整的话采用的分配方式就是空闲列表：所谓内存不规整就是已被使用的内存和空闲的内存相互交错在一起，那就没有办法简单地进行指针碰撞了，JVM 就必须维护一个列表，记录哪些内存块是可用的，在分配的时候从列表中找到一块足够大的连续空间划分给这个对象，并更新列表上的记录，这就是空闲列表的方式

3）初始化零值：对象在内存中的布局可以分为 3 块区域：对象头、实例数据和对齐填充，对齐填充仅仅起占位作用，没啥特殊意义，初始化零值这个操作就是初始化实例数据这个部分，比如 boolean 字段初始化为 false 之类的

4）设置对象头：这个步骤就是设置对象头中的一些信息

5）执行 init 方法：最后就是执行构造函数，构造函数即 Class 文件中的 `<init>()` 方法，一般来说，new 指令之后会接着执行 `<init>()` 方法，按照构造函数的意图对这个对象进行初始化，这样一个真正可用的对象才算完全地被构造出来了



#### Q：Java对象的内存分配过程是如何保证线程安全

在为对象创建内存的时候，还需要考虑一个问题：并发安全问题。

对象创建在虚拟机中是非常频繁的行为，以上面介绍的指针碰撞法为例，即使只修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现某个线程正在给对象 A 分配内存，指针还没来得及修改，另一个线程创建了对象 B 又同时使用了原来的指针来分配内存的情况。

解决这个问题有两种可选方案：

- 方案 1：**CAS + 失败重试**：CAS 大伙应该都熟悉，比较并交换，乐观锁方案，如果失败就重试，直到成功为止
- 方案 2：**本地线程分配缓冲**（Thread Local Allocation Buffer，`TLAB`）：每个线程在堆中预先分配一小块内存，每个线程拥有的这一小块内存就称为 TLAB。哪个线程要分配内存了，就在哪个线程的 TLAB 中进行分配，这样各个线程之间互不干扰。如果某个线程的 TLAB 用完了，那么虚拟机就需要为它分配新的 TLAB，这时才需要进行同步锁定。可以通过 `-XX：+/-UseTLAB` 参数来设定是否使用 TLAB。



#### Q：Unsafe类

Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力。

Unsafe类为一单例实现，Unsafe提供的API大致可分为内存操作、CAS、Class相关、对象操作、线程调度、系统 信息获取、内存屏障、数组操作等几类。

我们在Java中创建的对象都处于堆内内存（heap）中，堆内内存是由JVM所管控的Java进程内存，并且它们遵循JVM的内存管理机制，JVM会采用垃圾回收机制统一管理堆内存。与之相对的是堆外内存，存在于JVM管控之外的内存区域，Java中对堆外内存的操作，依赖于Unsafe提供的操作堆外内存的native方法。

**使用堆外内存的原因**：对垃圾回收停顿的改善，提升程序I/O操作的性能。
==DirectByteBuffer是Java用于实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，如在Netty、MINA等NIO框架中应用广泛。==DirectByteBuffer对于堆外内存的创建、使用、销毁等逻辑均由Unsafe提供的堆外内存API来实现。



#### Q：JVM 常用的调优参数

| 配置参数                        | 功能                                                         |
| :------------------------------ | :----------------------------------------------------------- |
| -Xms                            | 初始堆大小。如：-Xms256m                                     |
| -Xmx                            | 最大堆大小。如：-Xmx512m                                     |
| -Xmn                            | 新生代大小。通常为 Xmx 的 1/3 或 1/4。新生代 = Eden + 2 个 Survivor 空间。实际可用空间为 = Eden + 1 个 Survivor，即 90% |
| -Xss                            | JDK1.5+ 每个线程堆栈大小为 1M，一般来说如果栈不是很深的话， 1M 是绝对够用了的。 |
| -XX:NewRatio                    | 新生代与老年代的比例，如 –XX:NewRatio=2，则新生代占整个堆空间的1/3，老年代占2/3 |
| -XX:SurvivorRatio               | 新生代中 Eden 与 Survivor 的比值。默认值为 8。即 Eden 占新生代空间的 8/10，另外两个 Survivor 各占 1/10 |
| -XX:PermSize                    | 永久代(方法区)的初始大小                                     |
| -XX:MaxPermSize                 | 永久代(方法区)的最大值                                       |
| -XX:+PrintGCDetails             | 打印 GC 信息                                                 |
| -XX:+HeapDumpOnOutOfMemoryError | 让虚拟机在发生内存溢出时 Dump 出当前的内存堆转储快照，以便分析用 |

调优经验：

一般来说，我们的优化思路一般来说关系型数据库是先到瓶颈，首先排查是否为数据库的问题，然后会考虑是否扩容，接着，应用代码层面上排查并优化，再接着JVM层面上排查并优化，最后是网络和操作系统层面排查。



执行jps命令，列出正在运行的java程序的进程ID

使用top查看目前正在运行的进程使用系统资源情况

找到目标进程使用` jmap -dump:format=b,file=mydump.dump pid` 生成dump文件。



#### Q：内存溢出与内存泄露

**内存溢出**

指一种程序运行错误，当程序运行时需要的内存超过剩余内存，就会出现内存溢出错误。

出现情况：

1. 内存中加载的数据量过大，比如一次从数据库中取出过多数据；
2. 代码中存在死循环并且循环里面不断产生对的对象实体
3. 集合类中有对对象的引用，使用后未清空，使得JVM不能回收



**内存泄漏**

指占用的内存没有及时释放，内存泄漏多了就容易导致内存溢出。

出现情况：

1. 静态变量或者说静态集合类，如果它持有外部对象的引用，那么这个外部变量也不会被回收。典型的是ThreadLocal
2. 数据连接、IO、Scoket连接没有及时关闭



**内存溢出原因和解决思路**

JVM的内存溢出可以分成堆栈内存溢出。

栈溢出：

栈溢出时会出现两种异常：StackOverflowError异常和OutOfMemoryError异常。其中StackOverflowError异常是因为线程请求的栈深度大于虚拟机允许的最大深度；OutOfMemoryError异常发生是因为虚拟机内存动态扩展时，当扩展容量无法申请到足够的内存时发生。因为HotSpot不支持动态扩展的，所以除非线程创建时内存申请无法满足时会出现OutOfMemoryError，其余都是产生StackOverflowError异常。

栈溢出解决思路：出现StackOverflowError异常时有明确的错误堆栈可供分析，比较容易定位。一般通过优化递归调用或者减少栈容量来更多线程来解决。

堆溢出：

堆溢出是不断创建对象并垃圾回收不及时，总容量超过最大堆容量时，会报OutOfMemoryError溢出。

堆溢出思路：首先通过内存映像分析工具确认是内存泄漏还是内存溢出。

1. 如果是内存溢出，说明导致OOM的对象是不必要的，进一步通过工具查看GC Roots引用链。一般可以比较精确的定位。
2. 如果是内存溢出，对象是必须存活的，那就检查虚拟机的堆参数-Xms、-Xmx设置，对比机器内存，看是否还有上调的空间。再从代码上检查对象生命周期、持有状态时间、存储结构是否有设计不合理等情况。

方法区和运行时常量池溢出：

在经常运行时生成大量动态类的应用场景里可能出现太多新类导致溢出。

解决方案：参数设置，包括-XX:MinMetaspace Free Ratio：作用是在垃圾收集之后控制最小的元空间剩余容量的百分比，可减少因为元空间不足导致的垃圾收集的频率。

直接内存溢出：

在直接或间接使用了ByteBuffer中的allocateDirect方法的时候，而不做clear的时候就会出现类似的问题。明显的特征是在Heap Dump文件中不会看到明显的异常情况。

解决方案：设置参数：-XX:MaxDirectMemorySize



> 内存溢出，简单地说内存溢出就是指程序运行过程中申请的内存大于系统能够提供的内存，导致无法申请到足够的内存，于是就发生了内存溢出。引起内存溢出的原因有很多种，常见的有以下几种：
>
> 1. 内存中加载的数据量过于庞大，如一次从数据库取出过多数据；
> 2. 集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；
> 3. 代码中存在死循环或循环产生过多重复的对象实体；
> 4. 使用的第三方软件中的BUG；
> 5. 启动参数内存值设定的过小。
>
> 内存溢出的解决方案：
>
> 第一步，修改JVM启动参数，直接增加内存。
>
> 第二步，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。
>
> 第三步，对代码进行走查和分析，找出可能发生内存溢出的位置。
>
> 第四步，使用内存查看工具动态查看内存使用情况。
>
> 加分回答
>
>   除了程序计数器外，虚拟机内存的其他几个运行时区域都有发生OOM异常的可能。
>
> 1、Java堆溢出
>
> Java堆用于储存对象实例，我们只要不断地创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，那么随着对象数量的增加，总容量触及最大堆的容量限制后就会产生内存溢出异常。
>
> 2、虚拟机栈和本地方法栈溢出
>
> HotSpot虚拟机中并不区分虚拟机栈和本地方法栈，如果虚拟机的栈内存允许动态扩展，当扩展栈容量无法申请到足够的内存时，将抛出OutOfMemoryError异常。
>
> 3、方法区和运行时常量池溢出
>
> 方法区溢出也是一种常见的内存溢出异常，在经常运行时生成大量动态类的应用场景里，就应该特别关注这些类的回收状况。这类场景常见的包括：程序使用了CGLib字节码增强和动态语言、大量JSP或动态产生JSP文件的应用、基于OSGi的应用等。
>
> 在JDK 6或更早之前的HotSpot虚拟机中，常量池都是分配在永久代中，即常量池是方法去的一部分，所以上述问题在常量池中也同样会出现。而HotSpot从JDK 7开始逐步“去永久代”的计划，并在JDK 8中完全使用元空间来代替永久代，所以上述问题在JDK 8中会得到避免。
>
> 4、本地直接内存溢出
>
> 直接内存的容量大小可通过-XX：MaxDirectMemorySize参数来指定，如果不去指定，则默认与Java堆最大值一致。如果直接通过反射获取Unsafe实例进行内存分配，并超出了上述的限制时，将会引发OOM异常。



#### Q：VisualVM 分析堆内存溢出

测试代码：

```java
public class HeapOOP {

    static class OOMObject {
        private String name = "abc";
    }

    public static void main(String[] args) {
        List<OOMObject> list = new ArrayList<OOMObject>();
        try {
            while (true) {
                list.add(new OOMObject());
            }
        } catch (OutOfMemoryError error) {
            System.out.println("list的总大小为："+list.size());
            throw error;
        }

    }
}
```

首先修改IDEA的JVM启动参数，也就是VM options参数值如下：

```shell
-verbose:gc		# 辅助输出一些详细的gc信息
-Xms10M			# 堆初始大小
-Xmx10M			# 堆最大值
-Xmn5M			# 新生代大小
-XX:+HeapDumpOnOutOfMemoryError	# 当有内存溢出错误时自动生成dump文件（文件夹后缀名：.hprof）
-XX:HeapDumpPath				# 上一个参数生成的文件的路径
-XX:+PrintGCDetails				# 输出gc的详细信息
-XX:SurvivorRatio=8	
```

接下来，寻找生成的错误的dump文件，如果没指定-XX:HeapDumpPath，那么该dump文件在**项目跟目录**下根据进程号命名。

导入到visualVM 中，可以看到概要信息，在概要信息能够看到导致这次异常的线程信息

![在这里插入图片描述](C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\内存溢出排查.png)

可以看到导致发生错误的具体位置和原因，是添加对象时溢出了。

也可以再点到“类”页面，看一下信息：

![在这里插入图片描述](C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\内存溢出02.png)

发现类 OOMObject 实例数已经达到了360146个，这么多的实例，导致堆内存已经不够用，且没有被GC给回收。所以JVM就报出了内存溢出错误。

参考文章：https://blog.csdn.net/Myc_CSDN/article/details/99991449







参考文章：https://blog.csdn.net/chwshuang/category_2926853.html





## 框架

### SSM

#### Q：IoC原理

首先，IoC（Inverse of Control，控制反转）在其他语言中也有应用，并非 Spring 特有，它是一种设计思想，基本概念就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。IoC 具体的实现方式是依赖注入。

简单的说之前我们在代码中创建一个对象是通过 `new` 关键字，而使用了 `Spring` 之后，我们不在需要自己去 `new` 一个对象了，而是直接通过容器里面去取出来，再将其自动注入到我们需要的对象之中，也就说创建对象的控制权不在我们程序员手上了，全部交由 `Spring` 进行管理。

交给 Spring 管理的也称为 Bean，所有的 Bean 都被存储在一个 Map 集合中，这个 Map 集合也称为 IoC 容器（BeanFactory、ApplicationContext）。

将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。

比如说，在实际项目中一个 Service 类可能有几百甚至上千个类作为它的底层，假如我们需要实例化这个 Service，你可能每次都要搞清这个 Service 所有底层类的构造函数，这显然过于繁琐。如果利用 IoC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。

参考文章：https://mp.weixin.qq.com/s/uJv3KdSVUxgbz9Gkxy71aw



IoC （Inverse of Control，控制反转）是一种设计思想，用来简化应用的开发，把应用从复杂的依赖关系中解放出来。

具体来说就是将原本在程序中手动创建和管理对象的控制权，交由Spring IoC 容器来管理。IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。

当我们需要创建一个对象的时候，只需要配置好配置文件或注解即可，IoC容器会完成对象注入，而不用考虑对象的依赖关系和创建过程。

Spring IoC 的初始化过程

![图片](C:/Users/Lenovo/Desktop/笔记/CS-Learning-Notes/notes/pics/Spring IoC初始化过程.png)

底层原理：在XML文件配置好对象类的信息，其中包括id 和class，创建工厂类，通过反射来创建对象，根据设置的注入关系进行注入。 

DI（Dependency Injection，依赖注入）是IoC的一种手段，它说明了IoC控制的什么被反转了，也就是获得依赖对象的方式反转了。由Spring容器负责将需要的对象注入到调用者的成员变量，即为调用者注入了它依赖的实例，这就是依赖注入。 

注入方式有：

1. Setter注入
2. 构造器注入
3. 接口注入
4. 方法注入



#### Q：AOP原理

AOP（Aspect-oriented Programming）面向切面编程，为了解决横切逻辑代码存在的代码重复问题、以及横切逻辑代码和业务代码混杂在一起，代码臃肿，不便于维护等问题，而提出的一种编程思想。

它提出了横向抽取机制，将横切逻辑代码和业务逻辑代码分离。使得开发者在不改变源代码的前提下，为系统中不同业务组件添加某些通用功能。常见的应用场景有如日志功能、事务管理等。

Spring AOP实现方式：如果你的代理类有接口的话，那走的JDK的动态代理，如果没有的话，则使用cglib字节码技术去创建代理类对象，主要就是这两种方式来做的。

> - 切面(Aspect)：似于 Java 中的类声明，常用于应用中配置事务或者日志管理。一般使用 `@Aspect` 注解或者 `<aop:aspect>` 来定义一个切面。
> - 连接点(Join Point)：程序执行中的特定点，比如方法执行、处理一个异常等
> - 切点(Pointcut)：通过一种规则匹配的正则表达式，当有连接点可以匹配到切点时，就会触发改切点相关联的指定通知。
> - 通知(Advice)：在切面中某个连接点采取的动作，通知方式也有5种



#### Q：Spring Bean 的生命周期

答：（1）Spring在启动的时候需要扫描在XML/注解/JavaConfig 中需要被Spring管理的Bean信息，随后，会将这些**信息封装成BeanDefinition**，最后会把这些信息放到一个beanDefinitionMap中，这个Map的key应该是beanName，value则是BeanDefinition对象。

（2）接着会遍历这个beanDefinitionMap，执行BeanFactoryPostProcessor这个Bean工厂后置处理器的逻辑，对Bean的元信息进行修改。比如注入占位符等等。

（3）通过反射对对象进行实例化，这时对象具体的属性是还没注入的。

（4）接着开始初始化操作，首先判断该Bean是否实现了Aware相关的接口，如果存在则填充相关的资源。

（4）然后是BeanPostProcessor后置处理器有两个方法，一个是before，一个是after。这个BeanPostProcessor后置处理器是AOP实现的关键

（5）在这期间根据是否配置自定义的init-method执行方法

（6）执行完后，就可以通过getBean() 获取使用了。

（7）销毁的时候看是否实现DisposableBean接口和自定义destroy方法，执行就结束了。



#### Q：Spring 解决循环依赖

**三级缓存：**

1. singletonObjects（一级，正式Bean对象）

2. earlySingletonObjects（二级，还没进行属性注入，由三级缓存放进来，半成品）

3. singletonFactories（三级，Value是一个对象工厂）

过程：

1. A对象实例化后，属性注入前，会把A对象放入三级缓存，key是BeanName，而value是objectFactory
2. 当A属性注入时，发现依赖B，又会去实例化B
3. B属性注入时发现需要获取A对象，那么就从三级缓存中拿出ObjectFactory，得到对应的Bean，并把三级缓存中的A记录抹掉，放入二级缓存中
4. 等到B完全初始化之后，就会把二级缓存A对象记录抹掉放入一级缓存
5. 我们再去getBean时，拿到的则是一级缓存的



#### Q：Spring常用注解

（1）@SpringBootApplication

- @Configuration：标注当前类是配置类，内部的Bean也会被纳入Spring容器
- @EnableAutoConfiguration：启用 SpringBoot 的自动配置机制
- @ComponentScan：会扫描该类所在的包下所有的类

（2）Spring Bean 相关

- @Autowired：自动导入对象到类中，被注入进的类同样要被 Spring 容器管理
- @Componet、@Repository、@Service、@Controller：注解成可以自动装配的Bean
- @RestController：@Controller和@ResponseBody合集，表示这是个控制器 bean,并且是将函数的返回值直接填入 HTTP 响应体中
- @Scope：声明作用域
  - singleton：唯一 bean 实例，Spring 中的 bean 默认都是单例的
  - prototype：每次请求都会创建一个新的 bean 实例
  - request：每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效
  - session：每一个 HTTP Session 会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效

（3）处理常见的HTTP请求类型

- @GetMapping：@RequestMapping(value="/users",method=RequestMethod.GET)
- @PostMapping：@RequestMapping(value="/users",method=RequestMethod.POST)

（4）前后端传值

- @PathVariable：用于获取路径参数
- @RequestParam：用于获取查询参数
- @RequestBoby：用于读取 Request 请求

（5）读取配置信息

- @Value：读取简单配置信息
- @ConfigurationProperties：读取配置信息并与bean绑定

（6）开启事务

- @Transactional



#### Q：Spring 事务传播行为

目的：为了解决业务层方法之间相互调用的事务问题

类型：

1. required：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务
2. required_new：不管外部方法是否开启事务，修饰的内部方法都会新开启自己的事务，且开启的事务相互独立
3. nested：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED
4. mandatory：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。

不回滚类型：

1. supports：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行
2. not_supports：以非事务方式运行，如果当前存在事务则把事务挂起
3. never：以非事务方式运行，有事务则抛出异常



#### Q：SpringMVC 工作原理

<img src="C:\Users\Lenovo\Desktop\笔记\CS-Learning-Notes\notes\pics\SpringMVC工作原理.png" alt="图片" style="zoom: 67%;" />

1. 客户端（浏览器）发送请求，直接请求到 `DispatcherServlet`。
2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。
3. 解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由 `HandlerAdapter` 适配器处理。
4. `HandlerAdapter` 会根据 `Handler`来调用真正的处理器开处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回一个 `ModelAndView` 对象，`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
6. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
7. `DispatcherServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
8. 把 `View` 返回给请求者（浏览器）



#### Q：#{} 和 ${} 的区别

\#{} 是参数占位符，先预编译，然后填充参数加双引号，能防止SQL注入

${} 是变量占位符，直接拼接语句，执行语句，不安全



#### Q：XML映射文件中常见的标签

定义SQL语句：select、insert、update、delete、

配置Java对象属性与查询结果集中列名对应关系：resultMap

控制动态SQL拼接：foreach、if

格式化输出：where



#### Q：XML映射文件和DAO接口的映射原理

Dao 接口，就是人们常说的 `Mapper` 接口，接口的全限名，就是映射文件中的 namespace 的值，接口的方法名，就是映射文件中 `MappedStatement` 的 id 值，接口方法内的参数，就是传递给 sql 的参数。

Dao 接口的工作原理是 JDK 动态代理，MyBatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行 `MappedStatement` 所代表的 sql，然后将 sql 执行结果返回。





### Redis

#### Q：传统的RDBMS和NoSQL

RDBMS有组织化结构、固定的SQL、数据和关系都存储在单独的表中，有严格的语言规范，严格的一致性（ACID）和基础事务。

NoSQL：不仅仅是数据，没有固定查询语言，键值对存储（Redis）、、列存储（HBase）、文档存储（MongoDB）、图形数据库（不是存图形，放的是关系）（Neo4j），最终一致性（BASE）：基本可用、软状态/柔性事务、最终一致性



#### Q：Redis 和 Memcached的区别

都是基于内存的数据库；有过期策略。

但是Redis支持丰富的数据类型；持久化；原生支持集群模式。



#### Q：Redis 数据类型

1、**String**

最常用的一种数据类型，String类型的值可以是字符串、数字或者二进制。

应用场景：计数、缓存功能、共享用户session。set,get,strlen,exists,decr,incr,setex

底层结构：使用动态字符串进行封装

2、**List**

list 类型是用来存储多个有序的字符串的，列表当中的每一个字符串看做一个元素。与Java里面的双向链表差不多。

应用场景：消息队列、文章列表或者数据分页展示的应用。rpush、lpop、lpush、rpop、lrange

底层结构：linkedlist/ziplist

3、**Set**

set 类型可以用来存储多个字符串元素的集合，与list不同的是它是不允许重复且无序的。使用哈希表构造的，因此复杂度是O(1)，它支持集合内的增删改查，  并且支持多个集合间的交集、并集、差集操作。

应用场景：标签、共同好友功能、统计网络的独立IP。sadd、spop、smembers、scard、sunion

底层结构：intset/hashtable

4、**SortedSet**

redis有序集合也是集合类型的一部分，所以它保留了集合中元素不能重复的特性，但是不同的是，有序集合给每个元素多设置了一个分数。

应用场景： 排行榜、用SortedSet做带权重的队列。zadd、zcard、zscore、zrange

底层结构：ziplist/skiplist。zset同时使用跳跃表和字典；前者范围查找占有，后者随机查找占优



2、**Hash**

Hash 是一个键值对（key-value）集合,它是一个 string 类型的 field 和 value 的映射表。相当于在value中又套了一层key-value型数据。

应用场景：存储系统中对象数据，关系型数据库中的表记录。hset、hmset、hexists、hget、hkeys、hvals

底层结构：hashtable/ziplist

6、**Bitmap**

存储连续的二进制数字。

应用场景：需要保存状态信息（是否签到）。setbit、getbit、bitcount



#### Q：Redis 底层对象结构

**（1）redisObject**

1. type：对象的类型
2. encoding：对象所使用的编码，也就是对象使用了什么数据结构
3. ptr：指向对象的底层实现数据结构

**（2）redisServer**

1. redisDb *db：一个数组，保存着服务器中所有的数据库

   redisDb：

   - dict *dict：保存键值对
   - dict *expires：过期字典，保存着键的过期时间

2. int dbnum：服务器数据库数量

3. redisDb *db：记录客户端当前正在使用的数据库





#### Q：五大基本类型底层数据存储结构

![微信图片_20220402105034](C:/Users/Lenovo/Desktop/笔记/CS-Learning-Notes/notes/pics/微信图片_20220402105034.png)

（1）String 类型的存储结构

简单动态字符串SDS

采用sds结构体可以低复杂度获取字符串长度，避免缓冲区溢出，减少修改字符串的内存重新分配次数。

sds实现了空间预分配和惰性空间释放两种策略

空间预分配：如果sds修改后，sds长度（len的值）将于1mb，那么会分配与len相同大小的未使用空间，此时len与free值相同。如果大于等于1mb，每次给分配1mb未使用空间。

惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 free 属性将这些字节的数量记录下来，等待后续使用。

（2）List 类型的存储结构

1. Redis3.2之前的底层实现方式：压缩列表ziplist 或者 双向循环链表linkedlist；当list存储的数据量比较少且同时满足下面两个条件时，list就使用ziplist存储数据
2. Redis3.2及之后的底层实现方式：quicklist

quicklist是一个双向链表，而且是一个基于ziplist的双向链表，quicklist的每个节点都是一个ziplist，结合了双向链表和ziplist的优点。

（3）Hash 类型的存储结构

当Hash中数据项比较少的情况下，Hash底层才用压缩列表ziplist进行存储数据，随着数据的增加，底层的ziplist就可能会转成dict。

每个dict中都有两个hashtable，虽然dict结构有两个hashtable，但是通常情况下只有一个hashtable是有值的。但是在dict扩容缩容的时候，需要分配新的hashtable，然后进行渐近式搬迁，这时候两个hashtable存储的旧的hashtable和新的hashtable。搬迁结束后，旧hashtable删除，新的取而代之。

（4）set 类型的存储结构

集合Set类型底层编码包括hashtable和inset。

当存储的数据同时满足下面这样两个条件的时候，Redis 就采用整数集合intset来实现set这种数据类型：

- 存储的数据都是整数
- 存储的数据元素个数小于512个

当不能同时满足这两个条件的时候，Redis 就使用dict来存储集合中的数据。

（5）Zset 类型的存储结构

zet的底层编码有两种数据结构，一个ziplist，一个是skiplist。

ziplist 做排序：每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员（member），而第二个元素则保存元素的分值（score）。

skiplist 结构看上文。



#### Q：Redis 事务

redis事务提供了一种“将多个命令打包， 然后一次性、按顺序地执行”的机制， 并且事务在执行的期间不会主动中断 —— 服务器在执行完事务中的所有命令之后， 才会继续处理其他客户端的其他命令。

Redis中一个事务从开始到执行会经历开始事务（muiti）、命令入队和执行事务(exec)三个阶段，事务中的命令在加入时都没有被执行，直到提交时才会开始执行(Exec)一次性完成。

一组命令中存在两种错误不同处理方式

1.代码语法错误（编译时异常）所有命令都不执行

2.代码逻辑错误（运行时错误），其他命令可以正常执行 （该点不保证事务的原子性）

为什么redis不支持回滚来保证原子性

这种做法的优点：

- Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。

- 因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。

事务监控：redis使用watch key监控指定数据，相当于加乐观锁

watch保证事务只能在所有被监视键都没有被修改的前提下执行， 如果这个前提不能满足的话，事务就不会被执行。



#### Q：缓存异常

（1）缓存穿透

定义：指大量请求指向缓存和数据库中都没有的数据，导致大量请求绕过缓存落到数据库上，造成数据库短时间承受大量请求而崩掉。

解决措施：

1. 接口层增加校验，如用户权限校验、请求id校验
2. 从缓存和数据库都没取到数据，可以将key-value设置为key-null。缓存有效时间可以设置短点
3. 布隆过滤器，快速判断一个key是否存在于某容器。

（2）缓存击穿

定义：指大量请求缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，造成数据库压力过大。

解决措施：

1. 设置热点数据永不过期
2. 接口限流与熔断、降级
3. 互斥锁：对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询

（3）缓存雪崩

定义：指缓存中数据大批量到过期时间，而查询数据量巨大，后面的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

解决措施：

1. 过期时间设置随机
2. 设置热点数据永不过期
3. 如果是缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中

（４）缓存降级

定义：当访问量剧增、服务出现问题时，保证核心服务依然可用，即使是有损的（非核心服务关闭）

目的：防止Redis服务故障，导致数据库跟着一起发生雪崩问题

做法：Redis出现问题，不去数据库查询，而是直接返回默认值给用户。



#### Q：Redis 线程模型

**（1）单线程速度快的原因**

1. 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
2. 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；
3. 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
4. 使用多路I/O复用模型，非阻塞IO；
5. 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

**（2）Redis的单线程模型**

1. 针对高并发的网络请求，Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型。通过**IO 多路复用程序** 来监听来自客户端的大量连接（或者说是监听多个 socket），收到事件后通过任务分派器进行分发。

2. 针对建立连接请求事件，通过 Acceptor 处理，并建立对应的 handler 负责后续业务处理。

3. 针对非连接事件，Reactor 会调用对应的 handler 完成 read->业务处理->write 处理流程，并将结果返回给客户端。


整个过程都在一个线程里完成，因此 Redis 被称为是单线程的操作。

**（3）Redis的瓶颈**

因为redis是单线程且基于内存的，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络IO操作上。

**（4）Redis 的多路复用 I/O 模型**

Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现。

多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

Redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，一次放到文件事件分派器，事件分派器将事件分发给事件处理器。



#### Q：Redis的持久化机制

Redis的持久化机制有两种，分别是RDB和AOF两种。

RDB是指根据我们自己设置的时间或者手动执行BGSAVE命令，Redis会去生成RDB文件。RDB文件是一个压缩后的二进制快照文件，Redis可以在启动的时候通过这个文件进行数据还原。RDB文件的载入工作是在服务器启动时自动执行的。

AOF则是把Redis服务器接收到的所有写命令都记录到日志中，Redis重跑一遍这个日志文件，就相当于还原了数据。

RDB持久化过程：

Redis有一套事件处理机制，主要处理文件事件和时间事件，定时的RDB就是一个时间事件。当线程轮询到发现有RDB事件时，就会调用BGSAVE命令。而BGSAVE命令会fork一个子进程来生成RDB文件。

> RDB时间事件—fork子进程—做快照文件

AOF持久化过程：

AOF是在命令执行完之后，将命令追加写到缓冲区。Redis提供了几种策略来选择存入磁盘的时间，比如每秒一次/每条命令都执行/从不存盘。AOF刷盘是由后台线程异步执行，而不是主线程去干的。并且考虑到文件可能会特别大，还会fork子进程对文件重写，也就是从数据库读取现在的值，然后用一条命令去记录键值对替代这个键值对的多条命令。

> AOF - 缓冲区-刷盘是后台线程异步的，文件重写是fork子进程





#### Q：过期删除策略

删除达到过期时间的key

**（1）定时删除**

==对于每一个设置了过期时间的key都会创建一个定时器，一旦到达过期时间就立即删除==。

该策略可以立即清除过期的数据，对内存较友好，但是缺点是占用了大量的CPU资源去处理过期的数据，会影响Redis的吞吐量和响应时间。

**（2）惰性删除**

==当访问一个key时，才判断该key是否过期，过期则删除==。

该策略能最大限度地节省CPU资源，但是对内存却十分不友好。有一种极端的情况是可能出现大量的过期key没有被再次访问，因此不会被清除，导致占用了大量的内存。

**（3）定期删除**

==每隔一段时间，扫描Redis中过期key字典，并清除部分过期的key==。该策略是前两者的一个折中方案，还可以通过调整定时扫描的时间间隔和每次扫描的限定耗时，在不同情况下使得CPU和内存资源达到最优的平衡效果。

**在Redis中，同时使用了定期删除和惰性删除。**

Redis的过期删除策略是在启动时注册了serverCron函数，每一个时间时钟周期，都会抽取expires字典中的部分key进行清理，从而实现定期删除。另外，Redis会在访问key时判断key是否过期，如果过期了，就删除，以及每一次Redis访问事件到来时，beforeSleep都会调用activeExpireCycle函数，在1ms时间内主动清理部分key，这是惰性删除的实现。



#### Q：内存淘汰策略

Redis的内存淘汰策略，是指内存达到maxmemory极限时，使用某种算法来决定清理掉哪些数据，以保证新数据的存入。

Redis 提供 6 种数据淘汰策略：

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰
2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

Redis会在每一次处理命令的时候（processCommand函数调用freeMemoryIfNeeded）判断当前redis是否达到了内存的最大限制，如果达到限制，则使用对应的算法去处理需要删除的key

**总结：**

Redis对于内存的回收有两种方式，一种是过期key的回收，另一种是超过redis的最大内存后的内存释放。

对于第一种情况，Redis会在：

1、每一次访问的时候判断key的过期时间是否到达，如果到达，就删除key

2、redis启动时会创建一个定时事件，会定期清理部分过期的key，默认是每秒执行十次检查，每次过期key清理的时间不超过CPU时间的25%，即若hz=1，则一次清理时间最大为250ms，若hz=10，则一次清理时间最大为25ms。

对于第二种情况，redis会在每次处理redis命令的时候判断当前redis是否达到了内存的最大限制，如果达到限制，则使用对应的算法去处理需要删除的key。

参考文章：[Redis内存回收机制](https://juejin.cn/post/6844903873618903048)





#### Q：Redis集群架构

Redis集群架构主要是为了满足高可用性。

最简单的是主从模式，设置一个主节点，==从服务器通过复制主服务器的数据进行同步==。当主节点挂掉以后，需要手动指定新的主节点。

其中主从复制分成完整重同步和部分重同步。

全量复制是指主节点通过RDB 的BGSAVE 命令生成一份RDB文件，并将RDB 文件拷贝给从节点，让从节点自己去同步。第一次进行同步时都是全量复制。

增量复制是指当主节点接收到客户端的写命令会被写入到缓冲区，当执行增量复制时，会把缓冲区中的命令发送到从节点，从节点进行同步。

两者通过offset（复制偏移量）、复制积压缓冲区、服务器ID来判断。

主从模式存在不能自动故障转移、达不到高可用的问题。



==哨兵模式是当主节点挂掉后，哨兵节点会主动选举新的主节点==。

哨兵是特殊的Redis服务器，它会不断地ping 节点，监控节点的运行状态，一旦发现节点没有正常响应，那就会主观认为这个Reids节点下线了。如果有足够多的哨兵认为该节点下线了，那就认为客观下线了。要是该节点恰好是主节点那么就会触发故障转移。

故障转移就是当主节点被认为客观下线了，哨兵们会从从节点中选举出一个新的主节点。选举主要考虑从库的配置优先级、要判断哪个从服务器的复制offset最大、RunID大小等。

哨兵模式解决了主从复制不能自动故障转移、达不到高可用性，但还是存在主节点的写能力、容量受限于单机配置的问题。

Redis在==主从复制和故障转移过程中可能导致数据丢失==。

在主从复制过程中，主服务器会一直接收请求，然后把修改命令发给从服务器。假如主服务器的命令还没发完给从服务器，自己就挂掉了。这时候想要让从服务器顶上主服务器，但从服务器的数据是不全的。

还有一种情况就是：有可能哨兵认为主服务器挂掉了，但真实是主服务器并没有挂掉（网络抖动），而哨兵已经选举出新的主服务器。此时客户端没有反应过来，还继续向主服务器写数据，等到旧主服务器重连时，已经被纳入新主服务器的从节点了，所以这段时间客户端写入旧服务器的数据就丢了。

只能通过配置尽量避免。

**min-slaves-to-write** 是指主库最少得有 N 个健康的从库存活才能执行写命令。

**min-slaves-max-lag** ：是指从库和主库进行数据复制时的 ACK 消息延迟的最大时间；

> 异步 导致数据丢失；脑裂 导致数据丢失



分片集群模式说白了就是往每个Redis服务器存储一部分数据，所有的Redis服务器数据加起来，才组成完整的数据。

要想组成分片集群，那就需要按照一定规则将数据分发到不同的Redis实例上。当集群所有的Redis实例的数据加起来，那这份数据就是全的。

集群它的「路由」是做在客户端的；对数据分发的逻辑中，就涉及到了哈希槽的概念。

集群默认一个集群有16384个哈希槽，这些哈希槽会分配到不同的Redis实例中。

此外每个Redis集群间会相互通信，每个Redis服务器都能获得其他所有Redis服务器所负责的哈希槽。

当客户端有==数据写入==的时候，就根据key进行hash，然后对得到值对16384进行取模，得到具体的哈希槽，然后就可以将数据插入到分配该哈希槽的Redis实例中。

当集群中==服务器数量增加或者修改==中，哈希槽的关系会发生变化，变化也会发送给集群所有的Redis服务器。

如果在数据迁移时，服务器就返回「ack」命令告诉客户端应该去找哪个Redis实例要数据；

如果已经迁移完毕了，那就返回「move」命令告诉客户端应该去找哪个Redis实例要数据，并且客户端应该更新自己的缓存(映射关系)



之所以是16384是绝对够用了，而且过多会导致服务器间通信压力大。

> CRC16算法产生的hash值有16bit，该算法可以产生2^16-=65536个值；16384 / 4 = 16384

之所以不选择一致性哈希，而选择hash槽的原因：

一致性哈希算法就是有一个 哈希环，当客户端请求时，会对key进行hash，确定哈希环的位置，然后顺时针往后找，找到的第一个真实节点。

一致性哈希算法比 传统固定取模的好处在于：如果集群需要新增或删除某实例，只会影响一部分的数据。但如果在集群中新增或者删除实例，在一致性哈希算法下，就得知道是「哪一部分数据」受到影响了，需要进行对受影响的数据进行迁移。

而哈希槽的方式，我们通过上面已经可以发现：在集群中的每个实例都能拿到槽位相关的信息，当客户端对key进行hash运算之后，如果发现请求的实例没有相关的数据，实例会返回「重定向」命令告诉客户端应该去哪儿请求。

一致性哈希算法存在哈希环的偏斜问题，需要采用虚拟节点处理。

参考文章：[一致性hash介绍](https://juejin.cn/post/6981644290057306119#heading-1)



#### Q：如何保证Redis和DB的一致性

因为cache和db的更新不是一个原子操作，严格意义上任何非原子操作都不可能保证一致性，除非用阻塞读写的强一致性分布式事务，但性能有限。缓存可以提升性能、缓解数据库压力，但是使用缓存也会导致数据不一致性的问题。一般我们是如何使用缓存呢？有三种经典的缓存模式：

**（1）Cache-Aside Pattern（旁路缓存模式）**

读流程：

1. 读的时候，先读缓存，缓存命中的话，直接返回数据；
2. 缓存没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应。

写流程：更新的时候，先更新数据库，然后再删除缓存。

> 扩展问题1：在写数据的过程中，可以先删除 cache ，后更新 DB 么？
>
> 答：会造成数据库（DB）和缓存（Cache）数据不一致的问题。在写请求在依次删除cache后到更新DB前的这段时间内，有可能出现读请求，从数据库取出数据放入缓存中。这样缓存和数据库的数据不一致了。缓存保存的是老数据，数据库保存的是新数据。
>
> 扩展问题2：在写数据的过程中，先更新DB，后删除cache就没有问题了么？
>
> 答：理论上来说还是可能会出现数据不一致性的问题。在读请求cache没命中情况下，在从数据库取出数据到放入缓存的这段时间内，有可能出现写请求，完成了更新数据库和删除cache，而读请求则会在cache放入旧版本数据。不过这种概率非常小，因为缓存的写入速度是比数据库的写入速度快很多！
>
> 扩展问题3：为什么写请求的时候，是删除cache而不是更新cache呢？
>
> 答：这是因为选择更新cache可能出现脏数据，比如两个前后顺序的写请求，因为网络原因，后者比前者先更新了cache，会使得cache保存的是老数据，数据库保存的是新数据。如果是采用删除缓存则不会出现这个脏数据问题。
>
> 扩展问题4：如果更新数据库成功，而删除缓存失败该怎么办？
>
> 答：增加 cache 更新重试机制： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。

现在我们再来分析一下 Cache Aside Pattern 的缺陷。

- 缺陷1：首次请求数据一定不在 cache 的问题

  解决办法：可以将热点数据可以提前放入cache 中。

- 缺陷2：写操作比较频繁的话导致cache中的数据会被频繁被删除，这样会影响缓存命中率 。

  解决办法：

  - 数据库和缓存数据强一致场景 ：更新DB的时候同样更新cache，不过我们需要加一个锁/分布式锁来保证更新cache的时候不存在线程安全问题。
  - 可以短暂地允许数据库和缓存数据不一致的场景 ：更新DB的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。



**（2）Read-Through/Write through（读写穿透）**

该模式下服务端把缓存作为主要数据存储。应用程序跟数据库缓存交互，都是通过**抽象缓存层**完成的。

读：

1. 从 cache 中读取数据，读取到就直接返回 
2. 读取不到的话，先从 DB 加载，写入到 cache 后返回响应

写流程：

1. 先查 cache，cache 中不存在，直接更新 DB
2. cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（同步更新 cache 和 DB）



**（3）Write behind（异步缓存写入）**

写流程：只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB

参考文章：[Redis与MySQL双写一致性如何保证？](https://juejin.cn/post/6964531365643550751#heading-1) 、[JavaGuide](https://github.com/Snailclimb/JavaGuide)





#### Q：Redis挂了，流量把数据库也打挂了，怎么办？

先说恢复：

1、首先服务挂了，优先考虑把 Redis 和数据库服务重新启动起来。

2、但是启动之前得先做个小操作，把流量摘掉，可以先把流量拦截在入口的地方，比如简单粗暴的通过 Nginx 的配置把请求都转到一个精心设计的错误页面。目的是为了防止流量过大，直接把新启动的服务，启动一个打挂一个的情况出现。

3、要是启动起来又扛不住了，请在心里默念分布式系统三大利器：缓存、拆分、加钱。有钱堆机器，没钱缓存预热，就是当 Redis 服务重新启动后，通过程序先放点已知的热点 key 进去后，系统再对外提供服务，防止缓存击穿的场景。

再谈预防：

从技术方案的角度说，这一切的问题都是因为 Redis 崩了，也就是发生了缓存雪崩。

在高并发的情况下，除了缓存雪崩，我们还必须得考虑到缓存的击穿、穿透问题。而且 Redis 为什么会崩了？是不是没有保证高可用？服务中是不是需要考虑限流或者熔断机制，最大程度的保护程序的运行？或者我们是否应该建立多级缓存的机制，防止 Redis 挂掉之后，大批流量直接打到 MySQL 服务导致数据库的崩盘？



### 消息队列

#### Q：消息队列的用途

服务解耦、异步处理、流量控制



#### Q：中间件的对比



#### Q：两种基本模型

（1）队列模型

生成者往队列里发送消息，消费者从中消费消息，彼此是竞争关系

（2）发布订阅模型

解决一条消息能被多个消费者消费的问题



#### Q：保证消息不丢失

（1）生产消息

生成消息发到Broker需要写好 try-catch；如果broker返回写入失败等错误信息，需要重试发送；当多次发送失败需要做报警，日志记录等。

（2）存储消息

存储消息阶段需要消息刷盘后再给生产者响应；如果是多副本机制，至少得两台以上写入成功才能给生产者响应。

（3）消费消息

业务逻辑处理完后再给Broker响应。

但是要注意消息可靠性增强了，性能就下降了，等待消息刷盘、多副本同步后返回都会影响性能。因此还是看业务，例如日志的传输可能丢那么一两条关系不大，因此没必要等消息刷盘再响应。



#### Q：如何处理重复消息

正常业务消息重复是不可避免的，幂等处理重复消息。



#### Q：保证消息的有序性

（1）全局有序

如果要保证消息的全局有序，首先只能由一个生产者往Topic发送消息，并且一个Topic内部只能有一个队列（分区）。消费者也必须是单线程消费这个队列。

（2）部分有序

将Topic内部划分成我们需要的队列数，把消息通过特定的策略发往固定的队列中，然后每个队列对应一个单线程处理的消费者。



#### Q：如何处理消息堆积

原因：生产者的生产速度与消费者的消费速度不匹配

措施：

1. 定位消费慢的原因，优化逻辑
2. 水平扩容，增加Topic的队列数和消费者的数量；一个Topic中，一个队列只会分配给一个消费者



### 设计模式

#### Q：单例模式

答：单例是指在当前进程中，通过单例模式创建的类有且只有一个实例。

单例模式经典的有饿汉式和懒汉式。

```java
// 饿汉式单例实现 饿汉式之所以是线程安全的，是因为JVM在类加载的过程，保证了不会初始化多个`static`对象。
public class Singleton {
  // 创建一个实例对象
    private static Singleton instance = new Singleton();
    /**
     * 私有构造方法，防止被实例化
     */
    private Singleton(){}
    /**
     * 静态get方法
     */
    public static Singleton getInstance(){
        return instance;
    }
}
```

```java
// synchronized 和 volatile 修饰的懒汉式
public class Singleton {
    private volatile static Singleton instance = null;
    private Singleton(){}
    public static Singleton getInstance(){
        //先检查实例是否存在，如果不存在才进入下面的同步块
        if(instance == null){
            //同步块，线程安全的创建实例
            synchronized (Singleton.class) {
                //再次检查实例是否存在，如果不存在才真正的创建实例
                if(instance == null){
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

```java
// 枚举写法
public enum Singleton {
    /**
     * 定义一个枚举的元素，它就代表了Singleton的一个实例。
     */
    Instance;
}
```

为什么不用静态方法而用单例模式？

两者其实都能实现我们加载的最终目的，但是他们一个是基于对象，一个是面向对象的，就像我们不面向对象也能解决问题一样，面向对象的代码提供一个更好的编程思想。

如果一个方法和他所在类的实例对象无关，那么它就应该是静态的，反之他就应该是非静态的。如果我们确实应该使用非静态的方法，但是在创建类时又确实只需要维护一份实例时，就需要用单例模式了。





#### Q：代理模式

答：所谓代理模式就是使用代理对象来代替对真实对象的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。代理模式有三大角色：

- Real Subject：真实类，也就是被代理类、委托类。用来真正完成业务服务功能
- Proxy：代理类。将自身的请求用 Real Subject 对应的功能来实现，代理类对象并不真正的去实现其业务功能
- Subject：定义 RealSubject 和 Proxy 角色都应该实现的接口

代理模式分为静态代理和动态代理。

先来说静态代理：

静态代理就是，对于你想要增强的委托类，我们需要新建一个代理类，这两个类实现一个同样的接口，然后==将委托类注入进代理类中==，在代理类的方法中调用委托类中的对应方法。这样，我们就可以通过代理类屏蔽对目标对象的访问，并且可以在目标方法执行前后做一些自己想做的事情。

从 JVM 层面来说， 静态代理就是在编译时就将接口、委托类、代理类这些都变成了一个个实际的 .class 文件。

静态代理的弊端很明显，一个委托类对应一个代理类，多个委托类就需要新建多个代理类，我们能不能将代理类做成一个通用的呢？

为此，动态代理应用而生。

动态代理的实现方式有很多种，常见的有：JDK 动态代理和 CGLIB 动态代理

先来说 JDK 动态代理：

同样的，JDK 动态代理需要委托类实现一个接口，不过代理类就不需要也实现同样的接口了，但是，JDK 动态代理机制中添加了一个新的角色，那就是处理类。具体来说，我们需要新建一个处理类，然后将委托类注入处理类，另外，这个==处理类需要实现 InvocationHandler 接口，并重写其 invoke 方法==，在 invoke 方法中可以利用反射机制调用委托类的方法，并可以在其前后添加一些额外的处理逻辑。最后，我们定义一个创建代理对象的工厂类Proxy（代理类），通过 Proxy.newProxyInstance() 创建委托类对象的代理对象。

这样做的缺点也是明显，那就是参数 Interfaces 是委托类的接口，是必传的，JDK 动态代理是通过与委托类实现同样的接口，然后在实现的接口方法里进行增强来实现的，这就意味着如果要用 JDK 代理，委托类必须实现接口。

如果目标类没有实现接口，就得选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个字节码生成的类库，可以在==运行时动态的生成某个类的子类==（通过修改字节码来实现代理）。

CGlib 动态代理也提供了类似的 Enhance 类，增强逻辑写在 MethodInterceptor.intercept() 中，也就是说所有委托类的非 final 方法都会被方法拦截器拦截，从而在拦截器里实现逻辑增强。

当然 CGLib 动态代理也有自身限制：只能代理委托类中任意的非 final 的方法，另外它是通过继承自委托类来生成代理的，所以如果委托类是 final 的，就无法被代理了。

那么什么情况下需要使用动态代理呢？

1. 设计模式中有一个设计原则是开闭原则，即对修改关闭，对扩展开放，我们在工作中有时会接手很多前人的代码，里面代码逻辑让人摸不着头脑，就很难去下手修改代码，那么这时我们就可以通过代理对类进行增强。
2. 我们在使用 RPC 框架的时候，框架本身并不能提前知道各个业务方要调用哪些接口的哪些方法。那么这个时候，就可用通过动态代理的方式来建立一个中间人给客户端使用，也方便框架进行搭建逻辑，某种程度上也是客户端代码和框架松耦合的一种表现。
3. Spring 的 AOP 机制同样也是采用了动态代理



#### Q：工厂模式

用于对类实现逻辑的封装，并且通过公共的接口提供对象的实例化的服务。

简单工厂模式：定义一个工厂类，根据传入的参数不同返回不同的实例，被创建的实例具有共同的父类和接口。

工厂方法模式：针对每个要创建的对象都会提供一个工厂类，这些工厂类都实现了一个工厂基类；也就是让一个类的实例化延迟到其子类。

适用场景：客户端不需要知道它所创建的对象的类；或可以通过子类来指定创建对应的对象。

抽象工厂模式：在这个模式中的工厂类不单单可以创建一个对象，而是可以创建一组对象。





#### Q：责任链模式

将请求的发送和接收解耦，让多个对象都有机会处理这个请求，这些对象串成一条链，传递这个请求，直到链上某个接收对象能够处理它为止。

角色：

- Client：客户端
- handle：处理器，是一个抽象类，里面由抽象方法handleRequest方法
- concreteHandler 具体处理器



#### Q：观测者模式

又称为发布订阅模式，当一个对象的状态发生改变时，已经登记的其他对象能够观察到这一改变从而作出自己相对应的改变；通过这种方式来达到减少依赖关系，解耦合的作用。

角色：

- Subject：主题，接口
- ConcreteSubject：具体主题，用一个容器维护订阅关系
- Observe：观测者，接受推送的消息



## 其他

### SQL

#### Q：常用SQL命令

```sql
# SQL 的增删改
create table students (
    id  int (10) not null,
    name varchar (20),
    #定义一个主键
    primary key (id)
);
alter table students add column age varchar(2);
alter table students drop age;
insert into students (id, name) values (1, 'wys');
update students set name = 'wang' where id = 1;
delete from students where name = 'wang';

# 索引
CREATE INDEX students_name ON students (name);
DROP INDEX students_name ON students;

# 从时间中获取日期
Date(时间) BETWEEN '2022-04-12' AND '2022-04-13'

# 聚集函数
AVG() 某列的平均值，COUNT() 行数，MAX() 最大值，MIN() 最小值，SUM(DISTINCT) 去重列值和

# 子查询
# (1) 利用子查询过滤：查询数学及格线以上的名单
SELECT name
FROM students
WHERE id IN (SELECT studentId
            FROM scores
            WHERE score >= 60 AND subjct = 'Math');
# (2) 作为计算字段使用子查询：查询每个学生的总分
SELECT name,
		(sELECT SUM(score)
        FROM scores
        WHERE scores.studentId = students.id) As totalScore
FROM students
ORDER BY name;

```



#### Q：打印男女成绩排名前五的名单

```java
(select name, sex, score from student where sex = 0 order by score desc limit 5)
union
(select name, sex, score from student where sex = 1 order by score desc limit 5)
```

#### Q：悲观锁(select...for update)与乐观锁(version)

```sql
# 悲观锁
START TRANSACTION;
select * from table where id=1 for update;
COMMIT;

# 乐观锁
update status set name='liar',version=(version+1) where id=1 and version=version;
```

#### Q：统计每天打卡率的成功率

```sql
select `date`, SUM(IF(status = 1, 1, 0)) / COUNT(*) AS rate
from sign_table
group by date
order by date desc;
```





### 编程考察

#### Q：多线程打印

方法一：用synchronized 、wait、notifyAll实现

```java
public class Main {

    private int num;
    private static final Object lock = new Object();
    private int maxnum = 10;

    private void printABC(int targetNum) {

        while (true) {
            synchronized (lock) {
                while (num % 3 != targetNum) {
                    if (num >= maxnum) {
                        break;
                    }
                    try {
                        lock.wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }

                }
                if (num >= maxnum) {
                    break;
                }
                num++;
                System.out.println(Thread.currentThread().getName() + ": " + num);
                lock.notifyAll();
            }

        }

    }


    public static void main(String[] args) {
        Main solution = new Main();
        new Thread(() -> {
            solution.printABC(0);
        }, "t1").start();

        new Thread(() -> {
            solution.printABC(1);
        }, "t2").start();

        new Thread(() -> {
            solution.printABC(2);
        }, "t3").start();

    }
    
}
```

方法二：用ReentrantLock实现

```java
public class Main {

    private int num;    // 当前状态值，保证交替打印
    private Lock lock = new ReentrantLock();


    private void printABC(int targetNum) {
        for (int i = 0; i < 10; ) {
            lock.lock();
            if (num % 3 == targetNum) {
                num++;
                i++;
                System.out.println(Thread.currentThread().getName());
            }
            lock.unlock();
        }
    }

    public static void main(String[] args) {
        Main solution = new Main();
        new Thread(() -> {
            solution.printABC(0);
        }, "A").start();

        new Thread(() -> {
            solution.printABC(1);
        }, "B").start();

        new Thread(() -> {
            solution.printABC(2);
        }, "C").start();
    }

}
```



方法三：用Lock+Condition实现

```java
class LockConditionABC {

    private int num;
    private static Lock lock = new ReentrantLock();
    private static Condition c1 = lock.newCondition();
    private static Condition c2 = lock.newCondition();
    private static Condition c3 = lock.newCondition();

    private void printABC(int targetNum, Condition currentThread, Condition nextThread) {
        for (int i = 0; i < 10; ) {
            lock.lock();
            try {
                while (num % 3 != targetNum) {
                    currentThread.await();  //阻塞当前线程
                }
                num++;
                i++;
                System.out.print(Thread.currentThread().getName());
                nextThread.signal();    //唤醒下一个线程，而不是唤醒所有线程
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                lock.unlock();
            }
        }
    }

    public static void main(String[] args) {
        LockConditionABC print = new LockConditionABC();
        new Thread(() -> {
            print.printABC(0, c1, c2);
        }, "A").start();
        new Thread(() -> {
            print.printABC(1, c2, c3);
        }, "B").start();
        new Thread(() -> {
            print.printABC(2, c3, c1);
        }, "C").start();
    }
}

```



方法四：

Semaphore：用来控制同时访问某个特定资源的操作数量，或者同时执行某个制定操作的数量。Semaphore内部维护了一个计数器，其值为可以访问的共享资源的个数。

一个线程要访问共享资源，先使用`acquire()`方法获得信号量，如果信号量的计数器值大于等于1，意味着有共享资源可以访问，则使其计数器值减去1，再访问共享资源。如果计数器值为0,线程进入休眠。

当某个线程使用完共享资源后，使用`release()`释放信号量，并将信号量内部的计数器加1，之前进入休眠的线程将被唤醒并再次试图获得信号量。

```java
class SemaphoreABC {

    private static Semaphore s1 = new Semaphore(1); //因为先执行线程A，所以这里设s1的计数器为1
    private static Semaphore s2 = new Semaphore(0);
    private static Semaphore s3 = new Semaphore(0);


    private void printABC(Semaphore currentThread, Semaphore nextThread) {
        for (int i = 0; i < 10; i++) {
            try {
                currentThread.acquire();       //阻塞当前线程，即信号量的计数器减1为0
                System.out.print(Thread.currentThread().getName());
                nextThread.release();          //唤醒下一个线程，即信号量的计数器加1

            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }

    public static void main(String[] args) throws InterruptedException {
        SemaphoreABC printer = new SemaphoreABC();
        new Thread(() -> {
            printer.printABC(s1, s2);
        }, "A").start();
        Thread.sleep(10);
        new Thread(() -> {
            printer.printABC(s2, s3);
        }, "B").start();
        Thread.sleep(10);
        new Thread(() -> {
            printer.printABC(s3, s1);
        }, "C").start();
    }
}

```

参考文章：[锁交替打印](https://juejin.cn/post/6959078859568316452)



#### Q：手写阻塞队列

参照ArrayBlockingQueue 实现版本

```java
import java.util.Random;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.ReentrantLock;

public class MyBlockingQueue {

    private Object[] tab; //队列容器

    private int takeIndex; //出队下标

    private int putIndex; //入队下标

    private int size;//元素数量

    private ReentrantLock reentrantLock = new ReentrantLock();

    private Condition notEmpty;//读条件

    private Condition notFull;//写条件

    public MyBlockingQueue(int tabCount) {
        if (tabCount <= 0) {
            new NullPointerException();
        }

        tab = new Object[tabCount];
        notEmpty = reentrantLock.newCondition();
        notFull = reentrantLock.newCondition();
    }

    public boolean offer(Object obj) {
        if (obj == null) { throw new NullPointerException(); }
        try {
            //获取锁
            reentrantLock.lock();
            //队列已满
            while (size==tab.length){
                System.out.println("队列已满");
                //堵塞
                notFull.await();
            }
            tab[putIndex]=obj;
            if(++putIndex==tab.length){
                putIndex=0;
            }
            size++;
            //唤醒读线程
            notEmpty.signal();
            return true;
        } catch (Exception e) {
            //唤醒读线程
            notEmpty.signal();
        } finally {
            reentrantLock.unlock();
        }
        return false;
    }


    public Object take(){
        try {
            reentrantLock.lock();
            while (size==0){
                System.out.println("队列空了");
                //堵塞
                notEmpty.await();
            }
            Object obj= tab[takeIndex];
            //如果到了最后一个，则从头开始
            if(++takeIndex==tab.length){
                takeIndex=0;
            }
            size--;
            //唤醒写线程
            notFull.signal();
            return obj;
        }catch (Exception e){
            //唤醒写线程
            notFull.signal();
        }finally {
            reentrantLock.unlock();
        }
        return null;
    }


    public static void main(String[] args) {
        Random random = new Random(100);
        MyBlockingQueue yzBlockingQuery=new MyBlockingQueue(5);
        Thread thread1 = new Thread(() -> {
            for (int i=0;i<100;i++) {
                try {
                    Thread.sleep(300);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                yzBlockingQuery.offer(i);
                System.out.println("生产者生产了："+i);
            }
        });

        Thread thread2 = new Thread(() -> {
            for (int i=0;i<100;i++) {
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                Object take = yzBlockingQuery.take();
                System.out.println("消费者消费了："+take);
            }
        });

        thread1.start();
        thread2.start();
    }



}
```



#### Q：排序算法

（1）冒泡排序

```java
public static void bubbleSort(int[] arr) {
    /* 冒泡排序算法 */
    int temp = 0;
    for (int i = arr.length - 1; i >= 0; i--) { // 每次需要排序的长度
        for (int j = 0; j < i; j++) {   // 从第1个元素到第i个元素
            if (arr[j] > arr[j + 1]) {  // 交换元素
                temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
            }
        }
    }
}
```

（2）选择排序

```java
public static void selectionSort(int[] arr) {
    /* 选择排序算法 */
    int temp, minIndex = 0;
    for (int i = 0; i < arr.length - 1; i++) {
        minIndex = i;
        // 循环查找最小值
        for (int j = i + 1; j < arr.length; j++) {
            if (arr[minIndex] > arr[j]) {
                minIndex = j;
            }
        }
        // 找到更小值,交换
        if (minIndex != i) {
            temp = arr[i];
            arr[i] = arr[minIndex];
            arr[minIndex] = temp;
        }
    }
}
```

（3）插入排序

```java
public static void insertionSort(int[] arr) {
    /* 插入排序 */
    int value, index;
    for (int i = 1; i < arr.length; i++) {
        value = arr[i];
        index = i;
        while (index > 0 && arr[index - 1] > value) {
            arr[index] = arr[index - 1];
            index--;
        }
        arr[index] = value;
    }
}
```

（4）归并排序

```java
public static void mergeSort(int[] arr) {
    /* 归并排序的主函数 */
    int[] temp = new int[arr.length];   // 用于排序腾挪
    internalMergeSort(arr, temp, 0, arr.length - 1);    // 拆分排序
}
    
private static void internalMergeSort(int[] arr, int[] temp, int left, int right) {
    /* 归并排序的拆分 */
    // 采用左闭右闭，故当left==right时，则不需要再划分
    if (left < right) {
        int middle = left + (right - left) / 2;
        internalMergeSort(arr, temp, left, middle); // 左子数组继续拆分
        internalMergeSort(arr, temp, middle + 1, right);    // 右子数组继续拆分
        mergeSortedArray(arr, temp, left, middle, right);  // 合并两个子数组
    }

}

private static void mergeSortedArray(int[] arr, int[] temp, int left, int middle, int right) {
    /* 归并排序的排序合并 */
    int i = left;   // 左序列指针
    int j = middle + 1; // 右序列指针
    int k = 0;  // 用于temp追加的指针
    while (i <= middle && j <= right) {
        temp[k++] = arr[i] <= arr[j] ? arr[i++] : arr[j++];
    }
    while (i <= middle) {   // 将左边剩余元素填充进temp中
        temp[k++] = arr[i++];
    }
    while (j <= right) {    // 将右边剩余元素填充进temp中
        temp[k++] = arr[j++];
    }
    // 把数据复制回原数组
    for (i = 0; i < k; i++) {
        arr[left + i] = temp[i];
    }
}
```

（5）快速排序

```java
public static void quickSort(int[] arr) {
    /* 快速排序 */
    qSort(arr, 0, arr.length - 1);
}

private static void qSort(int[] arr, int low, int high) {
    /* 快速排序的拆分 */
    if (low >= high)
        return;
    int pivot = partition(arr, low, high);  // 将数组分成两部分
    qSort(arr, low, pivot - 1); // 递归排序左子数组
    qSort(arr, pivot + 1, high);    // 递归排序右子数组
}

private static int partition(int[] arr, int low, int high) {
    /* 快速排序的分区 */
    int pivot = arr[low];   // 保存基准，同时使得low位置是待插入位置
    while (low < high) {    // 控制在low内遍历
        while (low < high && arr[high] >= pivot)
            high--; // 向前寻找
        arr[low] = arr[high];

        while (low < high && arr[low] <= pivot)
            low++;  // 向后寻找
        arr[high] = arr[low];
    }
    // low或high的位置就是该基准数据在数组中的正确索引位置
    arr[low] = pivot;
    return low;
}
```

（6）堆排序

```java
public static void heapSort(int[] arr) {
    /* 堆排序 */
    // 创建大顶堆
    for (int i = arr.length / 2 - 1; i >= 0; i--) {
        // 从第一个 非叶子节点 从下而上，从右至左调整结构
        adjustHeap(arr, i, arr.length);
    }
    // 调整堆结构且交换堆顶元素与末尾元素
    for (int j = arr.length - 1; j > 0; j--) {
        int temp = arr[0];
        arr[0] = arr[j];
        arr[j] = temp;
        adjustHeap(arr, 0, j);
    }
}

private static void adjustHeap(int[] arr, int i, int length) {
    /* 调整大顶堆 */
    int temp = arr[i];  // 先取出当前元素i
    // 从i结点的左子结点开始，也就是2 * i + 1处开始
    for (int k = i * 2 + 1; k < length; k = k * 2 + 1) {
        if (k + 1 < length && arr[k] < arr[k + 1]) {    // 如果左子结点小于右子结点，k指向右子结点
            k++;
        }
        if (arr[k] > temp) {    // 如果子节点大于父节点，将子节点值赋给父节点（不用进行交换）
            arr[i] = arr[k];
            i = k;  // 更新当前根节点
        } else {
            break;
        }
    }
    arr[i] = temp;  // 将temp值放到最终的位置
}
```







## 项目/HR面

### 待整理问题

常见项目问题：

- 你负责了项目的哪块内容？
- 项目的难点痛点是什么？你们怎么解决的？
- 你使用XX技术栈的时候有没有什么坑，你们怎么解决的？
- 项目中遇到过什么印象比较深的Bug？
- 遇到XX情况么？怎么解决的，怎么优化的？能多说几种方案么？
- 你是根据哪些指标进行针对性优化的？





### HR面

#### Q：自我介绍

面试官您好，我叫汪勇圣，目前湖南大学计算机学院研二在读。首先非常荣幸参与华为通用软件开发实习生的面试，介绍一下之前的项目开发经验，第一个项目是产前胎儿超声诊断项目，是医院和我们实验室合作的，为解决当前超声检测自动化和智能化程度低的问题，研究和开发实现包括标准切面抓取、胎儿生长参数检测和畸形诊断等功能。我的工作除了模型的研究以外，还有web参与后台开发工作，包括基于Redis中间件，实现了配置文件、图表数据的缓存，以及消息队列异步化处理切面检测等。另一个项目的话则是一个个人兴趣项目，搭建了一个RPC框架，实现了服务寻址、序列化和网络寻址等RPC的核心功能。我的项目经验的话大致是这样，至于学习生活方面，拿过了多次奖学金，平时的话我喜欢打羽毛球以及长跑。我的自我介绍说完了，谢谢！

> 面试官好，我叫汪勇圣，目前湖南大学计算机学院研二在读，期间做过的项目主要有两个，第一个是一个基于深度学习的产前胎儿超声诊断项目，主要是参与平台对外服务网站 WebUltrasonic 的部分开发工作以及胎儿骨骼切面检测模型的训练，目前这个项目已经上线，在300多家医院使用。第二个项目是实现了一个简易版的 RPC 框架，主要目的是想通过造轮子的方式来学习RPC的工作原理，目前已经实现了RPC网络传输、服务寻址、负载均衡等RPC核心功能，并且对系统的可用性和可靠性进行了一定提升。参加XXX的面试，希望能有一个后端开发实习的机会。







### WebUltrasonic

#### Q：项目概述

**背景**：产前超声AI智慧云平台是由湖南大学与深圳市妇幼保健院为主，合作的一个AI+医疗的项目，主要是为了解决当前产前超声检查自动化程度低，检查参数受主观影响严重，高度依赖于医生的经验水平的问题。
**面向群体**：这平台面向的群体是各大医院产科诊所的医生
**预期效果**：为他们提供一键式服务。医生使用超声仪器扫描孕妇，采集的超声视频会上传到平台，并调用标准切面抓取程序，得到标准切面图像。接着调用目标检测、分割模型进一步确定各个切面的小结构。医生可以从WebUltrasonic网站中查看到识别结果和统计分析结果。
**现状**：目前项目组团队共20余人，产品已经效果较好且相对稳定，上线推广至300+医院。

我的工作：

1. 参与平台对外服务系统 WebUltrasonic 的开发，针对线上超声图像标注存在切面重新检测导致响应时间较长 的情况，采用 Redis 消息队列异步化处理；针对信息统计首页高权限用户查询缓慢，采取分而治之缓存小区域数据的方式加速了统计过程。
2. 负责胎儿股骨肱骨切面的数据整理和模型训练工作，研究对比主流目标检测模型在处理超声图像任务的差异， 选择合适的网络模型调优并结合必要的后处理，最终训练的模型性能满足预期要求，现已部署上线。



#### Q：消息队列异步化处理的过程

为什么需要异步化：在医生质控模型切面预测的结果时，存在切面目标检测类型错误、位置错误以及判定信息错误等，当存在切面类型模型都预测错误的时候就需要将图像指定类型，重新送入模型检测，然后拿返回新的检测信息进行质控。而模型检测的过程，后端需要等待较长时间，所以引入了消息队列，让这个过程异步化解耦。

具体来说，就是当医生要质控一批数据的时候，我们会缓存在Redis中一个Hash类型变量缓存这批数据的一个完整的检测信息和状态信息。当医生对切面的质控修改信息都会被保存在里面，当存在切面类型错误时，则会将这个消息送入消息队列，让另一个工作进程去处理。当消息处理完成则修改Redis中缓存中对应的记录。

有三种颜色表示三种状态，灰色表示未质控、黄色表示在处理中、绿色表示已经质控完成。

送入消息队列时会将状态为黄色，当消费完成状态变成灰色。

> 任务一共三个进程（Flask、Redis、Worker）
>
> 具体流程：
>
> 1. 终端用户发送请求到服务端创建一个新任务
> 2. 任务队列会增加一个新任务，之后服务端再把任务id返回客户端，同时{workid: 1; res: 等待}存储在Redis的质控任务中
> 3. 消费进程消费任务前修改{workid: 1, res：正在处理}，处理好了那么就修改{workid: 1, res : 成功}；超时的话或者异常也会ACK，但是会修改{id: 1, res: 失败}，提示用户。
> 4. 创建好的任务会在服务端后台执行，客户端只需要使用AJAX不断轮询任务状态即可
>
> Stream提供了xreadgroup指令可以进行消费组的组内消费，需要提供消费组名称、消费者名称和起始消息ID。它同xread一样，也可以阻塞等待新消息。读到新消息后，对应的消息ID就会进入消费者的PEL(正在处理的消息)结构里，客户端处理完毕后使用xack指令通知服务器，本条消息已经处理完毕，该消息ID就会从PEL中移除。如果消费者收到了消息处理完了但是没有回复ack，就会导致PEL列表不断增长，如果有很多消费组的话，那么这个PEL占用的内存就会放大。

参考文章：[python requests post](https://www.jianshu.com/p/7db280adb4c0) 、[Redis Stream 消息队列](https://blog.csdn.net/qq_28827635/article/details/106141907) 、[python Stream](https://yukai08008.blog.csdn.net/article/details/121483156?spm=1001.2101.3001.6650.9&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9.topblog&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9.topblog&utm_relevant_index=14) 、 [redis消息队列搭建](https://yukai08008.blog.csdn.net/article/details/121466922?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_paycolumn_v3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_paycolumn_v3&utm_relevant_index=2) 

 

#### Q：消息队列的选型

首先考虑业务功能，这是一个ToB的项目，并发量并不会太高，其次出现故障也可以及时通知相应的单位。

而对比专业的消息队列中间件，它们优势主要是在消息不丢和消息可堆积性能上，但是在并发量不大的情况下，Redis 也可以保证这些。

其次从技术能力上来说，相对于Kafka、RocketMQ这些专业消息中间件，Redis消息队列的部署、维护都会更简单，还能够基本满足业务需求。



#### Q：Redis 缓存哪些数据

主要缓存一是配置信息，比如省市区、机构名称、切面信息包括代码、名称、小结构和颜色等信息。

然后还有一类是医院病例统计信息，医生很喜欢看图表内容，包括各种查询总表、分级表、变化图、各个切面统计。

然后我们还有一个是最近一周预测错误切面排行榜，统计最近一周的模型检测情况。



#### Q：项目存在的难点

1、项目随着运行数据库累积的数据量越来越大，网站首页的图表数据统计量也越来越大，特别是对于权限越高的用户，他所看到的数据也就越全，花费的时间也就长。而权限高的用户通常经常要拿些系统去先做汇报工作，所以对于响应时间的要求反而更高。而当时我就主要是负责数据管理部分的工作，但当时对于数据库查询优化这块并不熟悉，所以当时就看了很多网上的优化策略实验在我们这个系统上。比如说

（1）读取适当的记录limit M, N，而不要读取多余的记录

```sql
select id,name from t limit 866613, 20
```

当做分页时，随着表数据量的增强，直接使用`limit m, n`分页查询会越来越慢，这是因为MySQL 并非是跳过偏移量直接去取后面的数据，而是先把偏移量+要取的条数，然后再把前面偏移量这一段的数据抛弃掉再返回的。

优化方法：可以取前一页的最大行数的id，根据这个id来限制下一页的起点。或者是直接根据索引字段定位后，才取出相应内容，效率自然大大提升。

```sql
//方案一 ：返回上次查询的最大记录(偏移量)
select id,name from product where id > 866613 limit 20
//方案二：order by + 索引
select id,name from product order by id  limit 10000，10
//方案三：在业务允许的情况下限制页数
```

（2）优化Join语句

MySQL在执行Join的时候，会选择一个表把他要返回以及需要和其他表进行比较的数据放入`join_buffer` ，然后让这些数据依次去和被驱动表做匹配，所以实践中，需要尽可能减少循环次数的优化方式是，用小结果集驱动大结果集，尽量减少join语句中的Nested Loop的循环总次数。另一个是在被驱动表的join字段上建立索引，无法建立索引则设置足够的Join Buffer Size。

（3）表分区

MySQL在5.1后出现的，可以看作是水平拆分，分区表需要在建表的时候加上分区参数。分区表底层由多个物理子表组成，但是对于代码来说，分区表是透明的；分区类型有Range、hash、list、key分区。

```sql
// 可以使用ALTER TABLE来进行更改表为分区表
// 会创建一个分区表，然后自动进行数据copy然后删除原表
ALTER TABLE tbl_rtdata PARTITION BY RANGE (Month(fld_date))
(   
PARTITION p_Apr VALUES LESS THAN (TO_DAYS('2012-05-01')),
PARTITION p_May VALUES LESS THAN (TO_DAYS('2012-06-01')), 
PARTITION p_Dec VALUES LESS THAN MAXVALUE );
```

（4）增加缓存

主要思想是减少对数据库的访问，常用的是Redis。



### OPPO实习项目

OPPO广东移动通信有限公司   互联网服务系统 | 内容生态中心 | 技术架构部  2022-05 - 至今

项目描述：业务中台是内容产品中心的公共服务部门，提供围绕用户互动行为、业务增长诉求构建提供通用服务，例如为OPPO浏览器、锁屏、视频、负一屏等业务提供策略push、评论、点赞、消息以及用户资产等服务。

涉及技术：Spring、SpringMVC、MyBatis、Redis、MySQL、RocketMQ等

责任描述：

- 参与评论SDK的外部源接入
- push策略