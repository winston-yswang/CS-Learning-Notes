### 1、为什么要用Redis?

因为传统的关系型数据库如Mysql已经不能适用网站的访问响应速度，特别是应对首页的访问流量高峰时，所以引入了缓存中间件，目前市面上比较常用的缓存中间件有 **Redis** 和 **Memcached** 不过中和考虑了他们的优缺点，最后选择了Redis。

Redis在高性能和高并发两个方面非常有优势，操作缓存就是直接操作内存，所以速度相当快。直接操作缓存能够承受的请求是远远大于直接访问数据库的。



### 2、Redis 的数据结构、原理、使用场景

**String（字符串）** 

- 可以存储图片或者序列化的对象，值最大存储为512M；
- 常见命令：`set key value`、`get key`
- 应用场景：共享session、分布式锁、计数器、限流；
- 使用SDS动态字符串封装，因为C存在不保存字符串长度以及最后一个元素总是`\0` 的问题

```c
struct sdshdr{
  unsigned int len; // 标记buf的长度
  unsigned int free; //标记buf中未使用的元素个数
  char buf[]; // 存放元素的坑
}
```

**Hash（哈希）**

- 哈希类型是指v（值）本身又是一个键值对（k-v）结构；
- 常见命令：`hset key field value`、`hget key field`
- 应用场景：缓存用户信息、系统中对象数据的存储等；
- 开发时使用hgetall，哈希元素比较多的话，可能导致Redis阻塞，可以使用hscan。而如果只是获取部分field，建议使用hmget。
- hash 类似于 JDK1.8 前的 HashMap，通过 "数组 + 链表" 的链地址法来解决部分 哈希冲突

**List（列表）**

- 用来存储多个有序的字符串，一个列表最多可以存储2^32-1个元素；
- 常见命令：`lpush key value [value ...]`、`lrange key start end`
- 应用场景：消息队列、文章列表等。
- Redis 的 list 的实现为一个双向链表，即可以支持反向查找和遍历。

**Set（集合）**

- 用来保存多个的字符串元素，但是不允许重复元素；
- 常见命令：`sadd key element [element ...]`、`smembers key`
- 应用场景：用户标签、生成随机数抽奖、社交需求等
- Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。

**Zset（有序集合）**

- 已排序的字符串集合，同时元素不能重复；
- 常见命令：`zadd key score member [score member]`、`zrank key member`
- 应用场景：排行榜、社交需求（如用户点赞）
- 内部实现依赖了一种叫做**跳跃列表**的数据结构。

**HyperLogLog**

- 用来做基数统计算法的数据结构，如统计网络的UV；

**Geo**

- Redis3.2推出的，地理位置定位，用于存储地理位置信息，并对存储的信息进行操作

**Bitmaps**

- 用一个比特位来映射某个元素的状态，在Redis中，它的底层是基于字符串类型实现的，可以把bitmaps成作一个以比特位为单位的数组
- 应用场景：适合需要保存状态信息（比如是否签到、是否登录...）并需要进一步对这些信息进行分析的场景。比如用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。



### 3、zset 为何使用跳表？

- 跳表占用内存更小，更新节点有可能比B树更节约内存。

- 跳表因为底层是有序链表，可以顺序遍历元素，这点比红黑树高效得多。

- 更易于实现，调试。

跳表是一个随机化的数据结构，实质就是一种可以进行**二分**查找的**有序链表**。跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。

参考文章：[各种树的介绍](https://blog.csdn.net/flynetcn/article/details/120228493?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_aa&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_aa&utm_relevant_index=2)



### 4、如何保证Redis和DB的一致性

因为cache和db的更新不是一个原子操作，严格意义上任何非原子操作都不可能保证一致性，除非用阻塞读写的强一致性分布式事务，但性能有限。

缓存可以提升性能、缓解数据库压力，但是使用缓存也会导致数据不一致性的问题。一般我们是如何使用缓存呢？有三种经典的缓存模式：

#### **（1）Cache-Aside Pattern（旁路缓存模式）**

旁路缓存模式是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。

**读流程**：

1. 读的时候，先读缓存，缓存命中的话，直接返回数据；
2. 缓存没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应。

**写流程**：更新的时候，先更新数据库，然后再删除缓存。

拓展问题1：“**在写数据的过程中，可以先删除 cache ，后更新 DB 么？**”

**答案：** 那肯定是不行的！因为这样可能会造成**数据库（DB）和缓存（Cache）数据不一致**的问题。为什么呢？比如说请求1 先写数据A，请求2随后读数据A的话就很有可能产生数据不一致性的问题。这个过程可以简单描述为：

> 在写请求在依次删除cache后到更新DB前的这段时间内，有可能出现读请求，从数据库取出数据放入缓存中。

这样缓存和数据库的数据不一致了。缓存保存的是老数据，数据库保存的是新数据。

拓展问题2：“**在写数据的过程中，先更新DB，后删除cache就没有问题了么？**”

**答案：** 理论上来说还是可能会出现数据不一致性的问题，比如请求1先读数据 A，请求2随后写数据A，并且数据A不在缓存中的话也有可能产生数据不一致性的问题。这个过程可以简单描述为：

> 在读请求cache没命中情况下，在从数据库取出数据到放入缓存的这段时间内，有可能出现写请求，完成了更新数据库和删除cache，而读请求则会在cache放入旧版本数据。

不过这种概率非常小，因为缓存的写入速度是比数据库的写入速度快很多！

扩展问题3：**“为什么写请求的时候，是删除cache而不是更新cache呢？”**

**答案：** 这是因为选择更新cache可能出现脏数据，比如两个前后顺序的写请求，因为网络原因，后者比前者先更新了cache，会使得cache保存的是老数据，数据库保存的是新数据。如果是采用删除缓存则不会出现这个脏数据问题。

扩展问题4：如果更新数据库成功，而删除缓存该怎么办？

**增加 cache 更新重试机制**： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。

现在我们再来分析一下 **Cache Aside Pattern 的缺陷**。

**缺陷1：首次请求数据一定不在 cache 的问题** 

解决办法：可以将热点数据可以提前放入cache 中。

**缺陷2：写操作比较频繁的话导致cache中的数据会被频繁被删除，这样会影响缓存命中率 。**

解决办法：

- 数据库和缓存数据强一致场景 ：更新DB的时候同样更新cache，不过我们需要加一个锁/分布式锁来保证更新cache的时候不存在线程安全问题。
- 可以短暂地允许数据库和缓存数据不一致的场景 ：更新DB的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。

#### **（2）Read-Through/Write through（读写穿透）**

**Read/Write Through**模式中，服务端把缓存作为主要数据存储。应用程序跟数据库缓存交互，都是通过**抽象缓存层**完成的。

**Read-Through** 流程：

1. 从缓存读取数据，读到直接返回
2. 如果读取不到的话，从数据库加载，写入缓存后，再返回响应。

其实**Read-Through**就是多了一层**Cache-Provider** 的封装，让程序代码变得更简洁。

**Write-Through**模式下，当发生写请求时，也是由**缓存抽象层**完成数据源和缓存数据的更新。

这种缓存读写策略在平时在开发过程中非常少见。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存 Redis 并没有提供 cache 将数据写入DB的功能。

#### （3）Write behind（异步缓存写入）

**Write behind**跟**Read-Through/Write-Through**有相似的地方，都是由`Cache Provider`来负责缓存和数据库的读写。它两又有个很大的不同：**Read/Write Through**是同步更新缓存和数据的，**Write Behind**则是只更新缓存，不直接更新数据库，通过**批量异步**的方式来更新数据库。

很明显，这种方式对数据一致性带来了更大的挑战，比如cache数据可能还没异步更新DB的话，cache服务可能就就挂掉了。

Write Behind Pattern 下 DB 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。

参考文章：[Redis与MySQL双写一致性如何保证？](https://juejin.cn/post/6964531365643550751#heading-1) 、[JavaGuide](https://github.com/Snailclimb/JavaGuide)





### 5、Redis 为什么快，为什么redis单线程也快呢？

1. 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
2. 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；
3. 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
4. 使用多路I/O复用模型，非阻塞IO；
5. 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

#### Redis的单线程模型

针对高并发的网络请求，Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型。通过**IO 多路复用程序** 来监听来自客户端的大量连接（或者说是监听多个 socket），收到事件后通过任务分派器进行分发。

针对建立连接请求事件，通过 Acceptor 处理，并建立对应的 handler 负责后续业务处理。

针对非连接事件，Reactor 会调用对应的 handler 完成 read->业务处理->write 处理流程，并将结果返回给客户端。

整个过程都在一个线程里完成，因此 Redis 被称为是单线程的操作。

#### Redis的瓶颈

因为redis是单线程且基于内存的，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络IO操作上。

#### Redis 的多路复用 I/O 模型

Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现。

多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

Redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，一次放到文件事件分派器，事件分派器将事件分发给事件处理器。

**这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。**

采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。

参考文章：[Redis是单线程的，但Redis为什么这么快？](https://zhuanlan.zhihu.com/p/42272979) 、[面试时说Redis是单线程的，被喷惨了！](https://juejin.cn/post/6890769045608480776)



### 6、Redis 在分布式中会有什么问题怎么解决？

#### 缓存击穿

缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。

解决方法：

互斥锁：如果从redis中没有获取到数据，就让一个线程去数据库查询数据，然后构建缓存，其他的线程就等着，过一段时间后再从redis中去获取。

后台续命：后台开一个定时任务，专门主动更新即将过期的数据。

永不过期：会引发缓存击穿 key 一定会是个热点 key，会有大量的请求来访问这个数据。可以考虑直接放进去，永不过期。

#### 缓存穿透

缓存穿透说简单点就是大量请求的 key 根本不存在于缓存和数据库中，而用户短时间、高密度的发起这样的请求，每次都打到数据库服务上，给数据库造成了压力。

解决方法：

最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。

**缓存空对象**：就是在数据库即使查到的是空对象，我们也把这个空对象缓存起来。下次同样请求就会命中这个空对象，缓存层就处理了这个请求，不会对数据库产生压力。

扩展问题1：如果在某个时间，缓存为空的记录，在数据库里面有值了，你怎么办？

> 解决方法一：设置缓存的时候，同时设置一个过期时间，这样过期之后，就会重新去数据库查询最新的数据并缓存起来。
>
> 解决方法二：如果对实时性要求非常高的话，那就写数据库的时候，同时写缓存。这样可以保障实时性。
>
> 解决方法三：如果对实时性要求不是那么高，那就写数据库的时候给消息队列发一条数据，让消息队列再通知处理缓存的逻辑去数据库取出最新的数据。

扩展问题2：对于恶意攻击，请求的时候key往往各不相同，且只请求一次，那你要把这些key都缓存起来的话，因为每个key都只请求一次，那还是每次都会请求数据库，没有保护到数据库呀？

> 使用布隆过滤器

**布隆过滤器**：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。

 **布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**

_为什么会出现误判的情况呢? 我们还要从布隆过滤器的原理来说！_

我们先来看一下，**当一个元素加入布隆过滤器中的时候，会进行哪些操作：**

1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

我们再来看一下，**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：**

1. 对给定元素再次进行相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

然后，一定会出现这样一种情况：**不同的字符串可能哈希出来的位置相同。** （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）

#### 缓存雪崩

缓存雪崩：缓存在同一时间大面积的失效，或者缓存服务直接挂掉了，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。

解决方法：

针对 Redis 服务不可用的情况：

1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
2. 限流，避免同时处理大量的请求。

针对热点缓存失效的情况：

1. 设置不同的失效时间比如随机设置缓存的失效时间。
2. 缓存永不失效。

参考文章：[缓存击穿雪崩的概念](https://juejin.cn/post/7011672884271661064) 、[Redis挂了，流量把数据库也打挂了，怎么办？](https://juejin.cn/post/6991684241125801997#heading-3)



### 7、Redis 的两种持久化方式以及优劣

Redis 是**内存数据库**，如果不将内存中的数据库状态保存到磁盘，那么一旦服务器进程退出，服务器中的数据库状态也会消失。所以 Redis 提供了**持久化功能** 。

**Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）**。

#### RDB

RDB工作简单概述：

Redis会单独创建 ( fork )一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的。这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。我们默认的就是RDB，一般情况下不需要修改这个配置！

*rdb保存的文件是dump.rdb*

- 优点：
  - 恢复操作简单，容灾性好
  - 性能高，fork子进程进行写操作，主进程继续处理命令
  - 大数据集比AOF的恢复率高
- 缺点：
  - 数据安全性低，RDB是间隔一段时间进行持久化，若期间redis发生故障，可能发生数据丢失。
  - fork进程的时候，会占用一定的内存空间。



- 工作流程概述：

以日志的形式来记录每个写操作，将Redis执行过的所有指令记录下来（读操作不记录），只许追加文件但不可以改写文件, redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。

*aof保存的是appendonly.aof文件，默认是不开启的，我们需要手动进行配置！*

- 优点：
  - 数据安全
  - 三种同步策略：
    - 每次修改便会同步，保证文件完整性较好。
    - 每秒都进行一次同步，但是可能丢失这一秒的数据。
    - 从不进行同步，效率最高。
- 缺点：
  - AOF的持久化文件比RDB大，恢复速度慢
  - aof文件运行也要比rdb慢

参考文章：[Redis 的两种持久化方式以及优劣](https://juejin.cn/post/7029622373699551245)



### 8、Redis的内存回收机制

#### 过期删除策略

删除达到过期时间的key

**定时删除**

对于每一个设置了过期时间的key都会创建一个定时器，一旦到达过期时间就立即删除。该策略可以立即清除过期的数据，对内存较友好，但是缺点是占用了大量的CPU资源去处理过期的数据，会影响Redis的吞吐量和响应时间。

**惰性删除**

当访问一个key时，才判断该key是否过期，过期则删除。该策略能最大限度地节省CPU资源，但是对内存却十分不友好。有一种极端的情况是可能出现大量的过期key没有被再次访问，因此不会被清除，导致占用了大量的内存。

**定期删除**

每隔一段时间，扫描Redis中过期key字典，并清除部分过期的key。该策略是前两者的一个折中方案，还可以通过调整定时扫描的时间间隔和每次扫描的限定耗时，在不同情况下使得CPU和内存资源达到最优的平衡效果。

**在Redis中，同时使用了定期删除和惰性删除。**

Redis的过期删除策略是在启动时注册了serverCron函数，每一个时间时钟周期，都会抽取expires字典中的部分key进行清理，从而实现定期删除。另外，Redis会在访问key时判断key是否过期，如果过期了，就删除，以及每一次Redis访问事件到来时，beforeSleep都会调用activeExpireCycle函数，在1ms时间内主动清理部分key，这是惰性删除的实现。

#### 内存淘汰策略

Redis的内存淘汰策略，是指内存达到maxmemory极限时，使用某种算法来决定清理掉哪些数据，以保证新数据的存入。

Redis 提供 6 种数据淘汰策略：

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

7. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰
8. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

Redis会在每一次处理命令的时候（processCommand函数调用freeMemoryIfNeeded）判断当前redis是否达到了内存的最大限制，如果达到限制，则使用对应的算法去处理需要删除的key

#### 总结

Redis对于内存的回收有两种方式，一种是过期key的回收，另一种是超过redis的最大内存后的内存释放。

对于第一种情况，Redis会在：

1、每一次访问的时候判断key的过期时间是否到达，如果到达，就删除key

2、redis启动时会创建一个定时事件，会定期清理部分过期的key，默认是每秒执行十次检查，每次过期key清理的时间不超过CPU时间的25%，即若hz=1，则一次清理时间最大为250ms，若hz=10，则一次清理时间最大为25ms。

对于第二种情况，redis会在每次处理redis命令的时候判断当前redis是否达到了内存的最大限制，如果达到限制，则使用对应的算法去处理需要删除的key。

参考文章：[Redis内存回收机制](https://juejin.cn/post/6844903873618903048)

### 9、Redis挂了，流量把数据库也打挂了，怎么办？

先说恢复：

1、首先服务挂了，优先考虑把 Redis 和数据库服务重新启动起来。

2、但是启动之前得先做个小操作，把流量摘掉，可以先把流量拦截在入口的地方，比如简单粗暴的通过 Nginx 的配置把请求都转到一个精心设计的错误页面。目的是为了防止流量过大，直接把新启动的服务，启动一个打挂一个的情况出现。

3、要是启动起来又扛不住了，请在心里默念分布式系统三大利器：缓存、拆分、加钱。有钱堆机器，没钱缓存预热，就是当 Redis 服务重新启动后，通过程序先放点已知的热点 key 进去后，系统再对外提供服务，防止缓存击穿的场景。

再谈预防：

从技术方案的角度说，这一切的问题都是因为 Redis 崩了，也就是发生了缓存雪崩。

在高并发的情况下，除了缓存雪崩，我们还必须得考虑到缓存的击穿、穿透问题。而且 Redis 为什么会崩了？是不是没有保证高可用？服务中是不是需要考虑限流或者熔断机制，最大程度的保护程序的运行？或者我们是否应该建立多级缓存的机制，防止 Redis 挂掉之后，大批流量直接打到 MySQL 服务导致数据库的崩盘？

### 10、Redis高可用架构

参考文章：[Redis高可用总结](https://juejin.cn/post/6920457759393742862#heading-0)